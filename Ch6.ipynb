{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "16vlmGZvtm7E3dbiBU_X5m0ikOa3AzcXf",
      "authorship_tag": "ABX9TyNv5MotCnjZr4aWjztzDsdo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wakamatsuikuma/scratch-deeplearning/blob/main/Ch6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 44
        },
        "id": "cT9t4xrGpjEH",
        "outputId": "2e1f9c6b-6cc2-46cd-ffec-9d0d4369d121"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-32a1b201-594e-4bd8-9c9b-83e7c4dfbdba\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-32a1b201-594e-4bd8-9c9b-83e7c4dfbdba\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# coding: utf-8\n",
        "\n",
        "import sys, os\n",
        "ｓys.path.append(\"/content/drive/MyDrive/ゼロからつくるディープラーニング\")\n",
        "ｓys.path.append(\"/content/drive/MyDrive/ゼロからつくるディープラーニング/dataset\")\n",
        "ｓys.path.append(\"/content/drive/MyDrive/ゼロからつくるディープラーニング/common\")\n",
        "ｓys.path.append(\"/content/drive/MyDrive/ゼロからつくるディープラーニング/Ch4\")\n",
        "\n",
        "import numpy as np\n",
        "from mnist import load_mnist\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import pickle\n",
        "from functions import sigmoid, softmax\n",
        "from two_layer_net import TwoLayerNet\n",
        "\n",
        "\n",
        "# グーグルコラボなので画像表示はこれ使う\n",
        "def img_show(img):\n",
        "    pil_img = Image.fromarray(np.uint8(img))\n",
        "    display(pil_img)\n",
        "\n",
        "# ファイルをアップロード\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DQJ4E1HW8Iui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "確率的勾配降下法のモジュール実装\n",
        "\"\"\"\n",
        "\n",
        "class SGD:\n",
        "  # コンストラクタでは学習率を初期化\n",
        "  def __init__(self, lr=0.01):\n",
        "    self.lr = lr\n",
        "\n",
        "  # 学習では、引数に重みパラメータと勾配をディクショナリ変数で指定\n",
        "  def update(self, param, grads):\n",
        "    for key in param.keys():\n",
        "      param[key] -= self.lr * garads[key]\n"
      ],
      "metadata": {
        "id": "l4vH7sM5pvyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Momentumのモジュール実装\n",
        " vは速度であり、勾配方向に力を受け、その力によって速度が加算されていくイメージ\n",
        " SGDではその座標での勾配ベクトル分だけ移動していたが、Momentumではその座標で受けている力も加味される。\n",
        " →傾斜がゆるくても起伏がなければどんどん大きくなり、傾斜がきつくても起伏があれば安定しない　（＝行き過ぎない）？？\n",
        "\"\"\"\n",
        "\n",
        "class Momentum:\n",
        "  def __init__(self, lr=0.01, momentum=0.9):\n",
        "    self.lr = lr\n",
        "    self.momentum = momentum\n",
        "    self.v = None # 何も保持しないでおく。意味はわからん。\n",
        "  \n",
        "  def update(self, params, grads):\n",
        "    if self.v is None:\n",
        "      self.v = {}\n",
        "      for key, val in params.items():\n",
        "        self.v[key] = np.zeros_like(val)\n",
        "    \n",
        "    for key in params.kesy():\n",
        "      self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
        "      params[key] += self.v[key]\n"
      ],
      "metadata": {
        "id": "zC3-5oT2pzRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "AdamGradのモジュール実装\n",
        "  学習係数の減衰の手法。学習係数を勾配の要素ごとの乗算を保持した値の平方根で割ることで、\n",
        "  よく動いた要素はより小さくなるようにしている。\n",
        "\"\"\"\n",
        "class Momentum:\n",
        "  def __init__(self, lr=0.01):\n",
        "    self.lr = lr\n",
        "    self.ｈ = None # 何も保持しないでおく。意味はわからん。\n",
        "  \n",
        "  def update(self, params, grads):\n",
        "    if self.h is None:\n",
        "      self.h = {}\n",
        "      for key, val in params.items():\n",
        "        self.h[key] = np.zeros_like(val)\n",
        "    \n",
        "    for key in params.keys():\n",
        "      self.h[key] += grads[key] * grads[key]\n",
        "      params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7) # 0で除算するのを防ぐ"
      ],
      "metadata": {
        "id": "ziHA67UlpzTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "最適化手法の比較。MNISTデータで。\n",
        "　　　コード追うの厳しい。。。とりあえず結果確認のみ。\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# coding: utf-8\n",
        "import matplotlib.pyplot as plt\n",
        "from mnist import load_mnist\n",
        "from util import smooth_curve\n",
        "from multi_layer_net import MultiLayerNet\n",
        "from optimizer import *\n",
        "\n",
        "\n",
        "# 0:MNISTデータの読み込み==========\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
        "\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 128\n",
        "max_iterations = 2000\n",
        "\n",
        "\n",
        "# 1:実験の設定==========\n",
        "optimizers = {}\n",
        "optimizers['SGD'] = SGD()\n",
        "optimizers['Momentum'] = Momentum()\n",
        "optimizers['AdaGrad'] = AdaGrad()\n",
        "optimizers['Adam'] = Adam()\n",
        "#optimizers['RMSprop'] = RMSprop()\n",
        "\n",
        "networks = {}\n",
        "train_loss = {}\n",
        "for key in optimizers.keys():\n",
        "    networks[key] = MultiLayerNet(\n",
        "        input_size=784, hidden_size_list=[100, 100, 100, 100],\n",
        "        output_size=10) # 活性化関数にはReLu、\n",
        "    train_loss[key] = []    \n",
        "\n",
        "\n",
        "# 2:訓練の開始==========\n",
        "for i in range(max_iterations):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "    \n",
        "    for key in optimizers.keys():\n",
        "        grads = networks[key].gradient(x_batch, t_batch)\n",
        "        optimizers[key].update(networks[key].params, grads)\n",
        "    \n",
        "        loss = networks[key].loss(x_batch, t_batch)\n",
        "        train_loss[key].append(loss)\n",
        "    \n",
        "    if i % 100 == 0:\n",
        "        print( \"===========\" + \"iteration:\" + str(i) + \"===========\")\n",
        "        for key in optimizers.keys():\n",
        "            loss = networks[key].loss(x_batch, t_batch)\n",
        "            print(key + \":\" + str(loss))\n",
        "\n",
        "\n",
        "# 3.グラフの描画==========\n",
        "markers = {\"SGD\": \"o\", \"Momentum\": \"x\", \"AdaGrad\": \"s\", \"Adam\": \"D\"}\n",
        "x = np.arange(max_iterations)\n",
        "for key in optimizers.keys():\n",
        "    plt.plot(x, smooth_curve(train_loss[key]), marker=markers[key], markevery=100, label=key)\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"loss\")"
      ],
      "metadata": {
        "id": "6shB530ppzVO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a072dc76-3c35-4721-ca25-70aa2f10d44e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========iteration:0===========\n",
            "SGD:2.4926326643136045\n",
            "Momentum:2.3414673503214116\n",
            "AdaGrad:2.268675607196987\n",
            "Adam:2.1563959867948244\n",
            "===========iteration:100===========\n",
            "SGD:1.568481801156036\n",
            "Momentum:0.5323710871638367\n",
            "AdaGrad:0.19902658579372354\n",
            "Adam:0.35496460967711013\n",
            "===========iteration:200===========\n",
            "SGD:0.8478762718656939\n",
            "Momentum:0.28615506840828564\n",
            "AdaGrad:0.10759635915427085\n",
            "Adam:0.12732832885576895\n",
            "===========iteration:300===========\n",
            "SGD:0.5346149679270381\n",
            "Momentum:0.15986458038623574\n",
            "AdaGrad:0.048303796040715524\n",
            "Adam:0.10033005940172032\n",
            "===========iteration:400===========\n",
            "SGD:0.3816217581392449\n",
            "Momentum:0.11408754482834849\n",
            "AdaGrad:0.039073514280070616\n",
            "Adam:0.10241082385566252\n",
            "===========iteration:500===========\n",
            "SGD:0.39302475733622216\n",
            "Momentum:0.18760992813549815\n",
            "AdaGrad:0.0738530057232244\n",
            "Adam:0.09996495487307719\n",
            "===========iteration:600===========\n",
            "SGD:0.5118205977938011\n",
            "Momentum:0.20422053199031848\n",
            "AdaGrad:0.10823972802818804\n",
            "Adam:0.1455249269554414\n",
            "===========iteration:700===========\n",
            "SGD:0.29093532975778663\n",
            "Momentum:0.07257490068470548\n",
            "AdaGrad:0.03024651376654383\n",
            "Adam:0.06524232294203902\n",
            "===========iteration:800===========\n",
            "SGD:0.38361472871434943\n",
            "Momentum:0.12451293068542252\n",
            "AdaGrad:0.055556753457504646\n",
            "Adam:0.09668550889653739\n",
            "===========iteration:900===========\n",
            "SGD:0.25755416002616716\n",
            "Momentum:0.12293656601805046\n",
            "AdaGrad:0.042303592560469144\n",
            "Adam:0.11343189774037951\n",
            "===========iteration:1000===========\n",
            "SGD:0.23614277779426032\n",
            "Momentum:0.10725168795256795\n",
            "AdaGrad:0.04160518467989949\n",
            "Adam:0.07729280991550257\n",
            "===========iteration:1100===========\n",
            "SGD:0.3316605030615632\n",
            "Momentum:0.1531345352140906\n",
            "AdaGrad:0.09442748459013177\n",
            "Adam:0.14622207899748335\n",
            "===========iteration:1200===========\n",
            "SGD:0.3540082258960271\n",
            "Momentum:0.1443489955943924\n",
            "AdaGrad:0.03560400200778445\n",
            "Adam:0.05488435501823858\n",
            "===========iteration:1300===========\n",
            "SGD:0.306038337470697\n",
            "Momentum:0.10731083416298856\n",
            "AdaGrad:0.03968088763981878\n",
            "Adam:0.06444253452710673\n",
            "===========iteration:1400===========\n",
            "SGD:0.18537639520622667\n",
            "Momentum:0.0743375028213508\n",
            "AdaGrad:0.03908956245726611\n",
            "Adam:0.044512304966909874\n",
            "===========iteration:1500===========\n",
            "SGD:0.35317203610637415\n",
            "Momentum:0.09795330881773806\n",
            "AdaGrad:0.03131729959237124\n",
            "Adam:0.07106229808305285\n",
            "===========iteration:1600===========\n",
            "SGD:0.22542394016644515\n",
            "Momentum:0.03884266566759387\n",
            "AdaGrad:0.013460571135574894\n",
            "Adam:0.02082125980265162\n",
            "===========iteration:1700===========\n",
            "SGD:0.22442349218745822\n",
            "Momentum:0.07472861362261435\n",
            "AdaGrad:0.02635810685487685\n",
            "Adam:0.05341935724932945\n",
            "===========iteration:1800===========\n",
            "SGD:0.18706494261719625\n",
            "Momentum:0.061641100242911445\n",
            "AdaGrad:0.02090940555175087\n",
            "Adam:0.020187381737180515\n",
            "===========iteration:1900===========\n",
            "SGD:0.21098985297861356\n",
            "Momentum:0.08521255034358859\n",
            "AdaGrad:0.04086279198918058\n",
            "Adam:0.06389424488974241\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "アクティベーション分布の確認\n",
        "\"\"\"\n",
        "\n",
        "# coding: utf-8\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def ReLU(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "    \n",
        "input_data = np.random.randn(1000, 100)  # 1000個のデータ\n",
        "node_num = 100  # 各隠れ層のノード（ニューロン）の数\n",
        "hidden_layer_size = 5  # 隠れ層が5層\n",
        "activations = {}  # ここにアクティベーションの結果を格納する\n",
        "\n",
        "x = input_data\n",
        "\n",
        "for i in range(hidden_layer_size):\n",
        "    if i != 0:\n",
        "        x = activations[i-1]\n",
        "\n",
        "    # 初期値の値をいろいろ変えて実験しよう！\n",
        "    # w = np.random.randn(node_num, node_num) * 1\n",
        "    w = np.random.randn(node_num, node_num) * 0.01\n",
        "    # w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)\n",
        "    # w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)\n",
        "\n",
        "\n",
        "    a = np.dot(x, w)\n",
        "\n",
        "\n",
        "    # 活性化関数の種類も変えて実験しよう！\n",
        "    # z = sigmoid(a)\n",
        "    # z = ReLU(a)\n",
        "    # z = tanh(a)\n",
        "\n",
        "    activations[i] = z\n",
        "\n",
        "# ヒストグラムを描画\n",
        "for i, a in activations.items():\n",
        "    plt.subplot(1, len(activations), i+1)\n",
        "    plt.title(str(i+1) + \"-layer\")\n",
        "    if i != 0: plt.yticks([], [])\n",
        "    # plt.xlim(0.1, 1)\n",
        "    # plt.ylim(0, 7000)\n",
        "    plt.hist(a.flatten(), 30, range=(0,1))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "la6GgAhSpzXT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "7f98ecac-915a-4ce8-9cc7-605e3a671435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# coding: utf-8\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mnist import load_mnist\n",
        "from util import smooth_curve\n",
        "from multi_layer_net import MultiLayerNet\n",
        "from optimizer import SGD\n",
        "\n",
        "\n",
        "# 0:MNISTデータの読み込み==========\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
        "\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 128\n",
        "max_iterations = 2000\n",
        "\n",
        "\n",
        "# 1:実験の設定==========\n",
        "weight_init_types = {'std=0.01': 0.01, 'Xavier': 'sigmoid', 'He': 'relu'} # 各活性化関数に適した初期値で比較\n",
        "optimizer = SGD(lr=0.01)\n",
        "\n",
        "networks = {}\n",
        "train_loss = {}\n",
        "for key, weight_type in weight_init_types.items():\n",
        "    # ネットワークを設計。初期重みも。\n",
        "    networks[key] = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100],\n",
        "                                  output_size=10, weight_init_std=weight_type)\n",
        "    train_loss[key] = []\n",
        "\n",
        "\n",
        "# 2:訓練の開始==========\n",
        "for i in range(max_iterations):\n",
        "    # データをバッチ抽出\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "    \n",
        "    # 学習=勾配を更新(今回はSGDで。設計したネットワークで推定、損失関数求める、そのときの勾配求める、重みとバイアスをそれぞれ更新・保持→次のバッチデータでまた以上を繰り返す)\n",
        "    for key in weight_init_types.keys():\n",
        "        grads = networks[key].gradient(x_batch, t_batch)\n",
        "        optimizer.update(networks[key].params, grads)\n",
        "    \n",
        "        loss = networks[key].loss(x_batch, t_batch)\n",
        "        train_loss[key].append(loss)\n",
        "    \n",
        "    if i % 100 == 0:\n",
        "        print(\"===========\" + \"iteration:\" + str(i) + \"===========\")\n",
        "        for key in weight_init_types.keys():\n",
        "            loss = networks[key].loss(x_batch, t_batch)\n",
        "            print(key + \":\" + str(loss))\n",
        "\n",
        "\n",
        "# 3.グラフの描画==========\n",
        "markers = {'std=0.01': 'o', 'Xavier': 's', 'He': 'D'}\n",
        "x = np.arange(max_iterations)\n",
        "for key in weight_init_types.keys():\n",
        "    plt.plot(x, smooth_curve(train_loss[key]), marker=markers[key], markevery=100, label=key)\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.ylim(0, 2.5)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qU2et9CZpzZe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf4885c0-00b9-4b06-f23c-3918fb90bff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========iteration:0===========\n",
            "std=0.01:2.3025005890136723\n",
            "Xavier:2.28742035246983\n",
            "He:2.3288600647714706\n",
            "===========iteration:100===========\n",
            "std=0.01:2.301475564103388\n",
            "Xavier:2.185037668321559\n",
            "He:1.739104611108643\n",
            "===========iteration:200===========\n",
            "std=0.01:2.3013739544559133\n",
            "Xavier:1.9097629031644594\n",
            "He:0.8995152383168162\n",
            "===========iteration:300===========\n",
            "std=0.01:2.3023715634107624\n",
            "Xavier:1.3425770589617398\n",
            "He:0.5161416070837579\n",
            "===========iteration:400===========\n",
            "std=0.01:2.3027156416166488\n",
            "Xavier:0.9853394198263553\n",
            "He:0.4382876292989888\n",
            "===========iteration:500===========\n",
            "std=0.01:2.2957913993875545\n",
            "Xavier:0.6731117550204038\n",
            "He:0.41579164103323585\n",
            "===========iteration:600===========\n",
            "std=0.01:2.29823434263707\n",
            "Xavier:0.5121939318714686\n",
            "He:0.29519260835076305\n",
            "===========iteration:700===========\n",
            "std=0.01:2.3006963662892104\n",
            "Xavier:0.4696521275892075\n",
            "He:0.3048692769277434\n",
            "===========iteration:800===========\n",
            "std=0.01:2.3068827156384275\n",
            "Xavier:0.4809886128854871\n",
            "He:0.31197418435138036\n",
            "===========iteration:900===========\n",
            "std=0.01:2.302704567329788\n",
            "Xavier:0.42088742027432346\n",
            "He:0.2717161291218467\n",
            "===========iteration:1000===========\n",
            "std=0.01:2.296311688791238\n",
            "Xavier:0.49931238369432734\n",
            "He:0.35884504171379866\n",
            "===========iteration:1100===========\n",
            "std=0.01:2.3050172269211164\n",
            "Xavier:0.27657463704605606\n",
            "He:0.199756680381508\n",
            "===========iteration:1200===========\n",
            "std=0.01:2.305460833814311\n",
            "Xavier:0.353904691137652\n",
            "He:0.298309733454171\n",
            "===========iteration:1300===========\n",
            "std=0.01:2.3077903993226667\n",
            "Xavier:0.4026375357061777\n",
            "He:0.3116290772358413\n",
            "===========iteration:1400===========\n",
            "std=0.01:2.300729488643271\n",
            "Xavier:0.3332666393250055\n",
            "He:0.22146005269600214\n",
            "===========iteration:1500===========\n",
            "std=0.01:2.2930041124007445\n",
            "Xavier:0.22730770075865578\n",
            "He:0.1499769499734721\n",
            "===========iteration:1600===========\n",
            "std=0.01:2.3036437300173125\n",
            "Xavier:0.30751199138304397\n",
            "He:0.19859274270256264\n",
            "===========iteration:1700===========\n",
            "std=0.01:2.3017206259840624\n",
            "Xavier:0.2591856200249683\n",
            "He:0.19577451293732506\n",
            "===========iteration:1800===========\n",
            "std=0.01:2.297622551722333\n",
            "Xavier:0.26513902827469776\n",
            "He:0.20929705820894207\n",
            "===========iteration:1900===========\n",
            "std=0.01:2.297170223399121\n",
            "Xavier:0.24582541568769214\n",
            "He:0.15869527234200284\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch normalizationの計算グラフの説明\n",
        "\n",
        "https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html"
      ],
      "metadata": {
        "id": "RWEb_qW6FX2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "活性化関数の前後どちらに挿入するべきかの文献\n",
        "https://arxiv.org/abs/1502.03167\n",
        "\n",
        "https://arxiv.org/abs/1511.06422"
      ],
      "metadata": {
        "id": "WfffETnkZUQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coding: utf-8\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mnist import load_mnist\n",
        "from multi_layer_net_extend import MultiLayerNetExtend\n",
        "from optimizer import SGD, Adam\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
        "\n",
        "# 学習データを削減\n",
        "x_train = x_train[:1000]\n",
        "t_train = t_train[:1000]\n",
        "\n",
        "max_epochs = 20\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "\n",
        "def __train(weight_init_std):\n",
        "    # batch normalization有り無しのネットワークを生成しておく\n",
        "    bn_network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100], output_size=10, \n",
        "                                    weight_init_std=weight_init_std, use_batchnorm=True)\n",
        "    network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100], output_size=10,\n",
        "                                weight_init_std=weight_init_std)\n",
        "    \n",
        "    optimizer = SGD(lr=learning_rate)\n",
        "    \n",
        "\n",
        "    train_acc_list = []\n",
        "    bn_train_acc_list = []\n",
        "    \n",
        "\n",
        "    iter_per_epoch = max(train_size / batch_size, 1)\n",
        "    epoch_cnt = 0\n",
        "    \n",
        "    for i in range(1000000000):\n",
        "\n",
        "        # バッチデータ抽出\n",
        "        batch_mask = np.random.choice(train_size, batch_size)\n",
        "        x_batch = x_train[batch_mask]\n",
        "        t_batch = t_train[batch_mask]\n",
        "\n",
        "        # 学習フェーズ＝勾配計算(重みパラメータ、バイアスに対する損失関数の微分)→重みパラメータ、バイアス更新。\n",
        "        for _network in (bn_network, network):\n",
        "            grads = _network.gradient(x_batch, t_batch)\n",
        "            optimizer.update(_network.params, grads)\n",
        "    \n",
        "        if i % iter_per_epoch == 0:\n",
        "            train_acc = network.accuracy(x_train, t_train)\n",
        "            bn_train_acc = bn_network.accuracy(x_train, t_train)\n",
        "            train_acc_list.append(train_acc)\n",
        "            bn_train_acc_list.append(bn_train_acc)\n",
        "    \n",
        "            print(\"epoch:\" + str(epoch_cnt) + \" | \" + str(train_acc) + \" - \" + str(bn_train_acc))\n",
        "    \n",
        "            epoch_cnt += 1\n",
        "            if epoch_cnt >= max_epochs:\n",
        "                break\n",
        "                \n",
        "    return train_acc_list, bn_train_acc_list\n",
        "\n",
        "\n",
        "# 3.グラフの描画==========\n",
        "weight_scale_list = np.logspace(0, -4, num=16)\n",
        "x = np.arange(max_epochs)\n",
        "\n",
        "for i, w in enumerate(weight_scale_list):\n",
        "    print( \"============== \" + str(i+1) + \"/16\" + \" ==============\")\n",
        "    train_acc_list, bn_train_acc_list = __train(w)\n",
        "    \n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.title(\"W:\" + str(w))\n",
        "    if i == 15:\n",
        "        plt.plot(x, bn_train_acc_list, label='Batch Normalization', markevery=2)\n",
        "        plt.plot(x, train_acc_list, linestyle = \"--\", label='Normal(without BatchNorm)', markevery=2)\n",
        "    else:\n",
        "        plt.plot(x, bn_train_acc_list, markevery=2)\n",
        "        plt.plot(x, train_acc_list, linestyle=\"--\", markevery=2)\n",
        "\n",
        "    plt.ylim(0, 1.0)\n",
        "    if i % 4:\n",
        "        plt.yticks([])\n",
        "    else:\n",
        "        plt.ylabel(\"accuracy\")\n",
        "    if i < 12:\n",
        "        plt.xticks([])\n",
        "    else:\n",
        "        plt.xlabel(\"epochs\")\n",
        "    plt.legend(loc='lower right')\n",
        "    \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PMRCRV1YpzcF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b93e8a43-20d3-4098-c6bb-5f479aa1848b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============== 1/16 ==============\n",
            "epoch:0 | 0.097 - 0.122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/ゼロからつくるディープラーニング/common/multi_layer_net_extend.py:101: RuntimeWarning: overflow encountered in square\n",
            "  weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2)\n",
            "/content/drive/MyDrive/ゼロからつくるディープラーニング/common/multi_layer_net_extend.py:101: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1 | 0.097 - 0.136\n",
            "epoch:2 | 0.097 - 0.14\n",
            "epoch:3 | 0.097 - 0.158\n",
            "epoch:4 | 0.097 - 0.189\n",
            "epoch:5 | 0.097 - 0.201\n",
            "epoch:6 | 0.097 - 0.231\n",
            "epoch:7 | 0.097 - 0.254\n",
            "epoch:8 | 0.097 - 0.269\n",
            "epoch:9 | 0.097 - 0.287\n",
            "epoch:10 | 0.097 - 0.316\n",
            "epoch:11 | 0.097 - 0.338\n",
            "epoch:12 | 0.097 - 0.349\n",
            "epoch:13 | 0.097 - 0.369\n",
            "epoch:14 | 0.097 - 0.387\n",
            "epoch:15 | 0.097 - 0.398\n",
            "epoch:16 | 0.097 - 0.41\n",
            "epoch:17 | 0.097 - 0.44\n",
            "epoch:18 | 0.097 - 0.446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:19 | 0.097 - 0.456\n",
            "============== 2/16 ==============\n",
            "epoch:0 | 0.094 - 0.07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/ゼロからつくるディープラーニング/common/multi_layer_net_extend.py:101: RuntimeWarning: overflow encountered in square\n",
            "  weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2)\n",
            "/content/drive/MyDrive/ゼロからつくるディープラーニング/common/multi_layer_net_extend.py:101: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1 | 0.097 - 0.079\n",
            "epoch:2 | 0.097 - 0.114\n",
            "epoch:3 | 0.097 - 0.129\n",
            "epoch:4 | 0.097 - 0.158\n",
            "epoch:5 | 0.097 - 0.183\n",
            "epoch:6 | 0.097 - 0.221\n",
            "epoch:7 | 0.097 - 0.253\n",
            "epoch:8 | 0.097 - 0.275\n",
            "epoch:9 | 0.097 - 0.302\n",
            "epoch:10 | 0.097 - 0.312\n",
            "epoch:11 | 0.097 - 0.337\n",
            "epoch:12 | 0.097 - 0.368\n",
            "epoch:13 | 0.097 - 0.374\n",
            "epoch:14 | 0.097 - 0.406\n",
            "epoch:15 | 0.097 - 0.416\n",
            "epoch:16 | 0.097 - 0.436\n",
            "epoch:17 | 0.097 - 0.455\n",
            "epoch:18 | 0.097 - 0.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:19 | 0.097 - 0.492\n",
            "============== 3/16 ==============\n",
            "epoch:0 | 0.168 - 0.171\n",
            "epoch:1 | 0.368 - 0.159\n",
            "epoch:2 | 0.501 - 0.184\n",
            "epoch:3 | 0.59 - 0.228\n",
            "epoch:4 | 0.652 - 0.261\n",
            "epoch:5 | 0.697 - 0.297\n",
            "epoch:6 | 0.756 - 0.334\n",
            "epoch:7 | 0.813 - 0.36\n",
            "epoch:8 | 0.848 - 0.401\n",
            "epoch:9 | 0.882 - 0.441\n",
            "epoch:10 | 0.878 - 0.468\n",
            "epoch:11 | 0.915 - 0.491\n",
            "epoch:12 | 0.934 - 0.51\n",
            "epoch:13 | 0.942 - 0.532\n",
            "epoch:14 | 0.949 - 0.56\n",
            "epoch:15 | 0.958 - 0.588\n",
            "epoch:16 | 0.964 - 0.609\n",
            "epoch:17 | 0.966 - 0.622\n",
            "epoch:18 | 0.968 - 0.638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:19 | 0.973 - 0.657\n",
            "============== 4/16 ==============\n",
            "epoch:0 | 0.128 - 0.089\n",
            "epoch:1 | 0.293 - 0.109\n",
            "epoch:2 | 0.435 - 0.213\n",
            "epoch:3 | 0.528 - 0.307\n",
            "epoch:4 | 0.576 - 0.357\n",
            "epoch:5 | 0.656 - 0.425\n",
            "epoch:6 | 0.676 - 0.485\n",
            "epoch:7 | 0.722 - 0.527\n",
            "epoch:8 | 0.739 - 0.573\n",
            "epoch:9 | 0.759 - 0.596\n",
            "epoch:10 | 0.784 - 0.626\n",
            "epoch:11 | 0.796 - 0.657\n",
            "epoch:12 | 0.803 - 0.681\n",
            "epoch:13 | 0.821 - 0.697\n",
            "epoch:14 | 0.816 - 0.72\n",
            "epoch:15 | 0.834 - 0.734\n",
            "epoch:16 | 0.842 - 0.75\n",
            "epoch:17 | 0.854 - 0.766\n",
            "epoch:18 | 0.854 - 0.784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:19 | 0.876 - 0.796\n",
            "============== 5/16 ==============\n",
            "epoch:0 | 0.117 - 0.078\n",
            "epoch:1 | 0.124 - 0.115\n",
            "epoch:2 | 0.128 - 0.221\n",
            "epoch:3 | 0.135 - 0.345\n",
            "epoch:4 | 0.138 - 0.44\n",
            "epoch:5 | 0.142 - 0.531\n",
            "epoch:6 | 0.164 - 0.585\n",
            "epoch:7 | 0.179 - 0.638\n",
            "epoch:8 | 0.193 - 0.685\n",
            "epoch:9 | 0.207 - 0.723\n",
            "epoch:10 | 0.215 - 0.748\n",
            "epoch:11 | 0.239 - 0.774\n",
            "epoch:12 | 0.257 - 0.801\n",
            "epoch:13 | 0.259 - 0.82\n",
            "epoch:14 | 0.268 - 0.831\n",
            "epoch:15 | 0.271 - 0.842\n",
            "epoch:16 | 0.28 - 0.858\n",
            "epoch:17 | 0.288 - 0.866\n",
            "epoch:18 | 0.302 - 0.885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:19 | 0.314 - 0.887\n",
            "============== 6/16 ==============\n",
            "epoch:0 | 0.102 - 0.091\n",
            "epoch:1 | 0.124 - 0.216\n",
            "epoch:2 | 0.124 - 0.4\n",
            "epoch:3 | 0.161 - 0.54\n",
            "epoch:4 | 0.142 - 0.63\n",
            "epoch:5 | 0.117 - 0.689\n",
            "epoch:6 | 0.118 - 0.75\n",
            "epoch:7 | 0.117 - 0.772\n",
            "epoch:8 | 0.117 - 0.817\n",
            "epoch:9 | 0.162 - 0.833\n",
            "epoch:10 | 0.137 - 0.849\n",
            "epoch:11 | 0.13 - 0.876\n",
            "epoch:12 | 0.165 - 0.885\n",
            "epoch:13 | 0.149 - 0.897\n",
            "epoch:14 | 0.157 - 0.914\n",
            "epoch:15 | 0.181 - 0.914\n",
            "epoch:16 | 0.154 - 0.93\n",
            "epoch:17 | 0.12 - 0.936\n",
            "epoch:18 | 0.119 - 0.949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:19 | 0.117 - 0.955\n",
            "============== 7/16 ==============\n",
            "epoch:0 | 0.119 - 0.091\n",
            "epoch:1 | 0.115 - 0.334\n",
            "epoch:2 | 0.116 - 0.575\n",
            "epoch:3 | 0.117 - 0.697\n",
            "epoch:4 | 0.117 - 0.743\n",
            "epoch:5 | 0.117 - 0.793\n",
            "epoch:6 | 0.117 - 0.822\n",
            "epoch:7 | 0.117 - 0.863\n",
            "epoch:8 | 0.117 - 0.879\n",
            "epoch:9 | 0.117 - 0.898\n",
            "epoch:10 | 0.117 - 0.919\n",
            "epoch:11 | 0.117 - 0.941\n",
            "epoch:12 | 0.117 - 0.952\n",
            "epoch:13 | 0.121 - 0.963\n",
            "epoch:14 | 0.116 - 0.969\n",
            "epoch:15 | 0.16 - 0.975\n",
            "epoch:16 | 0.117 - 0.981\n",
            "epoch:17 | 0.117 - 0.986\n",
            "epoch:18 | 0.117 - 0.987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:19 | 0.117 - 0.991\n",
            "============== 8/16 ==============\n",
            "epoch:0 | 0.1 - 0.14\n",
            "epoch:1 | 0.117 - 0.505\n",
            "epoch:2 | 0.117 - 0.62\n",
            "epoch:3 | 0.117 - 0.737\n",
            "epoch:4 | 0.117 - 0.811\n",
            "epoch:5 | 0.117 - 0.878\n",
            "epoch:6 | 0.117 - 0.932\n",
            "epoch:7 | 0.116 - 0.95\n",
            "epoch:8 | 0.117 - 0.957\n",
            "epoch:9 | 0.117 - 0.977\n",
            "epoch:10 | 0.116 - 0.979\n",
            "epoch:11 | 0.116 - 0.985\n",
            "epoch:12 | 0.116 - 0.991\n",
            "epoch:13 | 0.117 - 0.993\n",
            "epoch:14 | 0.116 - 0.995\n",
            "epoch:15 | 0.117 - 0.996\n",
            "epoch:16 | 0.117 - 0.997\n",
            "epoch:17 | 0.117 - 0.997\n",
            "epoch:18 | 0.117 - 0.997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:19 | 0.117 - 0.998\n",
            "============== 9/16 ==============\n",
            "epoch:0 | 0.097 - 0.172\n",
            "epoch:1 | 0.117 - 0.505\n",
            "epoch:2 | 0.117 - 0.715\n",
            "epoch:3 | 0.117 - 0.827\n",
            "epoch:4 | 0.117 - 0.879\n",
            "epoch:5 | 0.117 - 0.931\n",
            "epoch:6 | 0.117 - 0.968\n",
            "epoch:7 | 0.117 - 0.976\n",
            "epoch:8 | 0.117 - 0.979\n",
            "epoch:9 | 0.117 - 0.988\n",
            "epoch:10 | 0.117 - 0.992\n",
            "epoch:11 | 0.117 - 0.995\n",
            "epoch:12 | 0.117 - 0.996\n",
            "epoch:13 | 0.117 - 0.997\n",
            "epoch:14 | 0.117 - 0.997\n",
            "epoch:15 | 0.117 - 0.998\n",
            "epoch:16 | 0.117 - 0.998\n",
            "epoch:17 | 0.117 - 0.998\n",
            "epoch:18 | 0.117 - 0.998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:19 | 0.117 - 0.999\n",
            "============== 10/16 ==============\n",
            "epoch:0 | 0.116 - 0.092\n",
            "epoch:1 | 0.117 - 0.542\n",
            "epoch:2 | 0.117 - 0.699\n",
            "epoch:3 | 0.117 - 0.824\n",
            "epoch:4 | 0.117 - 0.92\n",
            "epoch:5 | 0.117 - 0.967\n",
            "epoch:6 | 0.117 - 0.963\n",
            "epoch:7 | 0.117 - 0.982\n",
            "epoch:8 | 0.117 - 0.985\n",
            "epoch:9 | 0.117 - 0.991\n",
            "epoch:10 | 0.117 - 0.999\n",
            "epoch:11 | 0.117 - 0.999\n",
            "epoch:12 | 0.117 - 0.999\n",
            "epoch:13 | 0.117 - 1.0\n",
            "epoch:14 | 0.117 - 1.0\n",
            "epoch:15 | 0.117 - 1.0\n",
            "epoch:16 | 0.117 - 1.0\n",
            "epoch:17 | 0.117 - 1.0\n",
            "epoch:18 | 0.117 - 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:19 | 0.117 - 1.0\n",
            "============== 11/16 ==============\n",
            "epoch:0 | 0.092 - 0.183\n",
            "epoch:1 | 0.117 - 0.538\n",
            "epoch:2 | 0.117 - 0.807\n",
            "epoch:3 | 0.117 - 0.793\n",
            "epoch:4 | 0.117 - 0.834\n",
            "epoch:5 | 0.116 - 0.839\n",
            "epoch:6 | 0.117 - 0.852\n",
            "epoch:7 | 0.117 - 0.876\n",
            "epoch:8 | 0.117 - 0.886\n",
            "epoch:9 | 0.117 - 0.875\n",
            "epoch:10 | 0.117 - 0.849\n",
            "epoch:11 | 0.117 - 0.895\n",
            "epoch:12 | 0.117 - 0.912\n",
            "epoch:13 | 0.117 - 0.978\n",
            "epoch:14 | 0.116 - 0.978\n",
            "epoch:15 | 0.116 - 0.987\n",
            "epoch:16 | 0.116 - 0.997\n",
            "epoch:17 | 0.116 - 0.997\n",
            "epoch:18 | 0.116 - 0.998\n",
            "epoch:19 | 0.116 - 0.999"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============== 12/16 ==============\n",
            "epoch:0 | 0.1 - 0.148\n",
            "epoch:1 | 0.117 - 0.546\n",
            "epoch:2 | 0.117 - 0.729\n",
            "epoch:3 | 0.117 - 0.637\n",
            "epoch:4 | 0.117 - 0.759\n",
            "epoch:5 | 0.116 - 0.84\n",
            "epoch:6 | 0.116 - 0.777\n",
            "epoch:7 | 0.116 - 0.826\n",
            "epoch:8 | 0.116 - 0.863\n",
            "epoch:9 | 0.116 - 0.869\n",
            "epoch:10 | 0.116 - 0.865\n",
            "epoch:11 | 0.116 - 0.875\n",
            "epoch:12 | 0.116 - 0.881\n",
            "epoch:13 | 0.116 - 0.885\n",
            "epoch:14 | 0.116 - 0.859\n",
            "epoch:15 | 0.116 - 0.887\n",
            "epoch:16 | 0.116 - 0.896\n",
            "epoch:17 | 0.116 - 0.897\n",
            "epoch:18 | 0.116 - 0.904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:19 | 0.116 - 0.82\n",
            "============== 13/16 ==============\n",
            "epoch:0 | 0.097 - 0.12\n",
            "epoch:1 | 0.1 - 0.51\n",
            "epoch:2 | 0.117 - 0.43\n",
            "epoch:3 | 0.117 - 0.574\n",
            "epoch:4 | 0.116 - 0.598\n",
            "epoch:5 | 0.116 - 0.603\n",
            "epoch:6 | 0.116 - 0.68\n",
            "epoch:7 | 0.116 - 0.686\n",
            "epoch:8 | 0.117 - 0.694\n",
            "epoch:9 | 0.117 - 0.701\n",
            "epoch:10 | 0.117 - 0.705\n",
            "epoch:11 | 0.117 - 0.7\n",
            "epoch:12 | 0.117 - 0.708\n",
            "epoch:13 | 0.117 - 0.791\n",
            "epoch:14 | 0.117 - 0.8\n",
            "epoch:15 | 0.117 - 0.801\n",
            "epoch:16 | 0.117 - 0.759\n",
            "epoch:17 | 0.117 - 0.804\n",
            "epoch:18 | 0.117 - 0.814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:19 | 0.117 - 0.84\n",
            "============== 14/16 ==============\n",
            "epoch:0 | 0.092 - 0.114\n",
            "epoch:1 | 0.116 - 0.365\n",
            "epoch:2 | 0.116 - 0.445\n",
            "epoch:3 | 0.116 - 0.462\n",
            "epoch:4 | 0.116 - 0.483\n",
            "epoch:5 | 0.116 - 0.496\n",
            "epoch:6 | 0.116 - 0.488\n",
            "epoch:7 | 0.116 - 0.497\n",
            "epoch:8 | 0.116 - 0.563\n",
            "epoch:9 | 0.116 - 0.591\n",
            "epoch:10 | 0.116 - 0.587\n",
            "epoch:11 | 0.116 - 0.594\n",
            "epoch:12 | 0.116 - 0.597\n",
            "epoch:13 | 0.116 - 0.596\n",
            "epoch:14 | 0.116 - 0.602\n",
            "epoch:15 | 0.117 - 0.601\n",
            "epoch:16 | 0.117 - 0.586\n",
            "epoch:17 | 0.117 - 0.602\n",
            "epoch:18 | 0.117 - 0.583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:19 | 0.116 - 0.598\n",
            "============== 15/16 ==============\n",
            "epoch:0 | 0.092 - 0.094\n",
            "epoch:1 | 0.116 - 0.359\n",
            "epoch:2 | 0.116 - 0.453\n",
            "epoch:3 | 0.117 - 0.469\n",
            "epoch:4 | 0.117 - 0.495\n",
            "epoch:5 | 0.117 - 0.484\n",
            "epoch:6 | 0.117 - 0.504\n",
            "epoch:7 | 0.117 - 0.504\n",
            "epoch:8 | 0.117 - 0.515\n",
            "epoch:9 | 0.117 - 0.52\n",
            "epoch:10 | 0.117 - 0.503\n",
            "epoch:11 | 0.117 - 0.52\n",
            "epoch:12 | 0.116 - 0.515\n",
            "epoch:13 | 0.116 - 0.521\n",
            "epoch:14 | 0.116 - 0.517\n",
            "epoch:15 | 0.116 - 0.483\n",
            "epoch:16 | 0.116 - 0.516\n",
            "epoch:17 | 0.116 - 0.523\n",
            "epoch:18 | 0.116 - 0.517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:19 | 0.116 - 0.521\n",
            "============== 16/16 ==============\n",
            "epoch:0 | 0.1 - 0.135\n",
            "epoch:1 | 0.116 - 0.212\n",
            "epoch:2 | 0.116 - 0.3\n",
            "epoch:3 | 0.116 - 0.282\n",
            "epoch:4 | 0.116 - 0.391\n",
            "epoch:5 | 0.116 - 0.41\n",
            "epoch:6 | 0.116 - 0.423\n",
            "epoch:7 | 0.116 - 0.421\n",
            "epoch:8 | 0.116 - 0.427\n",
            "epoch:9 | 0.116 - 0.423\n",
            "epoch:10 | 0.116 - 0.421\n",
            "epoch:11 | 0.117 - 0.425\n",
            "epoch:12 | 0.116 - 0.425\n",
            "epoch:13 | 0.116 - 0.429\n",
            "epoch:14 | 0.117 - 0.433\n",
            "epoch:15 | 0.117 - 0.427\n",
            "epoch:16 | 0.117 - 0.38\n",
            "epoch:17 | 0.117 - 0.424\n",
            "epoch:18 | 0.117 - 0.423\n",
            "epoch:19 | 0.117 - 0.419\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "過学習の確認\n",
        "・レイヤを多く（＝パラメータが多くなり、表現力上がる）\n",
        "・訓練データ少なく\n",
        "\"\"\"\n",
        "# coding: utf-8\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from common.multi_layer_net import MultiLayerNet\n",
        "from common.optimizer import SGD\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
        "\n",
        "# 過学習を再現するために、学習データを削減\n",
        "x_train = x_train[:300]\n",
        "t_train = t_train[:300]\n",
        "\n",
        "# weight decay（荷重減衰）の設定 =======================\n",
        "weight_decay_lambda = 0 # weight decayを使用しない場合\n",
        "#weight_decay_lambda = 0.1\n",
        "# ====================================================\n",
        "\n",
        "network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10,\n",
        "                        weight_decay_lambda=weight_decay_lambda)\n",
        "optimizer = SGD(lr=0.01)\n",
        "\n",
        "max_epochs = 201\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "epoch_cnt = 0\n",
        "\n",
        "for i in range(1000000000):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    grads = network.gradient(x_batch, t_batch)\n",
        "    optimizer.update(network.params, grads)\n",
        "\n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "\n",
        "        print(\"epoch:\" + str(epoch_cnt) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc))\n",
        "\n",
        "        epoch_cnt += 1\n",
        "        if epoch_cnt >= max_epochs:\n",
        "            break\n",
        "\n",
        "\n",
        "# 3.グラフの描画==========\n",
        "markers = {'train': 'o', 'test': 's'}\n",
        "x = np.arange(max_epochs)\n",
        "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
        "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kxeuBln9pzeV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61e43436-89c8-4819-fb19-64a04a2a8018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:0, train acc:0.11333333333333333, test acc:0.103\n",
            "epoch:1, train acc:0.11666666666666667, test acc:0.1109\n",
            "epoch:2, train acc:0.13, test acc:0.1307\n",
            "epoch:3, train acc:0.16, test acc:0.1587\n",
            "epoch:4, train acc:0.20333333333333334, test acc:0.1853\n",
            "epoch:5, train acc:0.24666666666666667, test acc:0.1987\n",
            "epoch:6, train acc:0.29, test acc:0.2228\n",
            "epoch:7, train acc:0.33, test acc:0.2443\n",
            "epoch:8, train acc:0.35333333333333333, test acc:0.2768\n",
            "epoch:9, train acc:0.39666666666666667, test acc:0.299\n",
            "epoch:10, train acc:0.44666666666666666, test acc:0.3262\n",
            "epoch:11, train acc:0.5, test acc:0.3606\n",
            "epoch:12, train acc:0.5333333333333333, test acc:0.3863\n",
            "epoch:13, train acc:0.5966666666666667, test acc:0.4184\n",
            "epoch:14, train acc:0.6, test acc:0.4337\n",
            "epoch:15, train acc:0.6366666666666667, test acc:0.4581\n",
            "epoch:16, train acc:0.6433333333333333, test acc:0.473\n",
            "epoch:17, train acc:0.66, test acc:0.4757\n",
            "epoch:18, train acc:0.6633333333333333, test acc:0.4976\n",
            "epoch:19, train acc:0.6633333333333333, test acc:0.4996\n",
            "epoch:20, train acc:0.68, test acc:0.5103\n",
            "epoch:21, train acc:0.67, test acc:0.5169\n",
            "epoch:22, train acc:0.7, test acc:0.5244\n",
            "epoch:23, train acc:0.6866666666666666, test acc:0.5237\n",
            "epoch:24, train acc:0.7066666666666667, test acc:0.5494\n",
            "epoch:25, train acc:0.7133333333333334, test acc:0.5529\n",
            "epoch:26, train acc:0.7466666666666667, test acc:0.5787\n",
            "epoch:27, train acc:0.7366666666666667, test acc:0.5965\n",
            "epoch:28, train acc:0.76, test acc:0.5925\n",
            "epoch:29, train acc:0.7466666666666667, test acc:0.5757\n",
            "epoch:30, train acc:0.76, test acc:0.6044\n",
            "epoch:31, train acc:0.7633333333333333, test acc:0.5976\n",
            "epoch:32, train acc:0.7933333333333333, test acc:0.597\n",
            "epoch:33, train acc:0.81, test acc:0.6296\n",
            "epoch:34, train acc:0.7966666666666666, test acc:0.6245\n",
            "epoch:35, train acc:0.8266666666666667, test acc:0.6282\n",
            "epoch:36, train acc:0.8366666666666667, test acc:0.6469\n",
            "epoch:37, train acc:0.8366666666666667, test acc:0.658\n",
            "epoch:38, train acc:0.8366666666666667, test acc:0.6348\n",
            "epoch:39, train acc:0.8633333333333333, test acc:0.6595\n",
            "epoch:40, train acc:0.8633333333333333, test acc:0.6522\n",
            "epoch:41, train acc:0.8566666666666667, test acc:0.6592\n",
            "epoch:42, train acc:0.85, test acc:0.6671\n",
            "epoch:43, train acc:0.8733333333333333, test acc:0.6778\n",
            "epoch:44, train acc:0.87, test acc:0.6834\n",
            "epoch:45, train acc:0.8933333333333333, test acc:0.6959\n",
            "epoch:46, train acc:0.87, test acc:0.6863\n",
            "epoch:47, train acc:0.87, test acc:0.6855\n",
            "epoch:48, train acc:0.89, test acc:0.6895\n",
            "epoch:49, train acc:0.8966666666666666, test acc:0.6807\n",
            "epoch:50, train acc:0.9, test acc:0.7019\n",
            "epoch:51, train acc:0.91, test acc:0.7037\n",
            "epoch:52, train acc:0.9233333333333333, test acc:0.708\n",
            "epoch:53, train acc:0.9266666666666666, test acc:0.7031\n",
            "epoch:54, train acc:0.9166666666666666, test acc:0.7028\n",
            "epoch:55, train acc:0.9366666666666666, test acc:0.7182\n",
            "epoch:56, train acc:0.94, test acc:0.6995\n",
            "epoch:57, train acc:0.9333333333333333, test acc:0.706\n",
            "epoch:58, train acc:0.9466666666666667, test acc:0.7226\n",
            "epoch:59, train acc:0.9433333333333334, test acc:0.7209\n",
            "epoch:60, train acc:0.95, test acc:0.7186\n",
            "epoch:61, train acc:0.96, test acc:0.7298\n",
            "epoch:62, train acc:0.9633333333333334, test acc:0.7182\n",
            "epoch:63, train acc:0.9633333333333334, test acc:0.7262\n",
            "epoch:64, train acc:0.97, test acc:0.7262\n",
            "epoch:65, train acc:0.9633333333333334, test acc:0.7251\n",
            "epoch:66, train acc:0.9633333333333334, test acc:0.7254\n",
            "epoch:67, train acc:0.96, test acc:0.7355\n",
            "epoch:68, train acc:0.97, test acc:0.7286\n",
            "epoch:69, train acc:0.96, test acc:0.734\n",
            "epoch:70, train acc:0.97, test acc:0.7384\n",
            "epoch:71, train acc:0.9666666666666667, test acc:0.7308\n",
            "epoch:72, train acc:0.97, test acc:0.7331\n",
            "epoch:73, train acc:0.9733333333333334, test acc:0.731\n",
            "epoch:74, train acc:0.9633333333333334, test acc:0.7399\n",
            "epoch:75, train acc:0.9733333333333334, test acc:0.7437\n",
            "epoch:76, train acc:0.9766666666666667, test acc:0.7444\n",
            "epoch:77, train acc:0.9766666666666667, test acc:0.7463\n",
            "epoch:78, train acc:0.9766666666666667, test acc:0.7457\n",
            "epoch:79, train acc:0.9733333333333334, test acc:0.7449\n",
            "epoch:80, train acc:0.9766666666666667, test acc:0.7457\n",
            "epoch:81, train acc:0.9766666666666667, test acc:0.7455\n",
            "epoch:82, train acc:0.98, test acc:0.7463\n",
            "epoch:83, train acc:0.9833333333333333, test acc:0.7413\n",
            "epoch:84, train acc:0.9833333333333333, test acc:0.7411\n",
            "epoch:85, train acc:0.9866666666666667, test acc:0.7441\n",
            "epoch:86, train acc:0.99, test acc:0.7496\n",
            "epoch:87, train acc:0.9866666666666667, test acc:0.7489\n",
            "epoch:88, train acc:0.98, test acc:0.7529\n",
            "epoch:89, train acc:0.9766666666666667, test acc:0.7527\n",
            "epoch:90, train acc:0.98, test acc:0.752\n",
            "epoch:91, train acc:0.9866666666666667, test acc:0.7517\n",
            "epoch:92, train acc:0.9866666666666667, test acc:0.7538\n",
            "epoch:93, train acc:0.9866666666666667, test acc:0.75\n",
            "epoch:94, train acc:0.9866666666666667, test acc:0.7514\n",
            "epoch:95, train acc:0.9866666666666667, test acc:0.7447\n",
            "epoch:96, train acc:0.9866666666666667, test acc:0.7515\n",
            "epoch:97, train acc:0.9933333333333333, test acc:0.7516\n",
            "epoch:98, train acc:0.99, test acc:0.7552\n",
            "epoch:99, train acc:0.9933333333333333, test acc:0.7505\n",
            "epoch:100, train acc:0.9933333333333333, test acc:0.7498\n",
            "epoch:101, train acc:0.9933333333333333, test acc:0.7548\n",
            "epoch:102, train acc:0.9933333333333333, test acc:0.7545\n",
            "epoch:103, train acc:0.9966666666666667, test acc:0.7518\n",
            "epoch:104, train acc:0.9933333333333333, test acc:0.7551\n",
            "epoch:105, train acc:0.9933333333333333, test acc:0.7537\n",
            "epoch:106, train acc:0.9966666666666667, test acc:0.7546\n",
            "epoch:107, train acc:0.9966666666666667, test acc:0.7555\n",
            "epoch:108, train acc:0.9966666666666667, test acc:0.7532\n",
            "epoch:109, train acc:0.9933333333333333, test acc:0.7504\n",
            "epoch:110, train acc:0.9966666666666667, test acc:0.754\n",
            "epoch:111, train acc:1.0, test acc:0.7602\n",
            "epoch:112, train acc:0.9933333333333333, test acc:0.7575\n",
            "epoch:113, train acc:0.9966666666666667, test acc:0.7564\n",
            "epoch:114, train acc:0.9966666666666667, test acc:0.7544\n",
            "epoch:115, train acc:0.9966666666666667, test acc:0.7554\n",
            "epoch:116, train acc:1.0, test acc:0.7602\n",
            "epoch:117, train acc:0.9966666666666667, test acc:0.7571\n",
            "epoch:118, train acc:0.9966666666666667, test acc:0.7581\n",
            "epoch:119, train acc:1.0, test acc:0.7568\n",
            "epoch:120, train acc:1.0, test acc:0.7569\n",
            "epoch:121, train acc:1.0, test acc:0.7562\n",
            "epoch:122, train acc:1.0, test acc:0.7578\n",
            "epoch:123, train acc:1.0, test acc:0.7576\n",
            "epoch:124, train acc:1.0, test acc:0.7591\n",
            "epoch:125, train acc:1.0, test acc:0.7581\n",
            "epoch:126, train acc:1.0, test acc:0.7571\n",
            "epoch:127, train acc:1.0, test acc:0.7597\n",
            "epoch:128, train acc:1.0, test acc:0.7622\n",
            "epoch:129, train acc:1.0, test acc:0.761\n",
            "epoch:130, train acc:1.0, test acc:0.7569\n",
            "epoch:131, train acc:1.0, test acc:0.7565\n",
            "epoch:132, train acc:1.0, test acc:0.7555\n",
            "epoch:133, train acc:1.0, test acc:0.7585\n",
            "epoch:134, train acc:1.0, test acc:0.7583\n",
            "epoch:135, train acc:1.0, test acc:0.7595\n",
            "epoch:136, train acc:1.0, test acc:0.7608\n",
            "epoch:137, train acc:1.0, test acc:0.759\n",
            "epoch:138, train acc:1.0, test acc:0.7559\n",
            "epoch:139, train acc:1.0, test acc:0.7592\n",
            "epoch:140, train acc:1.0, test acc:0.7605\n",
            "epoch:141, train acc:1.0, test acc:0.7617\n",
            "epoch:142, train acc:1.0, test acc:0.76\n",
            "epoch:143, train acc:1.0, test acc:0.759\n",
            "epoch:144, train acc:1.0, test acc:0.7633\n",
            "epoch:145, train acc:1.0, test acc:0.7639\n",
            "epoch:146, train acc:1.0, test acc:0.7635\n",
            "epoch:147, train acc:1.0, test acc:0.7598\n",
            "epoch:148, train acc:1.0, test acc:0.7599\n",
            "epoch:149, train acc:1.0, test acc:0.7627\n",
            "epoch:150, train acc:1.0, test acc:0.7618\n",
            "epoch:151, train acc:1.0, test acc:0.7617\n",
            "epoch:152, train acc:1.0, test acc:0.7614\n",
            "epoch:153, train acc:1.0, test acc:0.7623\n",
            "epoch:154, train acc:1.0, test acc:0.7617\n",
            "epoch:155, train acc:1.0, test acc:0.7634\n",
            "epoch:156, train acc:1.0, test acc:0.7633\n",
            "epoch:157, train acc:1.0, test acc:0.7602\n",
            "epoch:158, train acc:1.0, test acc:0.7633\n",
            "epoch:159, train acc:1.0, test acc:0.762\n",
            "epoch:160, train acc:1.0, test acc:0.7622\n",
            "epoch:161, train acc:1.0, test acc:0.7624\n",
            "epoch:162, train acc:1.0, test acc:0.763\n",
            "epoch:163, train acc:1.0, test acc:0.7621\n",
            "epoch:164, train acc:1.0, test acc:0.7619\n",
            "epoch:165, train acc:1.0, test acc:0.7622\n",
            "epoch:166, train acc:1.0, test acc:0.7619\n",
            "epoch:167, train acc:1.0, test acc:0.7627\n",
            "epoch:168, train acc:1.0, test acc:0.7631\n",
            "epoch:169, train acc:1.0, test acc:0.7633\n",
            "epoch:170, train acc:1.0, test acc:0.7617\n",
            "epoch:171, train acc:1.0, test acc:0.763\n",
            "epoch:172, train acc:1.0, test acc:0.7647\n",
            "epoch:173, train acc:1.0, test acc:0.7626\n",
            "epoch:174, train acc:1.0, test acc:0.7631\n",
            "epoch:175, train acc:1.0, test acc:0.7636\n",
            "epoch:176, train acc:1.0, test acc:0.764\n",
            "epoch:177, train acc:1.0, test acc:0.7634\n",
            "epoch:178, train acc:1.0, test acc:0.7653\n",
            "epoch:179, train acc:1.0, test acc:0.7642\n",
            "epoch:180, train acc:1.0, test acc:0.7653\n",
            "epoch:181, train acc:1.0, test acc:0.7646\n",
            "epoch:182, train acc:1.0, test acc:0.765\n",
            "epoch:183, train acc:1.0, test acc:0.7648\n",
            "epoch:184, train acc:1.0, test acc:0.7665\n",
            "epoch:185, train acc:1.0, test acc:0.7661\n",
            "epoch:186, train acc:1.0, test acc:0.7656\n",
            "epoch:187, train acc:1.0, test acc:0.7648\n",
            "epoch:188, train acc:1.0, test acc:0.7636\n",
            "epoch:189, train acc:1.0, test acc:0.7648\n",
            "epoch:190, train acc:1.0, test acc:0.7652\n",
            "epoch:191, train acc:1.0, test acc:0.7656\n",
            "epoch:192, train acc:1.0, test acc:0.7639\n",
            "epoch:193, train acc:1.0, test acc:0.7657\n",
            "epoch:194, train acc:1.0, test acc:0.765\n",
            "epoch:195, train acc:1.0, test acc:0.7653\n",
            "epoch:196, train acc:1.0, test acc:0.7653\n",
            "epoch:197, train acc:1.0, test acc:0.7655\n",
            "epoch:198, train acc:1.0, test acc:0.7648\n",
            "epoch:199, train acc:1.0, test acc:0.7668\n",
            "epoch:200, train acc:1.0, test acc:0.7666\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Dropoutレイヤの実装\n",
        "\"\"\"\n",
        "\n",
        "class Dropout:\n",
        "    \"\"\"\n",
        "    http://arxiv.org/abs/1207.0580\n",
        "    \"\"\"\n",
        "    def __init__(self, dropout_ratio=0.5):\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "        self.mask = None\n",
        "    \n",
        "\n",
        "    # 条件分岐なくても良さそうやけど？\n",
        "    def forward(self, x, train_flg=True):\n",
        "        if train_flg:\n",
        "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
        "            return x * self.mask\n",
        "        else:\n",
        "            return x * (1.0 - self.dropout_ratio)\n",
        "\n",
        "    def backward(self, dout):\n",
        "        return dout * self.mask"
      ],
      "metadata": {
        "id": "W4-rDXnvpzg9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coding: utf-8\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
        "from common.trainer import Trainer\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
        "\n",
        "# 過学習を再現するために、学習データを削減\n",
        "x_train = x_train[:1000]\n",
        "t_train = t_train[:1000]\n",
        "\n",
        "# Dropuoutの有無、割り合いの設定 ========================\n",
        "use_dropout = True  \n",
        "# Dropoutなしのときの場合はFalseに(test acc:0.8609) Trueでtest acc:0.8851\n",
        "# データ数が300では精度低かったため、ある程度のデータ量がないと有効でないのかも\n",
        "\n",
        "dropout_ratio = 0.2\n",
        "# ====================================================\n",
        "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
        "                              output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
        "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
        "\n",
        "                  epochs=601, mini_batch_size=100,\n",
        "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n",
        "trainer.train()\n",
        "\n",
        "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list\n",
        "\n",
        "# グラフの描画==========\n",
        "markers = {'train': 'o', 'test': 's'}\n",
        "x = np.arange(len(train_acc_list))\n",
        "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
        "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c_kQYuycpzqT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6d0f933-824e-4402-8068-88c930796f3d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "train loss:0.6747694217886924\n",
            "train loss:0.7121376102658473\n",
            "train loss:0.6864512611260287\n",
            "train loss:0.6300396544707814\n",
            "train loss:0.6231774596640357\n",
            "=== epoch:148, train acc:0.8, test acc:0.7339 ===\n",
            "train loss:0.8407558931863237\n",
            "train loss:0.8036859380603866\n",
            "train loss:0.8109791567523746\n",
            "train loss:0.7342173155144647\n",
            "train loss:0.8080377931695328\n",
            "train loss:0.7996035962694534\n",
            "train loss:0.8096076290124308\n",
            "train loss:0.6773202940575226\n",
            "train loss:0.7117805413872605\n",
            "train loss:0.8302376106704351\n",
            "=== epoch:149, train acc:0.804, test acc:0.7378 ===\n",
            "train loss:0.5653551653558582\n",
            "train loss:0.705050560538453\n",
            "train loss:0.7555044054170631\n",
            "train loss:0.5870638401424716\n",
            "train loss:0.7318423298393754\n",
            "train loss:0.8759437849384791\n",
            "train loss:0.8043707037004961\n",
            "train loss:0.7620354205722231\n",
            "train loss:0.6383554314278364\n",
            "train loss:0.8813204468446884\n",
            "=== epoch:150, train acc:0.78, test acc:0.7304 ===\n",
            "train loss:0.7557861764186107\n",
            "train loss:0.6960895808951263\n",
            "train loss:0.6548456058315708\n",
            "train loss:0.7941283657996778\n",
            "train loss:0.6900218113848333\n",
            "train loss:0.6205542846135462\n",
            "train loss:0.7009146915119219\n",
            "train loss:0.7099200336825301\n",
            "train loss:0.6928004662879605\n",
            "train loss:0.7758153638067786\n",
            "=== epoch:151, train acc:0.784, test acc:0.73 ===\n",
            "train loss:0.9032815624386685\n",
            "train loss:0.7327462178698246\n",
            "train loss:0.6820649546321476\n",
            "train loss:0.6252332858950284\n",
            "train loss:0.7151317549359991\n",
            "train loss:0.6935659724176179\n",
            "train loss:0.7069947306266379\n",
            "train loss:0.8013183350634935\n",
            "train loss:0.6471994243078757\n",
            "train loss:0.7543864398233712\n",
            "=== epoch:152, train acc:0.798, test acc:0.7388 ===\n",
            "train loss:0.6964925350181427\n",
            "train loss:0.8353354373033183\n",
            "train loss:0.6357719397116276\n",
            "train loss:0.6957891600385182\n",
            "train loss:0.7161076825289208\n",
            "train loss:0.7038275958257012\n",
            "train loss:0.7170483179972662\n",
            "train loss:0.7345048652735511\n",
            "train loss:0.7769951087919078\n",
            "train loss:0.6664176060078796\n",
            "=== epoch:153, train acc:0.796, test acc:0.7411 ===\n",
            "train loss:0.8763019030600083\n",
            "train loss:0.6814418438906352\n",
            "train loss:0.7275339181008456\n",
            "train loss:0.7816724764734854\n",
            "train loss:0.9252359864348684\n",
            "train loss:0.6691376261876785\n",
            "train loss:0.873413995321716\n",
            "train loss:0.6867254667573437\n",
            "train loss:0.6964824213316134\n",
            "train loss:0.7524752927502667\n",
            "=== epoch:154, train acc:0.807, test acc:0.7463 ===\n",
            "train loss:0.6405946573374451\n",
            "train loss:0.601502873529257\n",
            "train loss:0.7120490934265679\n",
            "train loss:0.5721082295484698\n",
            "train loss:0.6184964294109241\n",
            "train loss:0.7515478618933542\n",
            "train loss:0.6585445373383381\n",
            "train loss:0.7600675836356894\n",
            "train loss:0.6854868365894692\n",
            "train loss:0.7194425317973274\n",
            "=== epoch:155, train acc:0.794, test acc:0.7359 ===\n",
            "train loss:0.7116563001956746\n",
            "train loss:0.6535899710222715\n",
            "train loss:0.649225953114848\n",
            "train loss:0.6843959920228551\n",
            "train loss:0.7030379721342611\n",
            "train loss:0.7301264096359802\n",
            "train loss:0.6762501099182806\n",
            "train loss:0.7238772098961452\n",
            "train loss:0.628964436900424\n",
            "train loss:0.5035792074531897\n",
            "=== epoch:156, train acc:0.796, test acc:0.7383 ===\n",
            "train loss:0.5762700836986645\n",
            "train loss:0.741223773611415\n",
            "train loss:0.6479318769498916\n",
            "train loss:0.6420101207945288\n",
            "train loss:0.7126834073221512\n",
            "train loss:0.6014052092413893\n",
            "train loss:0.6425489651146418\n",
            "train loss:0.672091896520906\n",
            "train loss:0.6865326282923442\n",
            "train loss:0.6293581849828429\n",
            "=== epoch:157, train acc:0.803, test acc:0.748 ===\n",
            "train loss:0.7203215724557137\n",
            "train loss:0.6041913531495249\n",
            "train loss:0.6052454788610929\n",
            "train loss:0.8109149790151013\n",
            "train loss:0.6751777891375151\n",
            "train loss:0.6276891426189299\n",
            "train loss:0.7127226852472917\n",
            "train loss:0.7011587637320602\n",
            "train loss:0.6851647184969133\n",
            "train loss:0.6158399788463139\n",
            "=== epoch:158, train acc:0.809, test acc:0.7529 ===\n",
            "train loss:0.5419559414732534\n",
            "train loss:0.6289445620088854\n",
            "train loss:0.6182931946335735\n",
            "train loss:0.7297621297163229\n",
            "train loss:0.5838452340891932\n",
            "train loss:0.6010148245066209\n",
            "train loss:0.6336326326738644\n",
            "train loss:0.6041930785018222\n",
            "train loss:0.6951488206315491\n",
            "train loss:0.5004202435381362\n",
            "=== epoch:159, train acc:0.807, test acc:0.7454 ===\n",
            "train loss:0.6210519691106435\n",
            "train loss:0.6614921791143739\n",
            "train loss:0.5404346558942552\n",
            "train loss:0.5949023306470275\n",
            "train loss:0.7171844831957682\n",
            "train loss:0.5471063227430311\n",
            "train loss:0.6143345932185997\n",
            "train loss:0.48089084883242594\n",
            "train loss:0.6228245461827905\n",
            "train loss:0.7595307352492827\n",
            "=== epoch:160, train acc:0.815, test acc:0.7498 ===\n",
            "train loss:0.6730805394007797\n",
            "train loss:0.755515977671232\n",
            "train loss:0.5305131023506522\n",
            "train loss:0.6810936520651143\n",
            "train loss:0.49209251703805185\n",
            "train loss:0.6874235892137348\n",
            "train loss:0.5895118600763649\n",
            "train loss:0.6290207213672637\n",
            "train loss:0.7127276170323553\n",
            "train loss:0.7055611097379062\n",
            "=== epoch:161, train acc:0.815, test acc:0.7527 ===\n",
            "train loss:0.6630502761111521\n",
            "train loss:0.6109853597335537\n",
            "train loss:0.7219055601536201\n",
            "train loss:0.6101874562997645\n",
            "train loss:0.5996279395546288\n",
            "train loss:0.5654764273628221\n",
            "train loss:0.589338383673701\n",
            "train loss:0.854044480553689\n",
            "train loss:0.8349593135564126\n",
            "train loss:0.6467262689157649\n",
            "=== epoch:162, train acc:0.824, test acc:0.7646 ===\n",
            "train loss:0.6961998702741837\n",
            "train loss:0.6007391500216742\n",
            "train loss:0.6294798289330068\n",
            "train loss:0.5299901334767422\n",
            "train loss:0.6131894679920857\n",
            "train loss:0.6760626222799828\n",
            "train loss:0.6680544183158235\n",
            "train loss:0.641776940357592\n",
            "train loss:0.6308853460763978\n",
            "train loss:0.6343912294437112\n",
            "=== epoch:163, train acc:0.826, test acc:0.7673 ===\n",
            "train loss:0.6012067516437842\n",
            "train loss:0.7658799894511931\n",
            "train loss:0.6878904772337243\n",
            "train loss:0.6403470975660239\n",
            "train loss:0.5183719549623085\n",
            "train loss:0.574877533382055\n",
            "train loss:0.6642192056319606\n",
            "train loss:0.5767126620687582\n",
            "train loss:0.7306640780605711\n",
            "train loss:0.6356418370887069\n",
            "=== epoch:164, train acc:0.821, test acc:0.7616 ===\n",
            "train loss:0.5948046607201968\n",
            "train loss:0.6710470186535828\n",
            "train loss:0.6448055588510749\n",
            "train loss:0.6566509265986591\n",
            "train loss:0.5276156770346548\n",
            "train loss:0.6823255251236456\n",
            "train loss:0.4829839178696174\n",
            "train loss:0.6511196632404187\n",
            "train loss:0.5667389870147886\n",
            "train loss:0.6465402515902301\n",
            "=== epoch:165, train acc:0.829, test acc:0.768 ===\n",
            "train loss:0.5704829287228018\n",
            "train loss:0.5572738802205456\n",
            "train loss:0.7241796023175234\n",
            "train loss:0.5937780997509404\n",
            "train loss:0.5044841673432592\n",
            "train loss:0.5400681336236395\n",
            "train loss:0.6371634769363812\n",
            "train loss:0.51913313788513\n",
            "train loss:0.5465367544879411\n",
            "train loss:0.5615307456523749\n",
            "=== epoch:166, train acc:0.822, test acc:0.7663 ===\n",
            "train loss:0.5941786153295504\n",
            "train loss:0.6268723778736132\n",
            "train loss:0.5924116990148419\n",
            "train loss:0.48870265333815943\n",
            "train loss:0.5768338605411911\n",
            "train loss:0.6087855832144948\n",
            "train loss:0.6016803140845022\n",
            "train loss:0.563474511746164\n",
            "train loss:0.6801836468367047\n",
            "train loss:0.6381419613940709\n",
            "=== epoch:167, train acc:0.83, test acc:0.7707 ===\n",
            "train loss:0.6447723770769349\n",
            "train loss:0.7465858653041744\n",
            "train loss:0.5243299991419257\n",
            "train loss:0.650932695932869\n",
            "train loss:0.6185080940020895\n",
            "train loss:0.6377536195549012\n",
            "train loss:0.5268145944619187\n",
            "train loss:0.550464480609474\n",
            "train loss:0.497899870839678\n",
            "train loss:0.6102491314220843\n",
            "=== epoch:168, train acc:0.838, test acc:0.7739 ===\n",
            "train loss:0.5378954776741514\n",
            "train loss:0.6508438372122322\n",
            "train loss:0.603888237034967\n",
            "train loss:0.5550184188943372\n",
            "train loss:0.6903731534691663\n",
            "train loss:0.6488021440522347\n",
            "train loss:0.5764989121010765\n",
            "train loss:0.5710536260742134\n",
            "train loss:0.5130049371345331\n",
            "train loss:0.6965132927310219\n",
            "=== epoch:169, train acc:0.841, test acc:0.7749 ===\n",
            "train loss:0.6063466177404682\n",
            "train loss:0.6303229151261068\n",
            "train loss:0.5918965261780137\n",
            "train loss:0.5549684641433585\n",
            "train loss:0.55227486911661\n",
            "train loss:0.5053313461007704\n",
            "train loss:0.7103199211187088\n",
            "train loss:0.5490321317643531\n",
            "train loss:0.6595421671588924\n",
            "train loss:0.5524177974153495\n",
            "=== epoch:170, train acc:0.842, test acc:0.7701 ===\n",
            "train loss:0.5047507100290884\n",
            "train loss:0.47833083295886\n",
            "train loss:0.4464996700089746\n",
            "train loss:0.5033693910598177\n",
            "train loss:0.501770880822495\n",
            "train loss:0.500581392283407\n",
            "train loss:0.515715466862394\n",
            "train loss:0.5683226377723258\n",
            "train loss:0.5953786843442338\n",
            "train loss:0.5012498566729184\n",
            "=== epoch:171, train acc:0.829, test acc:0.7675 ===\n",
            "train loss:0.49857853573545613\n",
            "train loss:0.5874520832545879\n",
            "train loss:0.5835744064042647\n",
            "train loss:0.5153769333039402\n",
            "train loss:0.5223980996385373\n",
            "train loss:0.6095945744772268\n",
            "train loss:0.6118281838327764\n",
            "train loss:0.6036814345485114\n",
            "train loss:0.5674486594209504\n",
            "train loss:0.5664964320856618\n",
            "=== epoch:172, train acc:0.83, test acc:0.7713 ===\n",
            "train loss:0.5268226873130013\n",
            "train loss:0.6495525024864282\n",
            "train loss:0.6164087855836418\n",
            "train loss:0.6521124183991874\n",
            "train loss:0.5844994204042352\n",
            "train loss:0.4348516184978187\n",
            "train loss:0.5193804868572796\n",
            "train loss:0.7531214305987395\n",
            "train loss:0.6044763834214057\n",
            "train loss:0.6034862033459096\n",
            "=== epoch:173, train acc:0.844, test acc:0.7793 ===\n",
            "train loss:0.5326435608288846\n",
            "train loss:0.4232541986585934\n",
            "train loss:0.44589322755606564\n",
            "train loss:0.5225458645272657\n",
            "train loss:0.546462946205776\n",
            "train loss:0.5091520471126191\n",
            "train loss:0.548750834579713\n",
            "train loss:0.5005585104861514\n",
            "train loss:0.5578923623836146\n",
            "train loss:0.49405941089857713\n",
            "=== epoch:174, train acc:0.85, test acc:0.7806 ===\n",
            "train loss:0.5307678242835138\n",
            "train loss:0.531325088028806\n",
            "train loss:0.5738086801500565\n",
            "train loss:0.6490576038896129\n",
            "train loss:0.5435009028297678\n",
            "train loss:0.41075615735424575\n",
            "train loss:0.48208906444503397\n",
            "train loss:0.5444637860717867\n",
            "train loss:0.518876500526675\n",
            "train loss:0.4836619654489421\n",
            "=== epoch:175, train acc:0.846, test acc:0.7883 ===\n",
            "train loss:0.7177992113260743\n",
            "train loss:0.6515066509808212\n",
            "train loss:0.4471752516108154\n",
            "train loss:0.5049166503406197\n",
            "train loss:0.5427590688338135\n",
            "train loss:0.3631614468712763\n",
            "train loss:0.4932317741038256\n",
            "train loss:0.541216024665661\n",
            "train loss:0.48427729490356464\n",
            "train loss:0.629492104805145\n",
            "=== epoch:176, train acc:0.849, test acc:0.7875 ===\n",
            "train loss:0.5658896625290385\n",
            "train loss:0.5460271682861234\n",
            "train loss:0.48411981137519045\n",
            "train loss:0.6553591861363259\n",
            "train loss:0.5248732477828131\n",
            "train loss:0.5471499587881765\n",
            "train loss:0.5222999298360425\n",
            "train loss:0.4275614160316745\n",
            "train loss:0.4803060467115659\n",
            "train loss:0.5906701280168752\n",
            "=== epoch:177, train acc:0.857, test acc:0.7918 ===\n",
            "train loss:0.45670622893478446\n",
            "train loss:0.49811070003650976\n",
            "train loss:0.577274754379209\n",
            "train loss:0.5132343023598509\n",
            "train loss:0.42062229207927343\n",
            "train loss:0.506754225877477\n",
            "train loss:0.4878585697108604\n",
            "train loss:0.49210129170205\n",
            "train loss:0.4923103306097375\n",
            "train loss:0.6803411418014682\n",
            "=== epoch:178, train acc:0.858, test acc:0.7884 ===\n",
            "train loss:0.4472241605833318\n",
            "train loss:0.5150480587086195\n",
            "train loss:0.5984622514414117\n",
            "train loss:0.5811413575371462\n",
            "train loss:0.46623921494247056\n",
            "train loss:0.528664897562249\n",
            "train loss:0.44079487121628225\n",
            "train loss:0.5528519779910707\n",
            "train loss:0.45443562865917764\n",
            "train loss:0.49894681719904344\n",
            "=== epoch:179, train acc:0.859, test acc:0.7872 ===\n",
            "train loss:0.4728945916774587\n",
            "train loss:0.5164337263992489\n",
            "train loss:0.6613568861115947\n",
            "train loss:0.36968204653010356\n",
            "train loss:0.4694613226632396\n",
            "train loss:0.5842601769652294\n",
            "train loss:0.48042486475743884\n",
            "train loss:0.5994289571907052\n",
            "train loss:0.4827800081548248\n",
            "train loss:0.4211782976762444\n",
            "=== epoch:180, train acc:0.859, test acc:0.7917 ===\n",
            "train loss:0.5654121739859171\n",
            "train loss:0.5375770667855092\n",
            "train loss:0.4844858553707762\n",
            "train loss:0.48661332816624553\n",
            "train loss:0.5212101504246565\n",
            "train loss:0.560673233306404\n",
            "train loss:0.538934911063458\n",
            "train loss:0.5039463772470635\n",
            "train loss:0.4856235606879617\n",
            "train loss:0.4445504273153459\n",
            "=== epoch:181, train acc:0.87, test acc:0.7996 ===\n",
            "train loss:0.4561166476441933\n",
            "train loss:0.5856285572862951\n",
            "train loss:0.5202095735744466\n",
            "train loss:0.5200759859979588\n",
            "train loss:0.4659300532253547\n",
            "train loss:0.46099174612887955\n",
            "train loss:0.5188665651855823\n",
            "train loss:0.4778075356868567\n",
            "train loss:0.6674864264035779\n",
            "train loss:0.5120802872659541\n",
            "=== epoch:182, train acc:0.867, test acc:0.8035 ===\n",
            "train loss:0.4318598041277053\n",
            "train loss:0.4134737266614186\n",
            "train loss:0.5574628834879953\n",
            "train loss:0.48413203507877384\n",
            "train loss:0.5076808030919623\n",
            "train loss:0.4717379232367682\n",
            "train loss:0.5526974373423595\n",
            "train loss:0.481058357164342\n",
            "train loss:0.38891213465000873\n",
            "train loss:0.4816009927349708\n",
            "=== epoch:183, train acc:0.863, test acc:0.8002 ===\n",
            "train loss:0.4684011652182312\n",
            "train loss:0.5555807541982505\n",
            "train loss:0.5562188193282989\n",
            "train loss:0.4335185594808171\n",
            "train loss:0.5165958821804367\n",
            "train loss:0.39550658670857936\n",
            "train loss:0.40085539845679435\n",
            "train loss:0.42484009944234946\n",
            "train loss:0.4922015150901089\n",
            "train loss:0.37820626297343174\n",
            "=== epoch:184, train acc:0.864, test acc:0.7999 ===\n",
            "train loss:0.44297035869276313\n",
            "train loss:0.5365049393720773\n",
            "train loss:0.5041545241816617\n",
            "train loss:0.5961983354135587\n",
            "train loss:0.44010609083645924\n",
            "train loss:0.46338376057385716\n",
            "train loss:0.5363524619154743\n",
            "train loss:0.4433425908847211\n",
            "train loss:0.6486644304788013\n",
            "train loss:0.406198224677366\n",
            "=== epoch:185, train acc:0.873, test acc:0.8035 ===\n",
            "train loss:0.35796188379240496\n",
            "train loss:0.4583978200813337\n",
            "train loss:0.4520497359834007\n",
            "train loss:0.46685566658404754\n",
            "train loss:0.3459962570334423\n",
            "train loss:0.46596810708440684\n",
            "train loss:0.5134715441564607\n",
            "train loss:0.520556517381285\n",
            "train loss:0.5927702211021234\n",
            "train loss:0.5089395620758028\n",
            "=== epoch:186, train acc:0.867, test acc:0.8038 ===\n",
            "train loss:0.49403574327870503\n",
            "train loss:0.42941153294953965\n",
            "train loss:0.5303592352272277\n",
            "train loss:0.40783097894370185\n",
            "train loss:0.5010615313377614\n",
            "train loss:0.5712073501757008\n",
            "train loss:0.49437155628269835\n",
            "train loss:0.49826454319907626\n",
            "train loss:0.4805582802651039\n",
            "train loss:0.4803437097339253\n",
            "=== epoch:187, train acc:0.869, test acc:0.8081 ===\n",
            "train loss:0.5199313413145333\n",
            "train loss:0.4759486041238833\n",
            "train loss:0.4227478687148196\n",
            "train loss:0.41106038324046956\n",
            "train loss:0.37464235834982207\n",
            "train loss:0.43814235977993987\n",
            "train loss:0.4922956204316027\n",
            "train loss:0.4244620935544175\n",
            "train loss:0.5077047505348119\n",
            "train loss:0.4265570677060109\n",
            "=== epoch:188, train acc:0.869, test acc:0.8072 ===\n",
            "train loss:0.43445121586091046\n",
            "train loss:0.37898014433354993\n",
            "train loss:0.5323616094585418\n",
            "train loss:0.41462073935702565\n",
            "train loss:0.4265680624513965\n",
            "train loss:0.5485616150052419\n",
            "train loss:0.5024131236944931\n",
            "train loss:0.4685774125829283\n",
            "train loss:0.39053741622743543\n",
            "train loss:0.5057836470521555\n",
            "=== epoch:189, train acc:0.876, test acc:0.8129 ===\n",
            "train loss:0.4501382822039786\n",
            "train loss:0.49650378585328375\n",
            "train loss:0.48908761974362824\n",
            "train loss:0.40256632283573884\n",
            "train loss:0.33345997829166424\n",
            "train loss:0.4303591072814812\n",
            "train loss:0.5839128897517789\n",
            "train loss:0.4166004421747472\n",
            "train loss:0.46648018536899954\n",
            "train loss:0.41266260950118044\n",
            "=== epoch:190, train acc:0.876, test acc:0.8172 ===\n",
            "train loss:0.36843362960655346\n",
            "train loss:0.4411587804643936\n",
            "train loss:0.3665954810003507\n",
            "train loss:0.5755636414230367\n",
            "train loss:0.3790254520240142\n",
            "train loss:0.4504400758664899\n",
            "train loss:0.4848292472795922\n",
            "train loss:0.42580670769567314\n",
            "train loss:0.5154188759824171\n",
            "train loss:0.4297802323757142\n",
            "=== epoch:191, train acc:0.872, test acc:0.8116 ===\n",
            "train loss:0.47683531956918906\n",
            "train loss:0.40820985907519725\n",
            "train loss:0.44681179232041246\n",
            "train loss:0.4213530226404434\n",
            "train loss:0.3110103191641148\n",
            "train loss:0.552031244484322\n",
            "train loss:0.4449524929904413\n",
            "train loss:0.38635202428473425\n",
            "train loss:0.35397784266370846\n",
            "train loss:0.4976505976281714\n",
            "=== epoch:192, train acc:0.878, test acc:0.8127 ===\n",
            "train loss:0.5098850651008853\n",
            "train loss:0.418790252579851\n",
            "train loss:0.43761947786594196\n",
            "train loss:0.4579981842963421\n",
            "train loss:0.4327837519740674\n",
            "train loss:0.43230820022489574\n",
            "train loss:0.47049933797655114\n",
            "train loss:0.4311192211231184\n",
            "train loss:0.40673090424021857\n",
            "train loss:0.3818060852011849\n",
            "=== epoch:193, train acc:0.881, test acc:0.8137 ===\n",
            "train loss:0.44728911517565684\n",
            "train loss:0.3942465134716348\n",
            "train loss:0.4218782443510397\n",
            "train loss:0.42295778822706426\n",
            "train loss:0.43189681657107043\n",
            "train loss:0.36078288173189405\n",
            "train loss:0.473596253639767\n",
            "train loss:0.3902034294456707\n",
            "train loss:0.4157409267373533\n",
            "train loss:0.2653337555565524\n",
            "=== epoch:194, train acc:0.877, test acc:0.8132 ===\n",
            "train loss:0.3427651164082294\n",
            "train loss:0.36007877839081837\n",
            "train loss:0.422080768956713\n",
            "train loss:0.4642990668036127\n",
            "train loss:0.46767574531639533\n",
            "train loss:0.6243150102818574\n",
            "train loss:0.38796828475358963\n",
            "train loss:0.3529590710585101\n",
            "train loss:0.3943053121326372\n",
            "train loss:0.43445289927228836\n",
            "=== epoch:195, train acc:0.878, test acc:0.8123 ===\n",
            "train loss:0.3865145277422203\n",
            "train loss:0.5437226788038264\n",
            "train loss:0.4960546041773462\n",
            "train loss:0.3538435204691092\n",
            "train loss:0.35253597974533923\n",
            "train loss:0.33918821123100423\n",
            "train loss:0.5500935303176292\n",
            "train loss:0.46375414392185427\n",
            "train loss:0.4406833510438549\n",
            "train loss:0.4836858850284168\n",
            "=== epoch:196, train acc:0.885, test acc:0.8157 ===\n",
            "train loss:0.3687303945200635\n",
            "train loss:0.4262696806024479\n",
            "train loss:0.45352274160452494\n",
            "train loss:0.41315006582120994\n",
            "train loss:0.46458332139937264\n",
            "train loss:0.4565578163112069\n",
            "train loss:0.45926959740782436\n",
            "train loss:0.4357999255119379\n",
            "train loss:0.41841540287821\n",
            "train loss:0.30673496650122956\n",
            "=== epoch:197, train acc:0.881, test acc:0.8194 ===\n",
            "train loss:0.38468164630708074\n",
            "train loss:0.4375582221251387\n",
            "train loss:0.3666954527931832\n",
            "train loss:0.4771254478358925\n",
            "train loss:0.3682334367494886\n",
            "train loss:0.403245637663852\n",
            "train loss:0.38780647195211043\n",
            "train loss:0.3846422232933072\n",
            "train loss:0.4637151892455135\n",
            "train loss:0.36947521125702343\n",
            "=== epoch:198, train acc:0.882, test acc:0.8204 ===\n",
            "train loss:0.4027115617381385\n",
            "train loss:0.35262767671854733\n",
            "train loss:0.38880248234852943\n",
            "train loss:0.4174280564745003\n",
            "train loss:0.6065353127051503\n",
            "train loss:0.36577602816542004\n",
            "train loss:0.38378267339671157\n",
            "train loss:0.38496631921800284\n",
            "train loss:0.46309670925810253\n",
            "train loss:0.3885715988186751\n",
            "=== epoch:199, train acc:0.884, test acc:0.824 ===\n",
            "train loss:0.45361659925703235\n",
            "train loss:0.4022291435368758\n",
            "train loss:0.4969350954243557\n",
            "train loss:0.4016844162587184\n",
            "train loss:0.4142741964814188\n",
            "train loss:0.3991985422585976\n",
            "train loss:0.317756392421991\n",
            "train loss:0.4025298144059897\n",
            "train loss:0.301450876545033\n",
            "train loss:0.31258419147941946\n",
            "=== epoch:200, train acc:0.882, test acc:0.8219 ===\n",
            "train loss:0.36023498874337195\n",
            "train loss:0.33731869077807175\n",
            "train loss:0.4870637331334587\n",
            "train loss:0.33197762431231753\n",
            "train loss:0.46554096762878594\n",
            "train loss:0.40463344644027477\n",
            "train loss:0.4264890387438401\n",
            "train loss:0.3927818160949176\n",
            "train loss:0.4634108392194735\n",
            "train loss:0.3803571900447668\n",
            "=== epoch:201, train acc:0.876, test acc:0.8233 ===\n",
            "train loss:0.4399627408417839\n",
            "train loss:0.5107944330984214\n",
            "train loss:0.42228814385553953\n",
            "train loss:0.47753638454540737\n",
            "train loss:0.3363257937134676\n",
            "train loss:0.37182742395119944\n",
            "train loss:0.4066269222422735\n",
            "train loss:0.2915454610297355\n",
            "train loss:0.43659795370190824\n",
            "train loss:0.3633954001857436\n",
            "=== epoch:202, train acc:0.88, test acc:0.8256 ===\n",
            "train loss:0.36532978347853207\n",
            "train loss:0.2920272959701897\n",
            "train loss:0.3593917847132138\n",
            "train loss:0.44481881527324435\n",
            "train loss:0.4483064753063\n",
            "train loss:0.4946587745504008\n",
            "train loss:0.4424107379787725\n",
            "train loss:0.4160650101272273\n",
            "train loss:0.4127723330909035\n",
            "train loss:0.3799691457547518\n",
            "=== epoch:203, train acc:0.883, test acc:0.8218 ===\n",
            "train loss:0.35885715760314485\n",
            "train loss:0.42121721196491824\n",
            "train loss:0.3012265884861875\n",
            "train loss:0.3754183168341505\n",
            "train loss:0.46005239464239145\n",
            "train loss:0.3358698036718132\n",
            "train loss:0.5190352387623771\n",
            "train loss:0.3863564883092048\n",
            "train loss:0.3911177030188021\n",
            "train loss:0.3479237827734077\n",
            "=== epoch:204, train acc:0.882, test acc:0.826 ===\n",
            "train loss:0.36278604834734296\n",
            "train loss:0.2773117041780482\n",
            "train loss:0.3379630229303896\n",
            "train loss:0.464625810842958\n",
            "train loss:0.3320584888399011\n",
            "train loss:0.3272976780850804\n",
            "train loss:0.3888048778163411\n",
            "train loss:0.410528491756955\n",
            "train loss:0.4198612126478868\n",
            "train loss:0.3148971882529655\n",
            "=== epoch:205, train acc:0.882, test acc:0.8278 ===\n",
            "train loss:0.33677265821160274\n",
            "train loss:0.36689858467479053\n",
            "train loss:0.3945897507987869\n",
            "train loss:0.43026429287814644\n",
            "train loss:0.46679573378289496\n",
            "train loss:0.2919588691677648\n",
            "train loss:0.4551864691959371\n",
            "train loss:0.4257685205500482\n",
            "train loss:0.40614420000548274\n",
            "train loss:0.315259865136881\n",
            "=== epoch:206, train acc:0.885, test acc:0.829 ===\n",
            "train loss:0.4373135038924731\n",
            "train loss:0.37756496270022616\n",
            "train loss:0.35728438147535985\n",
            "train loss:0.3514347264850058\n",
            "train loss:0.32963285191414493\n",
            "train loss:0.34427978583311336\n",
            "train loss:0.24973138894122787\n",
            "train loss:0.4389714535574\n",
            "train loss:0.37956474555180686\n",
            "train loss:0.41638136613612686\n",
            "=== epoch:207, train acc:0.886, test acc:0.8287 ===\n",
            "train loss:0.2311043485397552\n",
            "train loss:0.32865681940506797\n",
            "train loss:0.36611767804491613\n",
            "train loss:0.3151266930085572\n",
            "train loss:0.33872937874620523\n",
            "train loss:0.37435988534361786\n",
            "train loss:0.40597719017445194\n",
            "train loss:0.39011447952711414\n",
            "train loss:0.29410480550588003\n",
            "train loss:0.3860729346626026\n",
            "=== epoch:208, train acc:0.886, test acc:0.827 ===\n",
            "train loss:0.39868022329764424\n",
            "train loss:0.33002683483700934\n",
            "train loss:0.46140005961376607\n",
            "train loss:0.2652301817582098\n",
            "train loss:0.4935845164784611\n",
            "train loss:0.2655572880190701\n",
            "train loss:0.3409606774621798\n",
            "train loss:0.3961430432891722\n",
            "train loss:0.3177840469128914\n",
            "train loss:0.2709051079424927\n",
            "=== epoch:209, train acc:0.889, test acc:0.8276 ===\n",
            "train loss:0.39874168559752726\n",
            "train loss:0.3600030458978282\n",
            "train loss:0.347476835975306\n",
            "train loss:0.42860269758127845\n",
            "train loss:0.4261544674545561\n",
            "train loss:0.33092492055306927\n",
            "train loss:0.3828738070461983\n",
            "train loss:0.37721755024100134\n",
            "train loss:0.3871315858286906\n",
            "train loss:0.3972284320629894\n",
            "=== epoch:210, train acc:0.893, test acc:0.8321 ===\n",
            "train loss:0.35519392562540775\n",
            "train loss:0.31655786448535994\n",
            "train loss:0.2968790908998365\n",
            "train loss:0.32560101769388516\n",
            "train loss:0.3616653604411747\n",
            "train loss:0.3443671810188183\n",
            "train loss:0.32462149123709744\n",
            "train loss:0.2900302692971024\n",
            "train loss:0.46218406305438386\n",
            "train loss:0.32607954316119087\n",
            "=== epoch:211, train acc:0.894, test acc:0.8279 ===\n",
            "train loss:0.3218146700675453\n",
            "train loss:0.45918806928699274\n",
            "train loss:0.4749311820028002\n",
            "train loss:0.362214614484068\n",
            "train loss:0.5624998446380485\n",
            "train loss:0.4029625421014336\n",
            "train loss:0.4173365540113591\n",
            "train loss:0.33236281405610024\n",
            "train loss:0.36037824854823897\n",
            "train loss:0.39954468259319953\n",
            "=== epoch:212, train acc:0.895, test acc:0.8271 ===\n",
            "train loss:0.25469815600440465\n",
            "train loss:0.2820079810128323\n",
            "train loss:0.31590903891543237\n",
            "train loss:0.3502726056230007\n",
            "train loss:0.4111207483318074\n",
            "train loss:0.24085123008093426\n",
            "train loss:0.37473505908240123\n",
            "train loss:0.40428875426497224\n",
            "train loss:0.28774548545759066\n",
            "train loss:0.3201272186320109\n",
            "=== epoch:213, train acc:0.896, test acc:0.8284 ===\n",
            "train loss:0.3774836635437206\n",
            "train loss:0.36363212289562397\n",
            "train loss:0.3580800341477925\n",
            "train loss:0.3570799114473693\n",
            "train loss:0.43089847243344287\n",
            "train loss:0.3500073332685518\n",
            "train loss:0.3127393989939531\n",
            "train loss:0.24233699164229972\n",
            "train loss:0.28917901111368194\n",
            "train loss:0.23023180495071022\n",
            "=== epoch:214, train acc:0.895, test acc:0.8317 ===\n",
            "train loss:0.4970574797774813\n",
            "train loss:0.34641064791452536\n",
            "train loss:0.3445784679102236\n",
            "train loss:0.30769338931324103\n",
            "train loss:0.4058230424260251\n",
            "train loss:0.35695498377575274\n",
            "train loss:0.27634208324099674\n",
            "train loss:0.3390949659489167\n",
            "train loss:0.4004789085744704\n",
            "train loss:0.30121928710587353\n",
            "=== epoch:215, train acc:0.896, test acc:0.8315 ===\n",
            "train loss:0.4088663567254038\n",
            "train loss:0.3889551808966716\n",
            "train loss:0.4214107949972382\n",
            "train loss:0.4160137380531983\n",
            "train loss:0.2697579201365584\n",
            "train loss:0.3105891587663395\n",
            "train loss:0.4885316033073865\n",
            "train loss:0.4189018211289385\n",
            "train loss:0.35563424643343466\n",
            "train loss:0.28818729119475694\n",
            "=== epoch:216, train acc:0.899, test acc:0.83 ===\n",
            "train loss:0.33723464844731743\n",
            "train loss:0.38486898787876034\n",
            "train loss:0.35527430917944486\n",
            "train loss:0.34066105888359466\n",
            "train loss:0.3342005693126355\n",
            "train loss:0.22383882722163098\n",
            "train loss:0.48393875064121905\n",
            "train loss:0.3516502595070825\n",
            "train loss:0.39374508521311474\n",
            "train loss:0.34951843497897284\n",
            "=== epoch:217, train acc:0.9, test acc:0.8365 ===\n",
            "train loss:0.36488562079188336\n",
            "train loss:0.3177064057972035\n",
            "train loss:0.3805889536045385\n",
            "train loss:0.37224880670892296\n",
            "train loss:0.3550805133905438\n",
            "train loss:0.29087201826917863\n",
            "train loss:0.3808782966688339\n",
            "train loss:0.26390938311217754\n",
            "train loss:0.48407309118529307\n",
            "train loss:0.28284529814946735\n",
            "=== epoch:218, train acc:0.9, test acc:0.8349 ===\n",
            "train loss:0.3174897371460394\n",
            "train loss:0.3271125186900742\n",
            "train loss:0.307656579352437\n",
            "train loss:0.38470639031873416\n",
            "train loss:0.34956322420515895\n",
            "train loss:0.27879055116433327\n",
            "train loss:0.32532138134763516\n",
            "train loss:0.22548765960493644\n",
            "train loss:0.3679867975352407\n",
            "train loss:0.4329428587505827\n",
            "=== epoch:219, train acc:0.898, test acc:0.8369 ===\n",
            "train loss:0.30332212501436595\n",
            "train loss:0.2690696214448316\n",
            "train loss:0.26238244869036825\n",
            "train loss:0.41634965564445303\n",
            "train loss:0.27602409012662377\n",
            "train loss:0.3404016349724207\n",
            "train loss:0.4290320959693893\n",
            "train loss:0.26629109464498435\n",
            "train loss:0.34723800670505084\n",
            "train loss:0.317117396709577\n",
            "=== epoch:220, train acc:0.899, test acc:0.8356 ===\n",
            "train loss:0.22800973802823904\n",
            "train loss:0.3827631375642248\n",
            "train loss:0.47143329367256426\n",
            "train loss:0.32815504722722655\n",
            "train loss:0.3818357045992441\n",
            "train loss:0.3639454788332594\n",
            "train loss:0.2763843979247786\n",
            "train loss:0.2726738235542929\n",
            "train loss:0.3993250089515367\n",
            "train loss:0.38200420275153735\n",
            "=== epoch:221, train acc:0.906, test acc:0.8395 ===\n",
            "train loss:0.32066017813044867\n",
            "train loss:0.3977082011118033\n",
            "train loss:0.23691834023060307\n",
            "train loss:0.31635007088820954\n",
            "train loss:0.2715774004819364\n",
            "train loss:0.3893641037873449\n",
            "train loss:0.26954692218900417\n",
            "train loss:0.3010077704351673\n",
            "train loss:0.31393148012532557\n",
            "train loss:0.24761461342797442\n",
            "=== epoch:222, train acc:0.902, test acc:0.8378 ===\n",
            "train loss:0.28761108016693926\n",
            "train loss:0.27586035444491164\n",
            "train loss:0.3177555476325926\n",
            "train loss:0.3050859589989942\n",
            "train loss:0.28142623775509906\n",
            "train loss:0.40145378334598564\n",
            "train loss:0.2869788712077082\n",
            "train loss:0.2475899936018862\n",
            "train loss:0.2716322079740328\n",
            "train loss:0.2994328792640988\n",
            "=== epoch:223, train acc:0.903, test acc:0.8397 ===\n",
            "train loss:0.3898805382746671\n",
            "train loss:0.3281033414465275\n",
            "train loss:0.2800184829431658\n",
            "train loss:0.31709475358801864\n",
            "train loss:0.378801547750243\n",
            "train loss:0.30069839947149046\n",
            "train loss:0.3948527311244451\n",
            "train loss:0.3526869080318585\n",
            "train loss:0.2934825649345787\n",
            "train loss:0.2842649067715397\n",
            "=== epoch:224, train acc:0.909, test acc:0.8386 ===\n",
            "train loss:0.33840410543983634\n",
            "train loss:0.29493808853537223\n",
            "train loss:0.354676728027198\n",
            "train loss:0.27984718754211463\n",
            "train loss:0.3060909894734825\n",
            "train loss:0.29281307986756916\n",
            "train loss:0.3652769227338434\n",
            "train loss:0.3259048429549404\n",
            "train loss:0.36302309704026214\n",
            "train loss:0.32117748926140743\n",
            "=== epoch:225, train acc:0.908, test acc:0.8407 ===\n",
            "train loss:0.25379871902370404\n",
            "train loss:0.3212621056042116\n",
            "train loss:0.27160285218160946\n",
            "train loss:0.2759514146246518\n",
            "train loss:0.3069532305574996\n",
            "train loss:0.32416627010142\n",
            "train loss:0.3459065994831082\n",
            "train loss:0.2718927269565846\n",
            "train loss:0.269801977905406\n",
            "train loss:0.3452028536092\n",
            "=== epoch:226, train acc:0.913, test acc:0.8432 ===\n",
            "train loss:0.28877140061749\n",
            "train loss:0.2714761271488111\n",
            "train loss:0.2916132653059709\n",
            "train loss:0.27971872134511255\n",
            "train loss:0.24002517066127\n",
            "train loss:0.321015348812159\n",
            "train loss:0.21270301337360767\n",
            "train loss:0.32928308023469144\n",
            "train loss:0.2525235600360277\n",
            "train loss:0.30694229389569866\n",
            "=== epoch:227, train acc:0.914, test acc:0.8408 ===\n",
            "train loss:0.48703015033494806\n",
            "train loss:0.2815796845086895\n",
            "train loss:0.2543244141752684\n",
            "train loss:0.37355507493065915\n",
            "train loss:0.25170849379919086\n",
            "train loss:0.31225820132311094\n",
            "train loss:0.2706038563171312\n",
            "train loss:0.2684453030300328\n",
            "train loss:0.3191047833109187\n",
            "train loss:0.3003128852285989\n",
            "=== epoch:228, train acc:0.92, test acc:0.8434 ===\n",
            "train loss:0.3187036221205078\n",
            "train loss:0.25902596603171657\n",
            "train loss:0.3124128166504586\n",
            "train loss:0.23775789776583392\n",
            "train loss:0.3292109178403158\n",
            "train loss:0.2862261780272192\n",
            "train loss:0.2655962011714418\n",
            "train loss:0.3372311830048875\n",
            "train loss:0.2596042696016492\n",
            "train loss:0.2906593475362389\n",
            "=== epoch:229, train acc:0.921, test acc:0.8453 ===\n",
            "train loss:0.22286669662370148\n",
            "train loss:0.2748823659808035\n",
            "train loss:0.31739959017976543\n",
            "train loss:0.21275942608336149\n",
            "train loss:0.27989540232711285\n",
            "train loss:0.25143076619889543\n",
            "train loss:0.40035241857828247\n",
            "train loss:0.23683860358538758\n",
            "train loss:0.2698700137703034\n",
            "train loss:0.2880537345433739\n",
            "=== epoch:230, train acc:0.92, test acc:0.8451 ===\n",
            "train loss:0.244082167209912\n",
            "train loss:0.3032781333852119\n",
            "train loss:0.2513587475627831\n",
            "train loss:0.19225979502004403\n",
            "train loss:0.2123401038445775\n",
            "train loss:0.2793511785368635\n",
            "train loss:0.3495591182056875\n",
            "train loss:0.28795670129081785\n",
            "train loss:0.2841700787341876\n",
            "train loss:0.2934902207177869\n",
            "=== epoch:231, train acc:0.918, test acc:0.845 ===\n",
            "train loss:0.31219752772566023\n",
            "train loss:0.3103783188337898\n",
            "train loss:0.20323632228264926\n",
            "train loss:0.3249966154327698\n",
            "train loss:0.24803697390795423\n",
            "train loss:0.32866852419056314\n",
            "train loss:0.2893862106283261\n",
            "train loss:0.28930526588487626\n",
            "train loss:0.2587024623751781\n",
            "train loss:0.32769719734807423\n",
            "=== epoch:232, train acc:0.911, test acc:0.8424 ===\n",
            "train loss:0.3660377705947677\n",
            "train loss:0.23490654720370382\n",
            "train loss:0.24688067838687508\n",
            "train loss:0.352663440160786\n",
            "train loss:0.2985650100861492\n",
            "train loss:0.4279065465100531\n",
            "train loss:0.3001540546682923\n",
            "train loss:0.3078944158503855\n",
            "train loss:0.3221404270591859\n",
            "train loss:0.2099055208269046\n",
            "=== epoch:233, train acc:0.921, test acc:0.8429 ===\n",
            "train loss:0.21641620692252167\n",
            "train loss:0.2919824133098372\n",
            "train loss:0.2996549336091\n",
            "train loss:0.3067405116204489\n",
            "train loss:0.27006044645208066\n",
            "train loss:0.33780237307695676\n",
            "train loss:0.2781722195246474\n",
            "train loss:0.3492948508723718\n",
            "train loss:0.33600704233136947\n",
            "train loss:0.35526320702208525\n",
            "=== epoch:234, train acc:0.923, test acc:0.8472 ===\n",
            "train loss:0.22599379395801933\n",
            "train loss:0.306944041546177\n",
            "train loss:0.2377675153388117\n",
            "train loss:0.28658045753831873\n",
            "train loss:0.2850004509228073\n",
            "train loss:0.24958278670009848\n",
            "train loss:0.3239256224595155\n",
            "train loss:0.32940535748406563\n",
            "train loss:0.2694252738614242\n",
            "train loss:0.3110986088374308\n",
            "=== epoch:235, train acc:0.926, test acc:0.8476 ===\n",
            "train loss:0.36447227237472796\n",
            "train loss:0.2673516569373564\n",
            "train loss:0.2995125823549999\n",
            "train loss:0.3196751443216639\n",
            "train loss:0.24794377318313812\n",
            "train loss:0.3090161824139506\n",
            "train loss:0.26217510481641926\n",
            "train loss:0.26628467836022696\n",
            "train loss:0.2538663969393355\n",
            "train loss:0.27683756399179676\n",
            "=== epoch:236, train acc:0.927, test acc:0.8453 ===\n",
            "train loss:0.2584936148868744\n",
            "train loss:0.29905854284034084\n",
            "train loss:0.32858658232540316\n",
            "train loss:0.33831163804362946\n",
            "train loss:0.18890809814770645\n",
            "train loss:0.334041702203748\n",
            "train loss:0.2557617037224705\n",
            "train loss:0.23299539252763868\n",
            "train loss:0.20231745480255495\n",
            "train loss:0.21744724862053375\n",
            "=== epoch:237, train acc:0.924, test acc:0.8438 ===\n",
            "train loss:0.23077440542321995\n",
            "train loss:0.23241432367811996\n",
            "train loss:0.2951957871822891\n",
            "train loss:0.32416297292935103\n",
            "train loss:0.2478845959628239\n",
            "train loss:0.26746230819598177\n",
            "train loss:0.3001155122452525\n",
            "train loss:0.2898291891998743\n",
            "train loss:0.2204208748515557\n",
            "train loss:0.3342919589279923\n",
            "=== epoch:238, train acc:0.929, test acc:0.8477 ===\n",
            "train loss:0.3284280701501755\n",
            "train loss:0.2980035401305176\n",
            "train loss:0.4056174866565962\n",
            "train loss:0.30214770243224764\n",
            "train loss:0.26293489892943545\n",
            "train loss:0.33161378839686934\n",
            "train loss:0.29900226166311605\n",
            "train loss:0.22018623222295478\n",
            "train loss:0.23206494615407308\n",
            "train loss:0.3168214567920888\n",
            "=== epoch:239, train acc:0.931, test acc:0.8491 ===\n",
            "train loss:0.27542199099574316\n",
            "train loss:0.2864051510953309\n",
            "train loss:0.2904752726041663\n",
            "train loss:0.22132271686924487\n",
            "train loss:0.25874454502660116\n",
            "train loss:0.2971168142397343\n",
            "train loss:0.3520726117536672\n",
            "train loss:0.34472312135280875\n",
            "train loss:0.2608644563816849\n",
            "train loss:0.24571144894318173\n",
            "=== epoch:240, train acc:0.922, test acc:0.848 ===\n",
            "train loss:0.25497139066727015\n",
            "train loss:0.2972258612776612\n",
            "train loss:0.21543610108564157\n",
            "train loss:0.2576508561241321\n",
            "train loss:0.2424833006465984\n",
            "train loss:0.28188062337221864\n",
            "train loss:0.2274916067074546\n",
            "train loss:0.22114395048263302\n",
            "train loss:0.27181263085228036\n",
            "train loss:0.16046273991162063\n",
            "=== epoch:241, train acc:0.925, test acc:0.8477 ===\n",
            "train loss:0.2578187377056429\n",
            "train loss:0.2422949527476872\n",
            "train loss:0.2203745122101803\n",
            "train loss:0.22128208055495527\n",
            "train loss:0.2995501876797466\n",
            "train loss:0.37387960132718684\n",
            "train loss:0.28862117948454014\n",
            "train loss:0.19180955703584282\n",
            "train loss:0.2632479636980623\n",
            "train loss:0.27243052217867997\n",
            "=== epoch:242, train acc:0.93, test acc:0.8498 ===\n",
            "train loss:0.34049533575100066\n",
            "train loss:0.3366219546256023\n",
            "train loss:0.23081451863967797\n",
            "train loss:0.22763844562154742\n",
            "train loss:0.3071966387137244\n",
            "train loss:0.2503658149377086\n",
            "train loss:0.3149618104195779\n",
            "train loss:0.2847377565714144\n",
            "train loss:0.23517869243036554\n",
            "train loss:0.3207555753118859\n",
            "=== epoch:243, train acc:0.932, test acc:0.8496 ===\n",
            "train loss:0.26001198895808025\n",
            "train loss:0.2510728669037933\n",
            "train loss:0.23430168093619602\n",
            "train loss:0.23065728757455276\n",
            "train loss:0.24194212371799395\n",
            "train loss:0.21439404896943975\n",
            "train loss:0.25855516628667696\n",
            "train loss:0.24865652322705703\n",
            "train loss:0.15924341517915158\n",
            "train loss:0.17999575755452812\n",
            "=== epoch:244, train acc:0.926, test acc:0.8487 ===\n",
            "train loss:0.2748196039491284\n",
            "train loss:0.17318174869848574\n",
            "train loss:0.24159919856097475\n",
            "train loss:0.36088696431099154\n",
            "train loss:0.16516310840021045\n",
            "train loss:0.34677285980382705\n",
            "train loss:0.20387316310993\n",
            "train loss:0.30732752733273\n",
            "train loss:0.25513302734318044\n",
            "train loss:0.2313260620858244\n",
            "=== epoch:245, train acc:0.929, test acc:0.8496 ===\n",
            "train loss:0.21127255263774597\n",
            "train loss:0.28087125317616257\n",
            "train loss:0.28485125073573137\n",
            "train loss:0.24059779545506849\n",
            "train loss:0.2122839867000693\n",
            "train loss:0.25297607974539404\n",
            "train loss:0.20453691733992257\n",
            "train loss:0.25163525346115084\n",
            "train loss:0.2536228316855539\n",
            "train loss:0.2707224398701984\n",
            "=== epoch:246, train acc:0.925, test acc:0.85 ===\n",
            "train loss:0.30439698739068904\n",
            "train loss:0.3096617338752832\n",
            "train loss:0.19713572749400068\n",
            "train loss:0.25612327355403425\n",
            "train loss:0.2681337316589259\n",
            "train loss:0.2313291180056618\n",
            "train loss:0.30696053008798607\n",
            "train loss:0.22237449324631492\n",
            "train loss:0.21402837580586045\n",
            "train loss:0.3347657045229374\n",
            "=== epoch:247, train acc:0.937, test acc:0.8504 ===\n",
            "train loss:0.19791090121663932\n",
            "train loss:0.2505787386285207\n",
            "train loss:0.23787587204573513\n",
            "train loss:0.26564330476055037\n",
            "train loss:0.14416491693071823\n",
            "train loss:0.1588023351644331\n",
            "train loss:0.2682170496653645\n",
            "train loss:0.2767593073445604\n",
            "train loss:0.29577172318446665\n",
            "train loss:0.25317389675025637\n",
            "=== epoch:248, train acc:0.938, test acc:0.8523 ===\n",
            "train loss:0.1373003312079363\n",
            "train loss:0.19673921805228928\n",
            "train loss:0.2269044359024262\n",
            "train loss:0.2550528676036921\n",
            "train loss:0.23278373803991811\n",
            "train loss:0.21325148813672792\n",
            "train loss:0.24438465011012517\n",
            "train loss:0.1987520370233652\n",
            "train loss:0.2653435407745501\n",
            "train loss:0.33965591254953426\n",
            "=== epoch:249, train acc:0.935, test acc:0.8533 ===\n",
            "train loss:0.24406978674748572\n",
            "train loss:0.2307105986212301\n",
            "train loss:0.19484094446249256\n",
            "train loss:0.21441300200886362\n",
            "train loss:0.21256982328451735\n",
            "train loss:0.28573889296883015\n",
            "train loss:0.2281253560416596\n",
            "train loss:0.2590906004853171\n",
            "train loss:0.1800259029733487\n",
            "train loss:0.19930885439530244\n",
            "=== epoch:250, train acc:0.934, test acc:0.8528 ===\n",
            "train loss:0.1354316808552755\n",
            "train loss:0.1737579176535814\n",
            "train loss:0.2222873760981392\n",
            "train loss:0.28756141561454684\n",
            "train loss:0.23511811862512297\n",
            "train loss:0.20136469473781804\n",
            "train loss:0.20822446719821872\n",
            "train loss:0.258783648375498\n",
            "train loss:0.18997772290833495\n",
            "train loss:0.19763274521426755\n",
            "=== epoch:251, train acc:0.94, test acc:0.8522 ===\n",
            "train loss:0.22849346310268384\n",
            "train loss:0.2165779603339498\n",
            "train loss:0.28286594401924164\n",
            "train loss:0.2534394333469858\n",
            "train loss:0.31532144560175984\n",
            "train loss:0.23020650885791952\n",
            "train loss:0.20864027388985135\n",
            "train loss:0.1818292829700338\n",
            "train loss:0.19825898103718007\n",
            "train loss:0.25468476858946293\n",
            "=== epoch:252, train acc:0.935, test acc:0.853 ===\n",
            "train loss:0.2894664628395149\n",
            "train loss:0.25542267452986256\n",
            "train loss:0.16808770604080242\n",
            "train loss:0.22957716668660236\n",
            "train loss:0.34690710448240764\n",
            "train loss:0.2710270212392762\n",
            "train loss:0.21687539394182098\n",
            "train loss:0.28490175019890435\n",
            "train loss:0.19295361957201762\n",
            "train loss:0.25734307395993417\n",
            "=== epoch:253, train acc:0.937, test acc:0.8541 ===\n",
            "train loss:0.24040203162083051\n",
            "train loss:0.3209571433246451\n",
            "train loss:0.1958477826776649\n",
            "train loss:0.2173532504789074\n",
            "train loss:0.23349572496896115\n",
            "train loss:0.2608282612873087\n",
            "train loss:0.16725808668436806\n",
            "train loss:0.18263518008114257\n",
            "train loss:0.292806688746645\n",
            "train loss:0.26442870679299096\n",
            "=== epoch:254, train acc:0.938, test acc:0.854 ===\n",
            "train loss:0.22384146131797591\n",
            "train loss:0.26848092244461946\n",
            "train loss:0.17961180182083022\n",
            "train loss:0.31045621314387856\n",
            "train loss:0.1612159983822149\n",
            "train loss:0.1975766016967463\n",
            "train loss:0.24296398328421126\n",
            "train loss:0.26460381723424714\n",
            "train loss:0.1929149120579337\n",
            "train loss:0.18796947439280348\n",
            "=== epoch:255, train acc:0.94, test acc:0.8513 ===\n",
            "train loss:0.18783948271626397\n",
            "train loss:0.2739967663595275\n",
            "train loss:0.17013228091384122\n",
            "train loss:0.30199829979952747\n",
            "train loss:0.1737591832450978\n",
            "train loss:0.23535979247843308\n",
            "train loss:0.18218028843886153\n",
            "train loss:0.13397787236641187\n",
            "train loss:0.20475457845846512\n",
            "train loss:0.19339973856250908\n",
            "=== epoch:256, train acc:0.943, test acc:0.8541 ===\n",
            "train loss:0.15775421485144936\n",
            "train loss:0.23762300909311032\n",
            "train loss:0.18737986238394425\n",
            "train loss:0.2009278455010467\n",
            "train loss:0.1476742105203076\n",
            "train loss:0.24544013472007287\n",
            "train loss:0.1760338986363285\n",
            "train loss:0.23314787848263804\n",
            "train loss:0.23431932860916901\n",
            "train loss:0.1422763383058175\n",
            "=== epoch:257, train acc:0.94, test acc:0.8578 ===\n",
            "train loss:0.18188169169018623\n",
            "train loss:0.19214095090291652\n",
            "train loss:0.2633602422840637\n",
            "train loss:0.19327564354087193\n",
            "train loss:0.18029570206569429\n",
            "train loss:0.14931544998389057\n",
            "train loss:0.19189792117868337\n",
            "train loss:0.18138608215273283\n",
            "train loss:0.25635912018194756\n",
            "train loss:0.2573053281942008\n",
            "=== epoch:258, train acc:0.941, test acc:0.8554 ===\n",
            "train loss:0.2285728347174081\n",
            "train loss:0.2040409328281692\n",
            "train loss:0.27581153394361335\n",
            "train loss:0.25065024840249994\n",
            "train loss:0.26998629099566207\n",
            "train loss:0.20698402511201455\n",
            "train loss:0.22170381458013114\n",
            "train loss:0.27186727984463155\n",
            "train loss:0.22267814096911903\n",
            "train loss:0.2108219507206839\n",
            "=== epoch:259, train acc:0.939, test acc:0.8554 ===\n",
            "train loss:0.2575072551429788\n",
            "train loss:0.258404136000547\n",
            "train loss:0.17678170613382274\n",
            "train loss:0.15926475453027714\n",
            "train loss:0.21841285537999816\n",
            "train loss:0.12316949182346965\n",
            "train loss:0.2680120596454331\n",
            "train loss:0.212319941983608\n",
            "train loss:0.21183167567590633\n",
            "train loss:0.15327346073555354\n",
            "=== epoch:260, train acc:0.936, test acc:0.8552 ===\n",
            "train loss:0.24334100426369815\n",
            "train loss:0.16201053700940585\n",
            "train loss:0.2560303717282047\n",
            "train loss:0.1305773241663643\n",
            "train loss:0.19382624761568729\n",
            "train loss:0.17040360627143586\n",
            "train loss:0.2106544370593401\n",
            "train loss:0.195818059508274\n",
            "train loss:0.2633429926690566\n",
            "train loss:0.15020680419992194\n",
            "=== epoch:261, train acc:0.94, test acc:0.8527 ===\n",
            "train loss:0.18675418023938226\n",
            "train loss:0.2293019077553283\n",
            "train loss:0.266238938912222\n",
            "train loss:0.18123752572084\n",
            "train loss:0.2119906193918055\n",
            "train loss:0.110188166932729\n",
            "train loss:0.14039427341391383\n",
            "train loss:0.22667235897818347\n",
            "train loss:0.144099333385723\n",
            "train loss:0.19209254114067348\n",
            "=== epoch:262, train acc:0.943, test acc:0.8546 ===\n",
            "train loss:0.1713601175167615\n",
            "train loss:0.22960289244985624\n",
            "train loss:0.1791327894492769\n",
            "train loss:0.2527384952278501\n",
            "train loss:0.19047373401348666\n",
            "train loss:0.19686560093799532\n",
            "train loss:0.16010468910455208\n",
            "train loss:0.17747646237664966\n",
            "train loss:0.17161588684871937\n",
            "train loss:0.1876804366639964\n",
            "=== epoch:263, train acc:0.943, test acc:0.8543 ===\n",
            "train loss:0.25300987963117916\n",
            "train loss:0.29709690728853627\n",
            "train loss:0.2148401448572068\n",
            "train loss:0.22614397588799398\n",
            "train loss:0.18746431582227213\n",
            "train loss:0.26566185428274464\n",
            "train loss:0.11997952616003926\n",
            "train loss:0.2253552507325149\n",
            "train loss:0.15473964463624731\n",
            "train loss:0.17104640347249284\n",
            "=== epoch:264, train acc:0.946, test acc:0.8569 ===\n",
            "train loss:0.22116242174343462\n",
            "train loss:0.19409869856626497\n",
            "train loss:0.23583286543038828\n",
            "train loss:0.1345865051181758\n",
            "train loss:0.2555340051370847\n",
            "train loss:0.17941532331706803\n",
            "train loss:0.17383406140923707\n",
            "train loss:0.13161075826382357\n",
            "train loss:0.19157638811422184\n",
            "train loss:0.21470839197986064\n",
            "=== epoch:265, train acc:0.947, test acc:0.8573 ===\n",
            "train loss:0.20317690759525997\n",
            "train loss:0.316668047702368\n",
            "train loss:0.20079762233644322\n",
            "train loss:0.20170168074228934\n",
            "train loss:0.15207944537584653\n",
            "train loss:0.23640543681475054\n",
            "train loss:0.20154852298572487\n",
            "train loss:0.15767141086420608\n",
            "train loss:0.21030927265542088\n",
            "train loss:0.19610359336387326\n",
            "=== epoch:266, train acc:0.946, test acc:0.8547 ===\n",
            "train loss:0.16133608038928074\n",
            "train loss:0.2554518424343284\n",
            "train loss:0.13234275514373395\n",
            "train loss:0.18226057756442518\n",
            "train loss:0.1955719254807982\n",
            "train loss:0.19210455024064538\n",
            "train loss:0.1903712691184254\n",
            "train loss:0.2490486167033609\n",
            "train loss:0.1563002599940187\n",
            "train loss:0.21099230230614552\n",
            "=== epoch:267, train acc:0.948, test acc:0.8569 ===\n",
            "train loss:0.25189691977105794\n",
            "train loss:0.1827002098787138\n",
            "train loss:0.1868146956205897\n",
            "train loss:0.22507359491630033\n",
            "train loss:0.22070822770348955\n",
            "train loss:0.2062788078738863\n",
            "train loss:0.12723434113779694\n",
            "train loss:0.219817149623997\n",
            "train loss:0.24326877554126894\n",
            "train loss:0.19155747276248494\n",
            "=== epoch:268, train acc:0.946, test acc:0.8586 ===\n",
            "train loss:0.20950383667543296\n",
            "train loss:0.20478874550196566\n",
            "train loss:0.2539283637731231\n",
            "train loss:0.1305058915059298\n",
            "train loss:0.24698521990496491\n",
            "train loss:0.17182085978419293\n",
            "train loss:0.210951040646775\n",
            "train loss:0.15175605379553347\n",
            "train loss:0.1837537190332549\n",
            "train loss:0.16684119439848963\n",
            "=== epoch:269, train acc:0.944, test acc:0.8563 ===\n",
            "train loss:0.1684690489129897\n",
            "train loss:0.14869350025179626\n",
            "train loss:0.13943686900060043\n",
            "train loss:0.1611272497009345\n",
            "train loss:0.20848905882744131\n",
            "train loss:0.23494739435704376\n",
            "train loss:0.2228757675814586\n",
            "train loss:0.237539306922125\n",
            "train loss:0.1274333352807884\n",
            "train loss:0.1765677838081226\n",
            "=== epoch:270, train acc:0.947, test acc:0.8554 ===\n",
            "train loss:0.21103074274166672\n",
            "train loss:0.20685282870127597\n",
            "train loss:0.14676846447959538\n",
            "train loss:0.20116595162854808\n",
            "train loss:0.11407865222885503\n",
            "train loss:0.12511231863292813\n",
            "train loss:0.18906684297482254\n",
            "train loss:0.24310811636748114\n",
            "train loss:0.168230486268841\n",
            "train loss:0.1567469103766539\n",
            "=== epoch:271, train acc:0.945, test acc:0.8564 ===\n",
            "train loss:0.1674442539029676\n",
            "train loss:0.21837076213629372\n",
            "train loss:0.18927332469171174\n",
            "train loss:0.16013215614260962\n",
            "train loss:0.1588724534038009\n",
            "train loss:0.20944368031253918\n",
            "train loss:0.1978113306845313\n",
            "train loss:0.16628454182921973\n",
            "train loss:0.19693876581852213\n",
            "train loss:0.2171823289980762\n",
            "=== epoch:272, train acc:0.952, test acc:0.8576 ===\n",
            "train loss:0.15416961415520866\n",
            "train loss:0.19356441758852505\n",
            "train loss:0.15082154484973803\n",
            "train loss:0.16277550276305944\n",
            "train loss:0.1686353624626144\n",
            "train loss:0.20594747456905282\n",
            "train loss:0.10018560449316735\n",
            "train loss:0.091123095523865\n",
            "train loss:0.14114005010539685\n",
            "train loss:0.19707575284668344\n",
            "=== epoch:273, train acc:0.95, test acc:0.857 ===\n",
            "train loss:0.18839569541925458\n",
            "train loss:0.15786881236494288\n",
            "train loss:0.1809908158560789\n",
            "train loss:0.1412920502961004\n",
            "train loss:0.20009764188044193\n",
            "train loss:0.23150211754327735\n",
            "train loss:0.180541131676\n",
            "train loss:0.17938412976985657\n",
            "train loss:0.19869431745520483\n",
            "train loss:0.17385616037493576\n",
            "=== epoch:274, train acc:0.953, test acc:0.8569 ===\n",
            "train loss:0.13337965296369722\n",
            "train loss:0.1495404417253253\n",
            "train loss:0.211244704483216\n",
            "train loss:0.17228244854708\n",
            "train loss:0.2032897037449256\n",
            "train loss:0.19235912147999293\n",
            "train loss:0.20224804448218456\n",
            "train loss:0.148369031033784\n",
            "train loss:0.26421747209733487\n",
            "train loss:0.25272963203353915\n",
            "=== epoch:275, train acc:0.954, test acc:0.8585 ===\n",
            "train loss:0.1393045832673949\n",
            "train loss:0.2270984645943019\n",
            "train loss:0.18961552830574313\n",
            "train loss:0.17688332000553228\n",
            "train loss:0.23864344944065852\n",
            "train loss:0.11943777315758614\n",
            "train loss:0.2275560925162438\n",
            "train loss:0.12764853833448758\n",
            "train loss:0.22291599830055867\n",
            "train loss:0.17749363842644034\n",
            "=== epoch:276, train acc:0.956, test acc:0.8595 ===\n",
            "train loss:0.17064444600234277\n",
            "train loss:0.1158896684444528\n",
            "train loss:0.13659161200829978\n",
            "train loss:0.2317307211099356\n",
            "train loss:0.16462291650139613\n",
            "train loss:0.1331760186514243\n",
            "train loss:0.18155154735533677\n",
            "train loss:0.18728801786007715\n",
            "train loss:0.14015671648876293\n",
            "train loss:0.18100877047557357\n",
            "=== epoch:277, train acc:0.958, test acc:0.8617 ===\n",
            "train loss:0.1413361512879164\n",
            "train loss:0.17107383420538852\n",
            "train loss:0.2009213045555936\n",
            "train loss:0.13984608785341363\n",
            "train loss:0.21154505335656362\n",
            "train loss:0.18419130614909984\n",
            "train loss:0.1666232823968324\n",
            "train loss:0.21381130742463136\n",
            "train loss:0.2161460939318003\n",
            "train loss:0.12458480253000191\n",
            "=== epoch:278, train acc:0.96, test acc:0.8618 ===\n",
            "train loss:0.1160227656659294\n",
            "train loss:0.2605067447265711\n",
            "train loss:0.2476064185299373\n",
            "train loss:0.17539321063370486\n",
            "train loss:0.1339984317465723\n",
            "train loss:0.16135076243837407\n",
            "train loss:0.13515540790700942\n",
            "train loss:0.12532477479390267\n",
            "train loss:0.14858523336157142\n",
            "train loss:0.1806803965417774\n",
            "=== epoch:279, train acc:0.961, test acc:0.8605 ===\n",
            "train loss:0.13494042741925946\n",
            "train loss:0.1591502349062047\n",
            "train loss:0.15505165395567033\n",
            "train loss:0.1602737875979783\n",
            "train loss:0.10129420948777688\n",
            "train loss:0.15911894303125165\n",
            "train loss:0.1659489029209136\n",
            "train loss:0.12790829064994827\n",
            "train loss:0.19440992352300676\n",
            "train loss:0.12453637497199153\n",
            "=== epoch:280, train acc:0.955, test acc:0.8594 ===\n",
            "train loss:0.21937751536261033\n",
            "train loss:0.14868285447633364\n",
            "train loss:0.15669034537949436\n",
            "train loss:0.16585220899700673\n",
            "train loss:0.14707776972934938\n",
            "train loss:0.17403414213665006\n",
            "train loss:0.12385566654954905\n",
            "train loss:0.25114430031254226\n",
            "train loss:0.09899304718888872\n",
            "train loss:0.19173218159467859\n",
            "=== epoch:281, train acc:0.959, test acc:0.8623 ===\n",
            "train loss:0.2518706507899142\n",
            "train loss:0.13692165161012979\n",
            "train loss:0.1250642207403145\n",
            "train loss:0.08874317337310006\n",
            "train loss:0.19018320304612135\n",
            "train loss:0.12107980454560732\n",
            "train loss:0.1780126592882244\n",
            "train loss:0.1693138044044205\n",
            "train loss:0.23146772803594512\n",
            "train loss:0.14157556680881256\n",
            "=== epoch:282, train acc:0.96, test acc:0.8609 ===\n",
            "train loss:0.14260762243089883\n",
            "train loss:0.07998104546376497\n",
            "train loss:0.1513942551046722\n",
            "train loss:0.16528781257549638\n",
            "train loss:0.18238189268665103\n",
            "train loss:0.1754578638862546\n",
            "train loss:0.19264978405472266\n",
            "train loss:0.1965925355953644\n",
            "train loss:0.08515106892601583\n",
            "train loss:0.0877001986124736\n",
            "=== epoch:283, train acc:0.956, test acc:0.8608 ===\n",
            "train loss:0.22637755286071104\n",
            "train loss:0.16120528789148367\n",
            "train loss:0.20388529273414516\n",
            "train loss:0.12939230248483252\n",
            "train loss:0.11505806597250884\n",
            "train loss:0.16620867120667648\n",
            "train loss:0.1567293635722419\n",
            "train loss:0.21532953598916435\n",
            "train loss:0.1336036210580712\n",
            "train loss:0.1564894595744771\n",
            "=== epoch:284, train acc:0.954, test acc:0.856 ===\n",
            "train loss:0.13758868978056435\n",
            "train loss:0.1801416648732176\n",
            "train loss:0.20896277069330246\n",
            "train loss:0.19210954243972578\n",
            "train loss:0.14660112576914916\n",
            "train loss:0.18234652709048427\n",
            "train loss:0.13785730554089315\n",
            "train loss:0.1973039403705831\n",
            "train loss:0.1827406485338331\n",
            "train loss:0.12903903379975712\n",
            "=== epoch:285, train acc:0.962, test acc:0.8609 ===\n",
            "train loss:0.12157975306018186\n",
            "train loss:0.15517953943658405\n",
            "train loss:0.1603887030563501\n",
            "train loss:0.09815999542057931\n",
            "train loss:0.14509318738988303\n",
            "train loss:0.2119992464870366\n",
            "train loss:0.14712579389498365\n",
            "train loss:0.11985951772361778\n",
            "train loss:0.11461939236053748\n",
            "train loss:0.11555359544814556\n",
            "=== epoch:286, train acc:0.963, test acc:0.86 ===\n",
            "train loss:0.13971036738987158\n",
            "train loss:0.15638543130920135\n",
            "train loss:0.25954537807989714\n",
            "train loss:0.1088648808175301\n",
            "train loss:0.15995181215760504\n",
            "train loss:0.1978884531295007\n",
            "train loss:0.11750974126261861\n",
            "train loss:0.1362179498817188\n",
            "train loss:0.14213430229164029\n",
            "train loss:0.1304795933089393\n",
            "=== epoch:287, train acc:0.965, test acc:0.863 ===\n",
            "train loss:0.19894584163135895\n",
            "train loss:0.16313307745519562\n",
            "train loss:0.17879439433122163\n",
            "train loss:0.16172429994968088\n",
            "train loss:0.1544126207310092\n",
            "train loss:0.18363558689963566\n",
            "train loss:0.12701285092497472\n",
            "train loss:0.1542816186907519\n",
            "train loss:0.1631355254869646\n",
            "train loss:0.12329080884870175\n",
            "=== epoch:288, train acc:0.967, test acc:0.8622 ===\n",
            "train loss:0.12327000667167722\n",
            "train loss:0.14659433272796704\n",
            "train loss:0.1423778217679404\n",
            "train loss:0.18831537755166927\n",
            "train loss:0.13834519690858685\n",
            "train loss:0.13151012141885435\n",
            "train loss:0.15280131686586468\n",
            "train loss:0.12571890966744628\n",
            "train loss:0.10903688594915356\n",
            "train loss:0.13024312904759894\n",
            "=== epoch:289, train acc:0.968, test acc:0.8623 ===\n",
            "train loss:0.11426558426135074\n",
            "train loss:0.1234037484908478\n",
            "train loss:0.157694590157379\n",
            "train loss:0.140040070233478\n",
            "train loss:0.145313024859979\n",
            "train loss:0.2642558848160838\n",
            "train loss:0.16326321997600368\n",
            "train loss:0.1360653490509717\n",
            "train loss:0.09423407327167574\n",
            "train loss:0.14743014288967612\n",
            "=== epoch:290, train acc:0.964, test acc:0.8613 ===\n",
            "train loss:0.12035093867116614\n",
            "train loss:0.13878439865507342\n",
            "train loss:0.11248427819076319\n",
            "train loss:0.215608184698019\n",
            "train loss:0.1941517232540295\n",
            "train loss:0.18539684356012232\n",
            "train loss:0.08986956585969848\n",
            "train loss:0.1506790040845237\n",
            "train loss:0.13814422914129398\n",
            "train loss:0.09125323339105956\n",
            "=== epoch:291, train acc:0.968, test acc:0.8657 ===\n",
            "train loss:0.1299165963465116\n",
            "train loss:0.17307277449600592\n",
            "train loss:0.099106595368991\n",
            "train loss:0.25806527910045984\n",
            "train loss:0.12421644226708581\n",
            "train loss:0.10812621732891717\n",
            "train loss:0.1379694149721198\n",
            "train loss:0.11332629339059525\n",
            "train loss:0.14268918879343434\n",
            "train loss:0.126948558605363\n",
            "=== epoch:292, train acc:0.971, test acc:0.8621 ===\n",
            "train loss:0.18921461761178526\n",
            "train loss:0.09161166869264666\n",
            "train loss:0.09671179358167209\n",
            "train loss:0.19344453973336465\n",
            "train loss:0.11392492422532083\n",
            "train loss:0.10860114670390489\n",
            "train loss:0.09864299630932509\n",
            "train loss:0.12500275151590795\n",
            "train loss:0.07322707444662681\n",
            "train loss:0.07546596410313851\n",
            "=== epoch:293, train acc:0.967, test acc:0.8647 ===\n",
            "train loss:0.12043469296129466\n",
            "train loss:0.19340529312010277\n",
            "train loss:0.1973720855583474\n",
            "train loss:0.14271590749807725\n",
            "train loss:0.11272413317474785\n",
            "train loss:0.12114595864573938\n",
            "train loss:0.10055831752327805\n",
            "train loss:0.12286443321515185\n",
            "train loss:0.14492728887358497\n",
            "train loss:0.08492167121319065\n",
            "=== epoch:294, train acc:0.964, test acc:0.8613 ===\n",
            "train loss:0.1799432194022004\n",
            "train loss:0.14857676512458906\n",
            "train loss:0.1565265515570218\n",
            "train loss:0.1403007156164753\n",
            "train loss:0.08192102423906265\n",
            "train loss:0.13569268982290847\n",
            "train loss:0.0972174411122543\n",
            "train loss:0.11902286287775105\n",
            "train loss:0.10907802293948762\n",
            "train loss:0.08795258281133743\n",
            "=== epoch:295, train acc:0.967, test acc:0.8629 ===\n",
            "train loss:0.19527104715052893\n",
            "train loss:0.10834557570051884\n",
            "train loss:0.10286950080629399\n",
            "train loss:0.16778680565348625\n",
            "train loss:0.0867533999409737\n",
            "train loss:0.1754227088740456\n",
            "train loss:0.09332106104458303\n",
            "train loss:0.1712440766783413\n",
            "train loss:0.11302015705691859\n",
            "train loss:0.1210595455767733\n",
            "=== epoch:296, train acc:0.968, test acc:0.8631 ===\n",
            "train loss:0.16892092247462298\n",
            "train loss:0.15717753620653915\n",
            "train loss:0.11806558563182382\n",
            "train loss:0.1139805980394638\n",
            "train loss:0.12581414734912547\n",
            "train loss:0.1088197622660232\n",
            "train loss:0.11920221223005846\n",
            "train loss:0.055782632213919464\n",
            "train loss:0.17147252452310696\n",
            "train loss:0.10566792714177252\n",
            "=== epoch:297, train acc:0.97, test acc:0.865 ===\n",
            "train loss:0.12243344280362595\n",
            "train loss:0.11790711493761734\n",
            "train loss:0.11867427003972407\n",
            "train loss:0.11923601376668862\n",
            "train loss:0.1771444184552367\n",
            "train loss:0.12030021304381659\n",
            "train loss:0.09475153935140158\n",
            "train loss:0.09883213142727154\n",
            "train loss:0.07738580454414327\n",
            "train loss:0.1100553924081822\n",
            "=== epoch:298, train acc:0.969, test acc:0.8638 ===\n",
            "train loss:0.15505416871872224\n",
            "train loss:0.09370506754775318\n",
            "train loss:0.12148791175003802\n",
            "train loss:0.11449466009477786\n",
            "train loss:0.12074830512707464\n",
            "train loss:0.16546052908702516\n",
            "train loss:0.1509726187584662\n",
            "train loss:0.11591582805043933\n",
            "train loss:0.23453323899135475\n",
            "train loss:0.13984720785497573\n",
            "=== epoch:299, train acc:0.97, test acc:0.867 ===\n",
            "train loss:0.12657879660124846\n",
            "train loss:0.10247766081743331\n",
            "train loss:0.15602915600325057\n",
            "train loss:0.0796939216044819\n",
            "train loss:0.15515121949799535\n",
            "train loss:0.15194603900682063\n",
            "train loss:0.0967845862758191\n",
            "train loss:0.08882599365043545\n",
            "train loss:0.12791484042197732\n",
            "train loss:0.09022664624741594\n",
            "=== epoch:300, train acc:0.971, test acc:0.8676 ===\n",
            "train loss:0.1363027716973721\n",
            "train loss:0.11240818551575714\n",
            "train loss:0.12582922996799498\n",
            "train loss:0.10359174320009502\n",
            "train loss:0.21697830922055997\n",
            "train loss:0.10129832631961276\n",
            "train loss:0.12274062813081038\n",
            "train loss:0.13824539977167974\n",
            "train loss:0.12892579204807383\n",
            "train loss:0.1007647486532017\n",
            "=== epoch:301, train acc:0.968, test acc:0.8667 ===\n",
            "train loss:0.17157126764896\n",
            "train loss:0.10960303947023085\n",
            "train loss:0.18867811799507805\n",
            "train loss:0.11606262284848873\n",
            "train loss:0.15632882788595548\n",
            "train loss:0.07782745449886647\n",
            "train loss:0.1471784025574473\n",
            "train loss:0.12925396807067072\n",
            "train loss:0.17392520498245823\n",
            "train loss:0.11748672331565972\n",
            "=== epoch:302, train acc:0.972, test acc:0.8647 ===\n",
            "train loss:0.11059706564790982\n",
            "train loss:0.12408500285779661\n",
            "train loss:0.10645202345747715\n",
            "train loss:0.13898094625320417\n",
            "train loss:0.10731963636239852\n",
            "train loss:0.15065319949981595\n",
            "train loss:0.13731984171150632\n",
            "train loss:0.11772808712071318\n",
            "train loss:0.18093852181388395\n",
            "train loss:0.07742897458124054\n",
            "=== epoch:303, train acc:0.972, test acc:0.8655 ===\n",
            "train loss:0.2047121173921089\n",
            "train loss:0.11246515923702521\n",
            "train loss:0.1205461481726338\n",
            "train loss:0.19626215294256333\n",
            "train loss:0.0940328148936061\n",
            "train loss:0.12410297893689086\n",
            "train loss:0.09423736581782644\n",
            "train loss:0.10989262134732891\n",
            "train loss:0.17496293255336567\n",
            "train loss:0.09477610797506855\n",
            "=== epoch:304, train acc:0.972, test acc:0.866 ===\n",
            "train loss:0.09464337568435242\n",
            "train loss:0.11483737657198978\n",
            "train loss:0.11495748729794755\n",
            "train loss:0.06960438951868357\n",
            "train loss:0.11509698147845655\n",
            "train loss:0.10434273300468129\n",
            "train loss:0.1275222634144032\n",
            "train loss:0.1885998405838998\n",
            "train loss:0.08344187724774434\n",
            "train loss:0.1201947937420988\n",
            "=== epoch:305, train acc:0.974, test acc:0.8687 ===\n",
            "train loss:0.0911168337189946\n",
            "train loss:0.17869337098950414\n",
            "train loss:0.07789421803965588\n",
            "train loss:0.12498522738026153\n",
            "train loss:0.10467008398792087\n",
            "train loss:0.12473759394002679\n",
            "train loss:0.16072730476267005\n",
            "train loss:0.08914422965551148\n",
            "train loss:0.1266315153707722\n",
            "train loss:0.10725650076191037\n",
            "=== epoch:306, train acc:0.977, test acc:0.8671 ===\n",
            "train loss:0.12516809448565577\n",
            "train loss:0.12946348021942003\n",
            "train loss:0.1023191428173938\n",
            "train loss:0.08357614498518824\n",
            "train loss:0.11737118106705204\n",
            "train loss:0.1752810323072596\n",
            "train loss:0.10888162103077886\n",
            "train loss:0.0885521273489117\n",
            "train loss:0.12484499463728416\n",
            "train loss:0.12012222641155741\n",
            "=== epoch:307, train acc:0.977, test acc:0.8686 ===\n",
            "train loss:0.14119564546453905\n",
            "train loss:0.09858585594668316\n",
            "train loss:0.14606050620721825\n",
            "train loss:0.1104121819802827\n",
            "train loss:0.11151109994048422\n",
            "train loss:0.09881284150886778\n",
            "train loss:0.12360301565517115\n",
            "train loss:0.08383533683640393\n",
            "train loss:0.1150737923955203\n",
            "train loss:0.10492224243705621\n",
            "=== epoch:308, train acc:0.975, test acc:0.8679 ===\n",
            "train loss:0.145070930214929\n",
            "train loss:0.10196252366106155\n",
            "train loss:0.08881813766052044\n",
            "train loss:0.16578747719427345\n",
            "train loss:0.12047838478897117\n",
            "train loss:0.1138881126430795\n",
            "train loss:0.1142377615202389\n",
            "train loss:0.09204530244815368\n",
            "train loss:0.11127733811201464\n",
            "train loss:0.07198004877829897\n",
            "=== epoch:309, train acc:0.974, test acc:0.8646 ===\n",
            "train loss:0.12095104692708494\n",
            "train loss:0.14850951051970143\n",
            "train loss:0.13887272569256673\n",
            "train loss:0.077684102437727\n",
            "train loss:0.09800965501704581\n",
            "train loss:0.14723222177601847\n",
            "train loss:0.09090093938495157\n",
            "train loss:0.10871969873270476\n",
            "train loss:0.08480596759906339\n",
            "train loss:0.15833792023746973\n",
            "=== epoch:310, train acc:0.976, test acc:0.8641 ===\n",
            "train loss:0.09648078423906234\n",
            "train loss:0.12921780431641303\n",
            "train loss:0.08661437995245327\n",
            "train loss:0.1254470954311112\n",
            "train loss:0.11568747662125947\n",
            "train loss:0.11507879296835638\n",
            "train loss:0.1359931625990757\n",
            "train loss:0.11790628813431216\n",
            "train loss:0.13673741524992727\n",
            "train loss:0.1002923612645082\n",
            "=== epoch:311, train acc:0.972, test acc:0.8652 ===\n",
            "train loss:0.07088176200018363\n",
            "train loss:0.0837303218544797\n",
            "train loss:0.0913429830631975\n",
            "train loss:0.08330530205231897\n",
            "train loss:0.06473220637062502\n",
            "train loss:0.1201183921400248\n",
            "train loss:0.07619018884697257\n",
            "train loss:0.14311897282497532\n",
            "train loss:0.08736559266299655\n",
            "train loss:0.09425666213193297\n",
            "=== epoch:312, train acc:0.971, test acc:0.865 ===\n",
            "train loss:0.1311606369148005\n",
            "train loss:0.1462257189210073\n",
            "train loss:0.0943520488647847\n",
            "train loss:0.11004697829984218\n",
            "train loss:0.10170581426474688\n",
            "train loss:0.1262620407340548\n",
            "train loss:0.09185258942327831\n",
            "train loss:0.15805432359633456\n",
            "train loss:0.12060466184559447\n",
            "train loss:0.07809890646826849\n",
            "=== epoch:313, train acc:0.976, test acc:0.8674 ===\n",
            "train loss:0.07276451860631555\n",
            "train loss:0.0905500192899616\n",
            "train loss:0.06414222030519662\n",
            "train loss:0.07587499208090125\n",
            "train loss:0.10354008665486558\n",
            "train loss:0.10323570822059952\n",
            "train loss:0.08411902731614859\n",
            "train loss:0.07421865700442343\n",
            "train loss:0.06767538322836467\n",
            "train loss:0.10900282259027161\n",
            "=== epoch:314, train acc:0.975, test acc:0.8692 ===\n",
            "train loss:0.08915686351414678\n",
            "train loss:0.09812797250583954\n",
            "train loss:0.11403209327782596\n",
            "train loss:0.09137114652842124\n",
            "train loss:0.05776294785905117\n",
            "train loss:0.12011005523190586\n",
            "train loss:0.07325024570047302\n",
            "train loss:0.09610375840940096\n",
            "train loss:0.10092832794256715\n",
            "train loss:0.10111825899891339\n",
            "=== epoch:315, train acc:0.975, test acc:0.8691 ===\n",
            "train loss:0.11246967947151737\n",
            "train loss:0.10244300989893493\n",
            "train loss:0.059134439834396174\n",
            "train loss:0.05572857952315183\n",
            "train loss:0.058284225322457466\n",
            "train loss:0.09071237560252103\n",
            "train loss:0.05969904550077916\n",
            "train loss:0.10974975494571827\n",
            "train loss:0.12536262323496597\n",
            "train loss:0.13271403535956405\n",
            "=== epoch:316, train acc:0.975, test acc:0.8667 ===\n",
            "train loss:0.10961896186767946\n",
            "train loss:0.1076287252457303\n",
            "train loss:0.10162355536675133\n",
            "train loss:0.10393816495037185\n",
            "train loss:0.17878948295206257\n",
            "train loss:0.12972003434091278\n",
            "train loss:0.11208611850736809\n",
            "train loss:0.12798435809860484\n",
            "train loss:0.10877718215700832\n",
            "train loss:0.15198573733454684\n",
            "=== epoch:317, train acc:0.975, test acc:0.8684 ===\n",
            "train loss:0.07536647278388778\n",
            "train loss:0.09201885393079491\n",
            "train loss:0.12213987050422741\n",
            "train loss:0.12770883175530418\n",
            "train loss:0.11179934767274066\n",
            "train loss:0.12304171020755017\n",
            "train loss:0.14629815221008258\n",
            "train loss:0.04642847066430174\n",
            "train loss:0.09657802033796895\n",
            "train loss:0.14686166247434845\n",
            "=== epoch:318, train acc:0.977, test acc:0.8684 ===\n",
            "train loss:0.12358597935375397\n",
            "train loss:0.09608748369414176\n",
            "train loss:0.0967249371556852\n",
            "train loss:0.09924490315918166\n",
            "train loss:0.06742162065213739\n",
            "train loss:0.08339098123780093\n",
            "train loss:0.12511807357310029\n",
            "train loss:0.13862915151723568\n",
            "train loss:0.0770933206652536\n",
            "train loss:0.12449324613989782\n",
            "=== epoch:319, train acc:0.976, test acc:0.8685 ===\n",
            "train loss:0.08342462041749026\n",
            "train loss:0.07487787067344959\n",
            "train loss:0.08892033737320641\n",
            "train loss:0.09930742425706784\n",
            "train loss:0.10080403860771861\n",
            "train loss:0.10917896696127456\n",
            "train loss:0.08277340379879453\n",
            "train loss:0.12532857289472238\n",
            "train loss:0.11134020789494463\n",
            "train loss:0.06847047099840768\n",
            "=== epoch:320, train acc:0.978, test acc:0.8681 ===\n",
            "train loss:0.14840409726772594\n",
            "train loss:0.08632421942714041\n",
            "train loss:0.13048089238645802\n",
            "train loss:0.06889117891540544\n",
            "train loss:0.10691690414400704\n",
            "train loss:0.09797296068996805\n",
            "train loss:0.11441945475281827\n",
            "train loss:0.09870963475214474\n",
            "train loss:0.11724674106253279\n",
            "train loss:0.13175739549333446\n",
            "=== epoch:321, train acc:0.976, test acc:0.8694 ===\n",
            "train loss:0.08244874509507265\n",
            "train loss:0.11217891102460069\n",
            "train loss:0.09459939365297275\n",
            "train loss:0.09610265997306731\n",
            "train loss:0.05912565620636649\n",
            "train loss:0.08591899480361526\n",
            "train loss:0.0652031289122849\n",
            "train loss:0.09187057908337165\n",
            "train loss:0.0642872203550171\n",
            "train loss:0.08879404374768977\n",
            "=== epoch:322, train acc:0.978, test acc:0.8694 ===\n",
            "train loss:0.059887370571511056\n",
            "train loss:0.18154560136012404\n",
            "train loss:0.14440234020514162\n",
            "train loss:0.07515745560947926\n",
            "train loss:0.11023327250150328\n",
            "train loss:0.07641624082112765\n",
            "train loss:0.07057293019184238\n",
            "train loss:0.11348601526389712\n",
            "train loss:0.07918701912475172\n",
            "train loss:0.08201480326287318\n",
            "=== epoch:323, train acc:0.978, test acc:0.867 ===\n",
            "train loss:0.12365867599968747\n",
            "train loss:0.10097798820856164\n",
            "train loss:0.09559703150198634\n",
            "train loss:0.0476623081994414\n",
            "train loss:0.0717685572286773\n",
            "train loss:0.05030863572673782\n",
            "train loss:0.06736792606588622\n",
            "train loss:0.12329327772474473\n",
            "train loss:0.05408353187956005\n",
            "train loss:0.11736994710250602\n",
            "=== epoch:324, train acc:0.978, test acc:0.8668 ===\n",
            "train loss:0.060383710478159935\n",
            "train loss:0.07978792987456447\n",
            "train loss:0.08698512444008726\n",
            "train loss:0.11806111446561841\n",
            "train loss:0.07607465367084865\n",
            "train loss:0.09387036120875353\n",
            "train loss:0.06935451959030761\n",
            "train loss:0.09092885727789754\n",
            "train loss:0.13991586026479733\n",
            "train loss:0.05075188343222254\n",
            "=== epoch:325, train acc:0.978, test acc:0.8667 ===\n",
            "train loss:0.06889902313255834\n",
            "train loss:0.13929902968968608\n",
            "train loss:0.11437552828193592\n",
            "train loss:0.08803689599543016\n",
            "train loss:0.1091972159609018\n",
            "train loss:0.08751528416754027\n",
            "train loss:0.0969556569195576\n",
            "train loss:0.08932808552786659\n",
            "train loss:0.12007299276753543\n",
            "train loss:0.08361456921449426\n",
            "=== epoch:326, train acc:0.98, test acc:0.87 ===\n",
            "train loss:0.08419961833384831\n",
            "train loss:0.0724071314087274\n",
            "train loss:0.12706399214933178\n",
            "train loss:0.06341721539189588\n",
            "train loss:0.07262714922052263\n",
            "train loss:0.07426988321327513\n",
            "train loss:0.09806090285420493\n",
            "train loss:0.09612003202344821\n",
            "train loss:0.07631549276078094\n",
            "train loss:0.11617642211024445\n",
            "=== epoch:327, train acc:0.981, test acc:0.8717 ===\n",
            "train loss:0.07621951306975572\n",
            "train loss:0.1150917269574713\n",
            "train loss:0.05744931079879555\n",
            "train loss:0.11024226440868816\n",
            "train loss:0.08088394130688908\n",
            "train loss:0.05315448022536751\n",
            "train loss:0.06601001796060696\n",
            "train loss:0.06409938494177561\n",
            "train loss:0.07300021124809114\n",
            "train loss:0.09990167371466695\n",
            "=== epoch:328, train acc:0.98, test acc:0.8729 ===\n",
            "train loss:0.07693881160490533\n",
            "train loss:0.04502936635118612\n",
            "train loss:0.05309934628494708\n",
            "train loss:0.1260184753006356\n",
            "train loss:0.08307550234781093\n",
            "train loss:0.09766763633703239\n",
            "train loss:0.10114077466351443\n",
            "train loss:0.09245738500597589\n",
            "train loss:0.0967196257115174\n",
            "train loss:0.1396772977197111\n",
            "=== epoch:329, train acc:0.978, test acc:0.8712 ===\n",
            "train loss:0.09892991172178803\n",
            "train loss:0.06562942933505149\n",
            "train loss:0.061559831286229126\n",
            "train loss:0.08845717361118798\n",
            "train loss:0.09209277359534593\n",
            "train loss:0.05578850293256262\n",
            "train loss:0.06622917355502714\n",
            "train loss:0.09109414901601699\n",
            "train loss:0.06136967341834807\n",
            "train loss:0.08669353716995853\n",
            "=== epoch:330, train acc:0.981, test acc:0.8702 ===\n",
            "train loss:0.073109478637213\n",
            "train loss:0.08159405588649857\n",
            "train loss:0.10337611049383261\n",
            "train loss:0.07186005003110606\n",
            "train loss:0.04013975960932915\n",
            "train loss:0.051346424725872704\n",
            "train loss:0.06971718829616697\n",
            "train loss:0.19873431552794174\n",
            "train loss:0.07289269248218717\n",
            "train loss:0.058646293852309093\n",
            "=== epoch:331, train acc:0.981, test acc:0.8724 ===\n",
            "train loss:0.09779756307687747\n",
            "train loss:0.09766151965365796\n",
            "train loss:0.09065220727248223\n",
            "train loss:0.0723724643322184\n",
            "train loss:0.0709747906853868\n",
            "train loss:0.07977904188584263\n",
            "train loss:0.14542916349572574\n",
            "train loss:0.04394529054878622\n",
            "train loss:0.07095087117211751\n",
            "train loss:0.057734355015269495\n",
            "=== epoch:332, train acc:0.981, test acc:0.8689 ===\n",
            "train loss:0.0680980337401188\n",
            "train loss:0.1296182829856237\n",
            "train loss:0.0676536838026003\n",
            "train loss:0.056999064843169994\n",
            "train loss:0.09696614060302107\n",
            "train loss:0.07963448621936604\n",
            "train loss:0.046009941928881526\n",
            "train loss:0.02670929881141915\n",
            "train loss:0.0971654444271392\n",
            "train loss:0.08524169081019072\n",
            "=== epoch:333, train acc:0.984, test acc:0.8727 ===\n",
            "train loss:0.07520203312494728\n",
            "train loss:0.08090360971791473\n",
            "train loss:0.07082727300525896\n",
            "train loss:0.07453897341679766\n",
            "train loss:0.09615361646530596\n",
            "train loss:0.062385042102119835\n",
            "train loss:0.08460131606101634\n",
            "train loss:0.08252593423614824\n",
            "train loss:0.05801203536760236\n",
            "train loss:0.06502790043267914\n",
            "=== epoch:334, train acc:0.983, test acc:0.8744 ===\n",
            "train loss:0.0560481954470929\n",
            "train loss:0.07571227969338434\n",
            "train loss:0.07193076051474379\n",
            "train loss:0.08607038354499155\n",
            "train loss:0.06633701529846908\n",
            "train loss:0.06149957766172357\n",
            "train loss:0.14070840316774869\n",
            "train loss:0.08037859144661195\n",
            "train loss:0.09350826199924173\n",
            "train loss:0.08107073247344315\n",
            "=== epoch:335, train acc:0.985, test acc:0.8723 ===\n",
            "train loss:0.03514865931523942\n",
            "train loss:0.08499911080429699\n",
            "train loss:0.0969946879030255\n",
            "train loss:0.07300112607258538\n",
            "train loss:0.0657289196367507\n",
            "train loss:0.10938622194863631\n",
            "train loss:0.056666046984732106\n",
            "train loss:0.09523161947063592\n",
            "train loss:0.11353235623498756\n",
            "train loss:0.12931429818719406\n",
            "=== epoch:336, train acc:0.983, test acc:0.8733 ===\n",
            "train loss:0.05716352205517322\n",
            "train loss:0.051390767652670394\n",
            "train loss:0.0572069073081469\n",
            "train loss:0.08470146419115984\n",
            "train loss:0.05902776476573889\n",
            "train loss:0.06814992068295785\n",
            "train loss:0.07977532609602363\n",
            "train loss:0.057338564179843565\n",
            "train loss:0.08628868268357896\n",
            "train loss:0.1052113058899763\n",
            "=== epoch:337, train acc:0.984, test acc:0.8735 ===\n",
            "train loss:0.1190063424125694\n",
            "train loss:0.06204183518599253\n",
            "train loss:0.06708153048803193\n",
            "train loss:0.06298774782015487\n",
            "train loss:0.04213948160834138\n",
            "train loss:0.06867826174451015\n",
            "train loss:0.06302068405078161\n",
            "train loss:0.07718979736446713\n",
            "train loss:0.021053423674750313\n",
            "train loss:0.10031985825070286\n",
            "=== epoch:338, train acc:0.985, test acc:0.8757 ===\n",
            "train loss:0.0458038390127876\n",
            "train loss:0.11159896005712763\n",
            "train loss:0.08773577984775978\n",
            "train loss:0.052655746608141596\n",
            "train loss:0.08299649706989477\n",
            "train loss:0.05410915779301541\n",
            "train loss:0.07368375220898832\n",
            "train loss:0.06498190945015381\n",
            "train loss:0.05106544519584391\n",
            "train loss:0.06565101964201964\n",
            "=== epoch:339, train acc:0.986, test acc:0.8747 ===\n",
            "train loss:0.05149244806636284\n",
            "train loss:0.04224767142694405\n",
            "train loss:0.06001706620773719\n",
            "train loss:0.0950661289546286\n",
            "train loss:0.05091701995585161\n",
            "train loss:0.10566662969657328\n",
            "train loss:0.06375748560396668\n",
            "train loss:0.1075327196248365\n",
            "train loss:0.11632143242379493\n",
            "train loss:0.04647334109069593\n",
            "=== epoch:340, train acc:0.986, test acc:0.8742 ===\n",
            "train loss:0.08438671073154232\n",
            "train loss:0.06980103203838978\n",
            "train loss:0.070295984916588\n",
            "train loss:0.07108020656809946\n",
            "train loss:0.06351285504093844\n",
            "train loss:0.0486476203587408\n",
            "train loss:0.04068389202494626\n",
            "train loss:0.035662814596465\n",
            "train loss:0.07271101694679358\n",
            "train loss:0.06803771503406615\n",
            "=== epoch:341, train acc:0.986, test acc:0.8747 ===\n",
            "train loss:0.042146860591976386\n",
            "train loss:0.053762198255785175\n",
            "train loss:0.1054049104771813\n",
            "train loss:0.04019374589082899\n",
            "train loss:0.08405492202524059\n",
            "train loss:0.08117938533660989\n",
            "train loss:0.04686035801233743\n",
            "train loss:0.08214287651322193\n",
            "train loss:0.1283518690455976\n",
            "train loss:0.12421159910985517\n",
            "=== epoch:342, train acc:0.987, test acc:0.8756 ===\n",
            "train loss:0.05616658855853211\n",
            "train loss:0.09096095311165632\n",
            "train loss:0.05538674266870963\n",
            "train loss:0.05111374788337424\n",
            "train loss:0.061948828671514126\n",
            "train loss:0.047404970527040395\n",
            "train loss:0.05206430493624775\n",
            "train loss:0.09640165561188647\n",
            "train loss:0.10531478854633748\n",
            "train loss:0.08140153795458666\n",
            "=== epoch:343, train acc:0.988, test acc:0.8754 ===\n",
            "train loss:0.07264423686269722\n",
            "train loss:0.05804548062636337\n",
            "train loss:0.07187715631244364\n",
            "train loss:0.09142797384215885\n",
            "train loss:0.07113991471094075\n",
            "train loss:0.04779029410987778\n",
            "train loss:0.05987357337491256\n",
            "train loss:0.07710619105805643\n",
            "train loss:0.05558189210596108\n",
            "train loss:0.06523189910532783\n",
            "=== epoch:344, train acc:0.988, test acc:0.8737 ===\n",
            "train loss:0.08112159967978369\n",
            "train loss:0.05043598931087882\n",
            "train loss:0.043104795314442626\n",
            "train loss:0.05240473357577584\n",
            "train loss:0.05761890936682417\n",
            "train loss:0.04151093664221381\n",
            "train loss:0.07580003925550646\n",
            "train loss:0.041078224412996175\n",
            "train loss:0.07292727678087822\n",
            "train loss:0.048274589837201634\n",
            "=== epoch:345, train acc:0.988, test acc:0.8728 ===\n",
            "train loss:0.08563534392041791\n",
            "train loss:0.04612749424080831\n",
            "train loss:0.13456124093914767\n",
            "train loss:0.0832629411453567\n",
            "train loss:0.058555751029966956\n",
            "train loss:0.059320798933305996\n",
            "train loss:0.04567832852673261\n",
            "train loss:0.038729280856861524\n",
            "train loss:0.09204000732111775\n",
            "train loss:0.07545168389261439\n",
            "=== epoch:346, train acc:0.987, test acc:0.874 ===\n",
            "train loss:0.07848000491794772\n",
            "train loss:0.12731979617372347\n",
            "train loss:0.0876336434770298\n",
            "train loss:0.11101432872946475\n",
            "train loss:0.06258558985654135\n",
            "train loss:0.06153778005158029\n",
            "train loss:0.05703468334732532\n",
            "train loss:0.047502526491300184\n",
            "train loss:0.0961244067813384\n",
            "train loss:0.06427098188284196\n",
            "=== epoch:347, train acc:0.988, test acc:0.8735 ===\n",
            "train loss:0.06398994163221251\n",
            "train loss:0.051120570127900805\n",
            "train loss:0.049294798232682874\n",
            "train loss:0.0501866228705798\n",
            "train loss:0.08855963802502431\n",
            "train loss:0.046786453327311524\n",
            "train loss:0.0343348045385502\n",
            "train loss:0.0513356471166505\n",
            "train loss:0.04762008378138507\n",
            "train loss:0.10981404577851482\n",
            "=== epoch:348, train acc:0.989, test acc:0.8746 ===\n",
            "train loss:0.07509505545188562\n",
            "train loss:0.11378857534108984\n",
            "train loss:0.06773539987153829\n",
            "train loss:0.05850273245666714\n",
            "train loss:0.0556357041839717\n",
            "train loss:0.0409135105339024\n",
            "train loss:0.06369662072896029\n",
            "train loss:0.06893270387134065\n",
            "train loss:0.10162360818857609\n",
            "train loss:0.0567773261007198\n",
            "=== epoch:349, train acc:0.99, test acc:0.8769 ===\n",
            "train loss:0.05225066269055669\n",
            "train loss:0.07679388785419208\n",
            "train loss:0.05940207269750315\n",
            "train loss:0.04812464269072333\n",
            "train loss:0.06089182989386946\n",
            "train loss:0.08514515940139349\n",
            "train loss:0.07949597148310544\n",
            "train loss:0.04530622157441615\n",
            "train loss:0.05399589964173718\n",
            "train loss:0.08224210880651162\n",
            "=== epoch:350, train acc:0.991, test acc:0.8757 ===\n",
            "train loss:0.049593258376414956\n",
            "train loss:0.053078214609045125\n",
            "train loss:0.029469640012250036\n",
            "train loss:0.0671777704461301\n",
            "train loss:0.04477905036652982\n",
            "train loss:0.04221560295257425\n",
            "train loss:0.0932985202005995\n",
            "train loss:0.06396237102659386\n",
            "train loss:0.048084348539926956\n",
            "train loss:0.07013999946023713\n",
            "=== epoch:351, train acc:0.991, test acc:0.8757 ===\n",
            "train loss:0.056824448899256925\n",
            "train loss:0.055174584646844764\n",
            "train loss:0.09295185531464377\n",
            "train loss:0.06888898638971869\n",
            "train loss:0.05961859298967254\n",
            "train loss:0.04152787825738783\n",
            "train loss:0.05718259179867599\n",
            "train loss:0.06143072913912293\n",
            "train loss:0.04219804590639312\n",
            "train loss:0.07095622384486278\n",
            "=== epoch:352, train acc:0.991, test acc:0.8755 ===\n",
            "train loss:0.06965437114187993\n",
            "train loss:0.062149661835569164\n",
            "train loss:0.05354671222626071\n",
            "train loss:0.03374038128654787\n",
            "train loss:0.07530433947859497\n",
            "train loss:0.06808578582498527\n",
            "train loss:0.04652007377274459\n",
            "train loss:0.06647034036777882\n",
            "train loss:0.09540243375829015\n",
            "train loss:0.05518430305939212\n",
            "=== epoch:353, train acc:0.99, test acc:0.8785 ===\n",
            "train loss:0.0563218554787787\n",
            "train loss:0.06307526226596318\n",
            "train loss:0.04453020844397149\n",
            "train loss:0.07448436147601055\n",
            "train loss:0.08653955003934051\n",
            "train loss:0.04701201859126817\n",
            "train loss:0.06655213513538272\n",
            "train loss:0.07487337154408\n",
            "train loss:0.06265318718973417\n",
            "train loss:0.05641766167886786\n",
            "=== epoch:354, train acc:0.989, test acc:0.8732 ===\n",
            "train loss:0.05240549997612457\n",
            "train loss:0.09291965149804488\n",
            "train loss:0.06264282939717516\n",
            "train loss:0.06019899526642563\n",
            "train loss:0.0785521750795718\n",
            "train loss:0.06621586575238239\n",
            "train loss:0.064322565414729\n",
            "train loss:0.05240999610130778\n",
            "train loss:0.07377902272968385\n",
            "train loss:0.0456371680442194\n",
            "=== epoch:355, train acc:0.988, test acc:0.8733 ===\n",
            "train loss:0.044304756830633465\n",
            "train loss:0.10124505537070373\n",
            "train loss:0.11807007370031468\n",
            "train loss:0.06324278243895538\n",
            "train loss:0.031230423738733658\n",
            "train loss:0.032792184069307895\n",
            "train loss:0.051728197936815816\n",
            "train loss:0.06896191956448393\n",
            "train loss:0.08460813028333668\n",
            "train loss:0.04916674499813627\n",
            "=== epoch:356, train acc:0.987, test acc:0.8739 ===\n",
            "train loss:0.11030467582132882\n",
            "train loss:0.061249572967310935\n",
            "train loss:0.05326220558085775\n",
            "train loss:0.07632451928080201\n",
            "train loss:0.054538956488609666\n",
            "train loss:0.04557718433555757\n",
            "train loss:0.02541969165555376\n",
            "train loss:0.08463394959082944\n",
            "train loss:0.040757963689374316\n",
            "train loss:0.04859548003456265\n",
            "=== epoch:357, train acc:0.989, test acc:0.8731 ===\n",
            "train loss:0.08017055617237316\n",
            "train loss:0.06912392038395887\n",
            "train loss:0.08764116102835989\n",
            "train loss:0.045841066589729\n",
            "train loss:0.07137657976328422\n",
            "train loss:0.033529303072130846\n",
            "train loss:0.044452357002307465\n",
            "train loss:0.04211120114931219\n",
            "train loss:0.04281751695204432\n",
            "train loss:0.046326004790321285\n",
            "=== epoch:358, train acc:0.989, test acc:0.8743 ===\n",
            "train loss:0.055139876182222665\n",
            "train loss:0.06968995451294327\n",
            "train loss:0.08104058790365593\n",
            "train loss:0.037099003425263156\n",
            "train loss:0.05956725229453502\n",
            "train loss:0.06530203011920553\n",
            "train loss:0.07675376401685362\n",
            "train loss:0.057437102274402234\n",
            "train loss:0.07378620176537569\n",
            "train loss:0.06670055259575616\n",
            "=== epoch:359, train acc:0.99, test acc:0.875 ===\n",
            "train loss:0.02749935948887503\n",
            "train loss:0.04384109656519817\n",
            "train loss:0.05043885564338712\n",
            "train loss:0.057466458305185604\n",
            "train loss:0.03542672024365847\n",
            "train loss:0.04759782249178647\n",
            "train loss:0.045324871331554155\n",
            "train loss:0.06426776284550079\n",
            "train loss:0.0681267800438758\n",
            "train loss:0.04557059261876253\n",
            "=== epoch:360, train acc:0.989, test acc:0.8737 ===\n",
            "train loss:0.044837516240269125\n",
            "train loss:0.04819608004896464\n",
            "train loss:0.03453504865245603\n",
            "train loss:0.05417682075984945\n",
            "train loss:0.04596456594921119\n",
            "train loss:0.03615485175293118\n",
            "train loss:0.03447403025703612\n",
            "train loss:0.05406832892968341\n",
            "train loss:0.04942118350965765\n",
            "train loss:0.047124909595597446\n",
            "=== epoch:361, train acc:0.989, test acc:0.8753 ===\n",
            "train loss:0.027739194906392362\n",
            "train loss:0.04517293837568559\n",
            "train loss:0.11787950898995529\n",
            "train loss:0.03340251631685862\n",
            "train loss:0.07863466809566495\n",
            "train loss:0.0671510001484491\n",
            "train loss:0.04375401408605392\n",
            "train loss:0.12282157866900131\n",
            "train loss:0.05845863009932223\n",
            "train loss:0.03496218710982514\n",
            "=== epoch:362, train acc:0.99, test acc:0.8764 ===\n",
            "train loss:0.04707419457351765\n",
            "train loss:0.049597543299768725\n",
            "train loss:0.0659151658464392\n",
            "train loss:0.025900700519284312\n",
            "train loss:0.05520157652505822\n",
            "train loss:0.0343194548764995\n",
            "train loss:0.05671747542706079\n",
            "train loss:0.06380389874897852\n",
            "train loss:0.027393785107419157\n",
            "train loss:0.046784544221271034\n",
            "=== epoch:363, train acc:0.992, test acc:0.8752 ===\n",
            "train loss:0.04417719040394071\n",
            "train loss:0.04303857374176791\n",
            "train loss:0.030372779929497128\n",
            "train loss:0.04810673568241357\n",
            "train loss:0.06254982925299253\n",
            "train loss:0.08866171739273582\n",
            "train loss:0.052172415441970085\n",
            "train loss:0.031590368157534326\n",
            "train loss:0.025467268205291854\n",
            "train loss:0.04074927785084406\n",
            "=== epoch:364, train acc:0.99, test acc:0.8751 ===\n",
            "train loss:0.040393792680888586\n",
            "train loss:0.059639789646807155\n",
            "train loss:0.08194144348889522\n",
            "train loss:0.059941720996376464\n",
            "train loss:0.041822639247572096\n",
            "train loss:0.0633563956069287\n",
            "train loss:0.046440802435934764\n",
            "train loss:0.07198246002552315\n",
            "train loss:0.06198679104441627\n",
            "train loss:0.04115817616783821\n",
            "=== epoch:365, train acc:0.993, test acc:0.8746 ===\n",
            "train loss:0.04165951123752578\n",
            "train loss:0.04404926387585352\n",
            "train loss:0.06836630189013229\n",
            "train loss:0.05098764693794524\n",
            "train loss:0.06255192129596093\n",
            "train loss:0.05684975953595553\n",
            "train loss:0.020591067654370937\n",
            "train loss:0.02941276955040679\n",
            "train loss:0.04658755926279386\n",
            "train loss:0.04565963305563864\n",
            "=== epoch:366, train acc:0.992, test acc:0.8752 ===\n",
            "train loss:0.06540831888090214\n",
            "train loss:0.05946114962454981\n",
            "train loss:0.0345495865651885\n",
            "train loss:0.04427996052303105\n",
            "train loss:0.04114079795998746\n",
            "train loss:0.057888411131193494\n",
            "train loss:0.04045502690100441\n",
            "train loss:0.058460358493445684\n",
            "train loss:0.06452466157126258\n",
            "train loss:0.07452987185955004\n",
            "=== epoch:367, train acc:0.993, test acc:0.8766 ===\n",
            "train loss:0.052500234943492936\n",
            "train loss:0.04347819689028211\n",
            "train loss:0.062106906189766005\n",
            "train loss:0.054389669916327606\n",
            "train loss:0.0404435122083663\n",
            "train loss:0.038682455992757714\n",
            "train loss:0.10157264478819965\n",
            "train loss:0.027219644073818272\n",
            "train loss:0.05495333139964624\n",
            "train loss:0.03505832220282672\n",
            "=== epoch:368, train acc:0.993, test acc:0.8763 ===\n",
            "train loss:0.04761363223992466\n",
            "train loss:0.06366944182738067\n",
            "train loss:0.041355553030144446\n",
            "train loss:0.056636292318646794\n",
            "train loss:0.059621475605401056\n",
            "train loss:0.05043887964549409\n",
            "train loss:0.05740051981389461\n",
            "train loss:0.06761917998043793\n",
            "train loss:0.05495027394191224\n",
            "train loss:0.03278223361148012\n",
            "=== epoch:369, train acc:0.993, test acc:0.8769 ===\n",
            "train loss:0.04379145887690949\n",
            "train loss:0.035662715315871646\n",
            "train loss:0.05186494839041558\n",
            "train loss:0.06294238199200743\n",
            "train loss:0.02043383665623533\n",
            "train loss:0.05574912519940797\n",
            "train loss:0.049170902313397595\n",
            "train loss:0.05982498521673877\n",
            "train loss:0.03251031982522505\n",
            "train loss:0.04449882321411651\n",
            "=== epoch:370, train acc:0.994, test acc:0.875 ===\n",
            "train loss:0.03059861502398241\n",
            "train loss:0.03446336556132056\n",
            "train loss:0.05432301448389855\n",
            "train loss:0.036142194663179465\n",
            "train loss:0.029396430478884135\n",
            "train loss:0.05301604915812514\n",
            "train loss:0.04834202626002792\n",
            "train loss:0.036803130177214656\n",
            "train loss:0.037065487185198275\n",
            "train loss:0.04129330333380202\n",
            "=== epoch:371, train acc:0.993, test acc:0.8774 ===\n",
            "train loss:0.0341114278479202\n",
            "train loss:0.12256328271692839\n",
            "train loss:0.029515861696994553\n",
            "train loss:0.054781276746920134\n",
            "train loss:0.05340750945777128\n",
            "train loss:0.04328876417203586\n",
            "train loss:0.04491933949719997\n",
            "train loss:0.04065284123514672\n",
            "train loss:0.0921877455011873\n",
            "train loss:0.052915531033755396\n",
            "=== epoch:372, train acc:0.995, test acc:0.8751 ===\n",
            "train loss:0.05053116553744664\n",
            "train loss:0.054489736152093265\n",
            "train loss:0.022587459451077218\n",
            "train loss:0.0352856995088845\n",
            "train loss:0.05921519835041447\n",
            "train loss:0.0420153179799538\n",
            "train loss:0.04844580104360806\n",
            "train loss:0.05229947693466677\n",
            "train loss:0.031751004890863875\n",
            "train loss:0.08369829839536426\n",
            "=== epoch:373, train acc:0.996, test acc:0.8752 ===\n",
            "train loss:0.08876110364012126\n",
            "train loss:0.04185778094997495\n",
            "train loss:0.04460019659886618\n",
            "train loss:0.029090879646721454\n",
            "train loss:0.04298383079424276\n",
            "train loss:0.053274173299433174\n",
            "train loss:0.06479893221639019\n",
            "train loss:0.02956728095831504\n",
            "train loss:0.05050395909251354\n",
            "train loss:0.027724787800848336\n",
            "=== epoch:374, train acc:0.996, test acc:0.8772 ===\n",
            "train loss:0.026964934609986425\n",
            "train loss:0.04958640786832427\n",
            "train loss:0.03583255234734535\n",
            "train loss:0.02913191498952924\n",
            "train loss:0.05105857051946476\n",
            "train loss:0.03243922523022449\n",
            "train loss:0.05752956190790643\n",
            "train loss:0.09435720335318147\n",
            "train loss:0.06183922693964265\n",
            "train loss:0.053378102599434776\n",
            "=== epoch:375, train acc:0.995, test acc:0.8764 ===\n",
            "train loss:0.04691055492942444\n",
            "train loss:0.04705846480066261\n",
            "train loss:0.04912432204122431\n",
            "train loss:0.02908117100135075\n",
            "train loss:0.040815896633512774\n",
            "train loss:0.05096871246829185\n",
            "train loss:0.04308260159104256\n",
            "train loss:0.03933396017646861\n",
            "train loss:0.035142009256580474\n",
            "train loss:0.04970614703926437\n",
            "=== epoch:376, train acc:0.995, test acc:0.8766 ===\n",
            "train loss:0.022834537175396866\n",
            "train loss:0.03398080578109217\n",
            "train loss:0.0641800297725725\n",
            "train loss:0.03348986391657978\n",
            "train loss:0.05037894052757088\n",
            "train loss:0.047825852706436967\n",
            "train loss:0.025324812201285112\n",
            "train loss:0.06158421689869268\n",
            "train loss:0.03466504058028869\n",
            "train loss:0.05499417206094111\n",
            "=== epoch:377, train acc:0.996, test acc:0.8782 ===\n",
            "train loss:0.033142492044236256\n",
            "train loss:0.0358784791994172\n",
            "train loss:0.026995087752559748\n",
            "train loss:0.07596129626692477\n",
            "train loss:0.025718736500204346\n",
            "train loss:0.04659502273756992\n",
            "train loss:0.03716504317937605\n",
            "train loss:0.046358168613839935\n",
            "train loss:0.054465977663745155\n",
            "train loss:0.04183857206967171\n",
            "=== epoch:378, train acc:0.996, test acc:0.8774 ===\n",
            "train loss:0.05373319510851186\n",
            "train loss:0.04560849116458166\n",
            "train loss:0.027978831940810415\n",
            "train loss:0.029307449060568164\n",
            "train loss:0.041943316321221336\n",
            "train loss:0.043824999253961314\n",
            "train loss:0.04076054802503065\n",
            "train loss:0.04746051894863225\n",
            "train loss:0.02360711434975922\n",
            "train loss:0.04500166767575054\n",
            "=== epoch:379, train acc:0.994, test acc:0.8772 ===\n",
            "train loss:0.03583928204115774\n",
            "train loss:0.02384214072056383\n",
            "train loss:0.05419271718119901\n",
            "train loss:0.04582676115049655\n",
            "train loss:0.028913801701325733\n",
            "train loss:0.03400086586233052\n",
            "train loss:0.04294247388545197\n",
            "train loss:0.03934585164966435\n",
            "train loss:0.04790720837061221\n",
            "train loss:0.0396355999502245\n",
            "=== epoch:380, train acc:0.993, test acc:0.8754 ===\n",
            "train loss:0.05878987856574262\n",
            "train loss:0.0561842728422596\n",
            "train loss:0.053489947986804946\n",
            "train loss:0.03107520908685348\n",
            "train loss:0.06290993946773137\n",
            "train loss:0.035772620260054545\n",
            "train loss:0.03435739643967732\n",
            "train loss:0.04277084137487516\n",
            "train loss:0.03832042413880679\n",
            "train loss:0.030773355502723188\n",
            "=== epoch:381, train acc:0.997, test acc:0.8776 ===\n",
            "train loss:0.040336319038850627\n",
            "train loss:0.030628213669804262\n",
            "train loss:0.028138247363998815\n",
            "train loss:0.026171171710042705\n",
            "train loss:0.048095367437787306\n",
            "train loss:0.04194384944688328\n",
            "train loss:0.02749570640852322\n",
            "train loss:0.0398948746394357\n",
            "train loss:0.03574213824342215\n",
            "train loss:0.020218002837303514\n",
            "=== epoch:382, train acc:0.996, test acc:0.8785 ===\n",
            "train loss:0.06089623849822244\n",
            "train loss:0.059954208171141055\n",
            "train loss:0.040263006668173375\n",
            "train loss:0.03240759873014908\n",
            "train loss:0.04532496292243506\n",
            "train loss:0.048989795650837234\n",
            "train loss:0.04426093797959471\n",
            "train loss:0.03610874848658348\n",
            "train loss:0.02533429130741092\n",
            "train loss:0.03371088917924361\n",
            "=== epoch:383, train acc:0.995, test acc:0.8772 ===\n",
            "train loss:0.021664274169534745\n",
            "train loss:0.059880593279059396\n",
            "train loss:0.08243925391550007\n",
            "train loss:0.04551300429303381\n",
            "train loss:0.042660924430728844\n",
            "train loss:0.039840467176924535\n",
            "train loss:0.03956626458583038\n",
            "train loss:0.05385092826502781\n",
            "train loss:0.029417318344334586\n",
            "train loss:0.042266475972904394\n",
            "=== epoch:384, train acc:0.995, test acc:0.8775 ===\n",
            "train loss:0.03342940834424366\n",
            "train loss:0.03797158437509395\n",
            "train loss:0.024252958835247033\n",
            "train loss:0.025525474951678985\n",
            "train loss:0.06879773310656172\n",
            "train loss:0.0448801398893849\n",
            "train loss:0.02544854888964307\n",
            "train loss:0.016967842563389436\n",
            "train loss:0.0336979934809725\n",
            "train loss:0.028459571382160105\n",
            "=== epoch:385, train acc:0.995, test acc:0.8753 ===\n",
            "train loss:0.017171222845066798\n",
            "train loss:0.029787839066209455\n",
            "train loss:0.04588072123575342\n",
            "train loss:0.03328980020855592\n",
            "train loss:0.037622333331338305\n",
            "train loss:0.0724916701004767\n",
            "train loss:0.030724023128771632\n",
            "train loss:0.035121591084589676\n",
            "train loss:0.029180010280965587\n",
            "train loss:0.03596881509663093\n",
            "=== epoch:386, train acc:0.996, test acc:0.8766 ===\n",
            "train loss:0.034739300327524945\n",
            "train loss:0.024200960315428108\n",
            "train loss:0.024136980397733855\n",
            "train loss:0.03721558146045356\n",
            "train loss:0.034894071345005655\n",
            "train loss:0.0612483604166786\n",
            "train loss:0.0384357284292976\n",
            "train loss:0.02956519431050153\n",
            "train loss:0.07811555174589717\n",
            "train loss:0.02782844600520613\n",
            "=== epoch:387, train acc:0.996, test acc:0.8764 ===\n",
            "train loss:0.028723318821154722\n",
            "train loss:0.03865513882015041\n",
            "train loss:0.038938281900632525\n",
            "train loss:0.03501737390364562\n",
            "train loss:0.030022027378999377\n",
            "train loss:0.015795160633640767\n",
            "train loss:0.060619677708811485\n",
            "train loss:0.08190788543976142\n",
            "train loss:0.016099441428545823\n",
            "train loss:0.023222255678943208\n",
            "=== epoch:388, train acc:0.996, test acc:0.8759 ===\n",
            "train loss:0.036885460379422634\n",
            "train loss:0.05017150931554051\n",
            "train loss:0.035270082788290774\n",
            "train loss:0.07236588923665695\n",
            "train loss:0.03559350184835033\n",
            "train loss:0.04683236590718489\n",
            "train loss:0.06015934783845887\n",
            "train loss:0.037871475358298386\n",
            "train loss:0.02613767383290464\n",
            "train loss:0.02422591783163985\n",
            "=== epoch:389, train acc:0.995, test acc:0.8763 ===\n",
            "train loss:0.030168287635953903\n",
            "train loss:0.03228025861962249\n",
            "train loss:0.017421220770155472\n",
            "train loss:0.026380936159677577\n",
            "train loss:0.01989527272223572\n",
            "train loss:0.04326807783095422\n",
            "train loss:0.02282393130593434\n",
            "train loss:0.023882190052544175\n",
            "train loss:0.024695308763255083\n",
            "train loss:0.0329913830654139\n",
            "=== epoch:390, train acc:0.996, test acc:0.8778 ===\n",
            "train loss:0.022992245776987105\n",
            "train loss:0.023306449683365073\n",
            "train loss:0.05769867180842354\n",
            "train loss:0.04270135367385402\n",
            "train loss:0.023284356468589788\n",
            "train loss:0.027810427184059523\n",
            "train loss:0.04734196629525027\n",
            "train loss:0.05363445113049845\n",
            "train loss:0.024837797507055292\n",
            "train loss:0.03147660815760484\n",
            "=== epoch:391, train acc:0.997, test acc:0.879 ===\n",
            "train loss:0.02801248730856719\n",
            "train loss:0.036115347547327564\n",
            "train loss:0.07029744259895859\n",
            "train loss:0.032091207805395414\n",
            "train loss:0.034984334004741637\n",
            "train loss:0.02569944454599811\n",
            "train loss:0.030998353677066028\n",
            "train loss:0.033617312291331046\n",
            "train loss:0.038324181991188956\n",
            "train loss:0.056288891812891234\n",
            "=== epoch:392, train acc:0.997, test acc:0.8769 ===\n",
            "train loss:0.02442068157264337\n",
            "train loss:0.02473634715660005\n",
            "train loss:0.02266961713916276\n",
            "train loss:0.04142360919837711\n",
            "train loss:0.02822192500453681\n",
            "train loss:0.04085946378096631\n",
            "train loss:0.047236777774134896\n",
            "train loss:0.025538070437471763\n",
            "train loss:0.056332067524895585\n",
            "train loss:0.028610877282381198\n",
            "=== epoch:393, train acc:0.998, test acc:0.8786 ===\n",
            "train loss:0.02997088236783574\n",
            "train loss:0.03923445351084834\n",
            "train loss:0.039456237177750444\n",
            "train loss:0.019404775910174765\n",
            "train loss:0.04107953002003477\n",
            "train loss:0.033107669043942745\n",
            "train loss:0.04169090114769428\n",
            "train loss:0.047699564971865206\n",
            "train loss:0.02039746324845001\n",
            "train loss:0.03328028961302112\n",
            "=== epoch:394, train acc:0.998, test acc:0.8805 ===\n",
            "train loss:0.02888014777312739\n",
            "train loss:0.032066563191810095\n",
            "train loss:0.03926692574149224\n",
            "train loss:0.029336355393912276\n",
            "train loss:0.027156596488944487\n",
            "train loss:0.04539884014246651\n",
            "train loss:0.03392762852688311\n",
            "train loss:0.02271229239232409\n",
            "train loss:0.0774572706113104\n",
            "train loss:0.03318977747396821\n",
            "=== epoch:395, train acc:0.997, test acc:0.8789 ===\n",
            "train loss:0.018669447944619288\n",
            "train loss:0.029048884807531445\n",
            "train loss:0.032210593633586276\n",
            "train loss:0.023836860053813132\n",
            "train loss:0.023354909465174295\n",
            "train loss:0.026554135766383512\n",
            "train loss:0.03878085416669845\n",
            "train loss:0.0185064745061924\n",
            "train loss:0.03629501746354235\n",
            "train loss:0.030473814605570252\n",
            "=== epoch:396, train acc:0.997, test acc:0.8794 ===\n",
            "train loss:0.017807895313593825\n",
            "train loss:0.028190733353748963\n",
            "train loss:0.032285533603521786\n",
            "train loss:0.05657499321063125\n",
            "train loss:0.04761553516892421\n",
            "train loss:0.042138091332664995\n",
            "train loss:0.028284426186418275\n",
            "train loss:0.029991126967458745\n",
            "train loss:0.03644648449621989\n",
            "train loss:0.033580660303955796\n",
            "=== epoch:397, train acc:0.998, test acc:0.88 ===\n",
            "train loss:0.023194909963594454\n",
            "train loss:0.031929875524606806\n",
            "train loss:0.03315164830527489\n",
            "train loss:0.07065375504855856\n",
            "train loss:0.022653563645268472\n",
            "train loss:0.057391123553009835\n",
            "train loss:0.03393988323707025\n",
            "train loss:0.032410103969334164\n",
            "train loss:0.03545185765291301\n",
            "train loss:0.0314601439516709\n",
            "=== epoch:398, train acc:0.997, test acc:0.8791 ===\n",
            "train loss:0.0315334498355056\n",
            "train loss:0.03032672183830259\n",
            "train loss:0.027796834092586455\n",
            "train loss:0.02443940815870661\n",
            "train loss:0.037695750643677736\n",
            "train loss:0.033460003337464087\n",
            "train loss:0.027087006988444188\n",
            "train loss:0.03371897899992506\n",
            "train loss:0.021952554947238436\n",
            "train loss:0.03171894144806454\n",
            "=== epoch:399, train acc:0.997, test acc:0.8788 ===\n",
            "train loss:0.024006132594130206\n",
            "train loss:0.031542682679135244\n",
            "train loss:0.055673775512197966\n",
            "train loss:0.06131252166100471\n",
            "train loss:0.02643717795109328\n",
            "train loss:0.023341064720255406\n",
            "train loss:0.021291279150050833\n",
            "train loss:0.02777763700869576\n",
            "train loss:0.0330794457662508\n",
            "train loss:0.02716084419747051\n",
            "=== epoch:400, train acc:0.998, test acc:0.8788 ===\n",
            "train loss:0.03104535920860166\n",
            "train loss:0.035940124104581916\n",
            "train loss:0.03753278102194269\n",
            "train loss:0.032670609927841716\n",
            "train loss:0.014377655279585337\n",
            "train loss:0.03278637842621161\n",
            "train loss:0.025757829970163282\n",
            "train loss:0.030887923529690067\n",
            "train loss:0.027797209306092002\n",
            "train loss:0.05569810793815114\n",
            "=== epoch:401, train acc:0.998, test acc:0.8792 ===\n",
            "train loss:0.026561508892887328\n",
            "train loss:0.030380387342114616\n",
            "train loss:0.02730485653478817\n",
            "train loss:0.08760840382593768\n",
            "train loss:0.024168495512384123\n",
            "train loss:0.04396699214006478\n",
            "train loss:0.0230179181326933\n",
            "train loss:0.029802940556962084\n",
            "train loss:0.019678489658748174\n",
            "train loss:0.02038943184978632\n",
            "=== epoch:402, train acc:0.997, test acc:0.8812 ===\n",
            "train loss:0.023198904416769132\n",
            "train loss:0.02196812194901056\n",
            "train loss:0.03529970350586467\n",
            "train loss:0.017676444271463487\n",
            "train loss:0.01535075919020882\n",
            "train loss:0.02270504694811374\n",
            "train loss:0.021988291471404985\n",
            "train loss:0.020311503998551732\n",
            "train loss:0.0578409734894629\n",
            "train loss:0.015206072470215094\n",
            "=== epoch:403, train acc:0.997, test acc:0.8797 ===\n",
            "train loss:0.02595154835454716\n",
            "train loss:0.023845237404280028\n",
            "train loss:0.023494329885919252\n",
            "train loss:0.05636614695536634\n",
            "train loss:0.02903038405390174\n",
            "train loss:0.019151985646596356\n",
            "train loss:0.024629044642048\n",
            "train loss:0.04060982504793799\n",
            "train loss:0.02990048219427581\n",
            "train loss:0.01944999319729865\n",
            "=== epoch:404, train acc:0.998, test acc:0.8805 ===\n",
            "train loss:0.055655582665499796\n",
            "train loss:0.026600488847217475\n",
            "train loss:0.025381340824494284\n",
            "train loss:0.034726995038863416\n",
            "train loss:0.027370068629682894\n",
            "train loss:0.03459756420322818\n",
            "train loss:0.02509021158433915\n",
            "train loss:0.05641800729171046\n",
            "train loss:0.03186923910882921\n",
            "train loss:0.02561039225164232\n",
            "=== epoch:405, train acc:0.998, test acc:0.8811 ===\n",
            "train loss:0.029435360133759178\n",
            "train loss:0.020242087806617733\n",
            "train loss:0.030643631832955927\n",
            "train loss:0.039372516937764834\n",
            "train loss:0.029863650709200558\n",
            "train loss:0.020074848204900114\n",
            "train loss:0.028396138665846993\n",
            "train loss:0.021132901364214488\n",
            "train loss:0.04194735185953473\n",
            "train loss:0.023906261387408527\n",
            "=== epoch:406, train acc:0.999, test acc:0.8803 ===\n",
            "train loss:0.015826222974960377\n",
            "train loss:0.021755140767318267\n",
            "train loss:0.016818593777810604\n",
            "train loss:0.10001796260183006\n",
            "train loss:0.05407139899520131\n",
            "train loss:0.02403932461058451\n",
            "train loss:0.02681412938692259\n",
            "train loss:0.03035865011819629\n",
            "train loss:0.018490694661418446\n",
            "train loss:0.02132190292632867\n",
            "=== epoch:407, train acc:0.998, test acc:0.8805 ===\n",
            "train loss:0.03417706046745406\n",
            "train loss:0.028758825315137543\n",
            "train loss:0.029799750220232988\n",
            "train loss:0.020804295137153282\n",
            "train loss:0.04489135964820647\n",
            "train loss:0.014824487679427673\n",
            "train loss:0.028462770402352913\n",
            "train loss:0.06135388546072568\n",
            "train loss:0.04262642486513043\n",
            "train loss:0.035864870109667026\n",
            "=== epoch:408, train acc:0.999, test acc:0.8797 ===\n",
            "train loss:0.0189238970871703\n",
            "train loss:0.028497357577373754\n",
            "train loss:0.02295830908413911\n",
            "train loss:0.016395253036238094\n",
            "train loss:0.02272512884739395\n",
            "train loss:0.02509764346675079\n",
            "train loss:0.034454982250746\n",
            "train loss:0.03455574173566452\n",
            "train loss:0.025873872277873945\n",
            "train loss:0.021798943983294697\n",
            "=== epoch:409, train acc:0.999, test acc:0.8803 ===\n",
            "train loss:0.020457109203941948\n",
            "train loss:0.026601351604765396\n",
            "train loss:0.025386076361262177\n",
            "train loss:0.04943015808613782\n",
            "train loss:0.0415923128841716\n",
            "train loss:0.024787102271744636\n",
            "train loss:0.024293498621762614\n",
            "train loss:0.026864610832336683\n",
            "train loss:0.025665286186398864\n",
            "train loss:0.021406978591309255\n",
            "=== epoch:410, train acc:0.999, test acc:0.8802 ===\n",
            "train loss:0.02136529772353005\n",
            "train loss:0.02600069198369881\n",
            "train loss:0.022477500075618904\n",
            "train loss:0.018636257937757198\n",
            "train loss:0.025525905515144987\n",
            "train loss:0.022632051348545037\n",
            "train loss:0.05996802432107252\n",
            "train loss:0.03986320755466203\n",
            "train loss:0.019558925623086566\n",
            "train loss:0.03572138583401741\n",
            "=== epoch:411, train acc:0.999, test acc:0.8811 ===\n",
            "train loss:0.03727222072949677\n",
            "train loss:0.028332632270435837\n",
            "train loss:0.024743189938134777\n",
            "train loss:0.017281036578290457\n",
            "train loss:0.04482211982732401\n",
            "train loss:0.017959327368499325\n",
            "train loss:0.017615250872921307\n",
            "train loss:0.028438349818070092\n",
            "train loss:0.037259637425648584\n",
            "train loss:0.029936178764673062\n",
            "=== epoch:412, train acc:0.999, test acc:0.8803 ===\n",
            "train loss:0.014338777066283202\n",
            "train loss:0.014844084743218173\n",
            "train loss:0.02544758775169707\n",
            "train loss:0.020792413862162906\n",
            "train loss:0.028699407682161393\n",
            "train loss:0.024001807655097164\n",
            "train loss:0.027535814984405674\n",
            "train loss:0.060542043697791786\n",
            "train loss:0.013625745462879296\n",
            "train loss:0.01722440463946033\n",
            "=== epoch:413, train acc:0.999, test acc:0.8804 ===\n",
            "train loss:0.015793373084993463\n",
            "train loss:0.019647637221115098\n",
            "train loss:0.017621999666418607\n",
            "train loss:0.031257529912754045\n",
            "train loss:0.037107109514154996\n",
            "train loss:0.01954066249728731\n",
            "train loss:0.034123372992792576\n",
            "train loss:0.05822436246026099\n",
            "train loss:0.0225537289193495\n",
            "train loss:0.07413429201408796\n",
            "=== epoch:414, train acc:0.999, test acc:0.8786 ===\n",
            "train loss:0.02510418156845486\n",
            "train loss:0.07094265951100817\n",
            "train loss:0.021381526408019717\n",
            "train loss:0.026409262563751916\n",
            "train loss:0.017472132219319383\n",
            "train loss:0.018931511126026784\n",
            "train loss:0.026879077814664053\n",
            "train loss:0.03511408476113175\n",
            "train loss:0.02302831220957944\n",
            "train loss:0.019166926094745504\n",
            "=== epoch:415, train acc:0.999, test acc:0.8793 ===\n",
            "train loss:0.02581505996316609\n",
            "train loss:0.01857309631658243\n",
            "train loss:0.012612580189244733\n",
            "train loss:0.02537643745176428\n",
            "train loss:0.01913868620938399\n",
            "train loss:0.019512148288619035\n",
            "train loss:0.0488645631750906\n",
            "train loss:0.026273084323648853\n",
            "train loss:0.012699769267710404\n",
            "train loss:0.032775024500258515\n",
            "=== epoch:416, train acc:0.999, test acc:0.8822 ===\n",
            "train loss:0.01558399572886804\n",
            "train loss:0.03421375145852087\n",
            "train loss:0.030691145326155703\n",
            "train loss:0.023762863384449613\n",
            "train loss:0.017640360117718537\n",
            "train loss:0.023186755357633197\n",
            "train loss:0.02723543604288543\n",
            "train loss:0.02184588614951792\n",
            "train loss:0.018037796106838828\n",
            "train loss:0.02001272784977547\n",
            "=== epoch:417, train acc:0.997, test acc:0.8806 ===\n",
            "train loss:0.021697530626863862\n",
            "train loss:0.01643610469516932\n",
            "train loss:0.025855168259651423\n",
            "train loss:0.02210106621612259\n",
            "train loss:0.054300670245751255\n",
            "train loss:0.044574324282701\n",
            "train loss:0.011445257011974847\n",
            "train loss:0.029020169790105958\n",
            "train loss:0.023944450130633926\n",
            "train loss:0.02194411403947162\n",
            "=== epoch:418, train acc:0.999, test acc:0.8821 ===\n",
            "train loss:0.03530026853898195\n",
            "train loss:0.018480090010220666\n",
            "train loss:0.01846131479381489\n",
            "train loss:0.02524960554036861\n",
            "train loss:0.023179660238453716\n",
            "train loss:0.022979533579906654\n",
            "train loss:0.026366005403166838\n",
            "train loss:0.013833701857152048\n",
            "train loss:0.020998610082649482\n",
            "train loss:0.04649673029203846\n",
            "=== epoch:419, train acc:0.999, test acc:0.8829 ===\n",
            "train loss:0.017735180089141336\n",
            "train loss:0.02798962810201746\n",
            "train loss:0.04588276366491768\n",
            "train loss:0.022910759854477006\n",
            "train loss:0.023105578714043375\n",
            "train loss:0.019551870180252073\n",
            "train loss:0.020491549179415473\n",
            "train loss:0.022012300880959644\n",
            "train loss:0.016116587159190735\n",
            "train loss:0.02238821570327814\n",
            "=== epoch:420, train acc:0.999, test acc:0.8822 ===\n",
            "train loss:0.019050803929679068\n",
            "train loss:0.05042045773211445\n",
            "train loss:0.016452026215400605\n",
            "train loss:0.018767162445610098\n",
            "train loss:0.017918105557344785\n",
            "train loss:0.017734889239447042\n",
            "train loss:0.02932067180742718\n",
            "train loss:0.02403734601812317\n",
            "train loss:0.025195608979730163\n",
            "train loss:0.020285555554748234\n",
            "=== epoch:421, train acc:0.999, test acc:0.8826 ===\n",
            "train loss:0.031774039716776975\n",
            "train loss:0.021222011156977687\n",
            "train loss:0.01168661947799263\n",
            "train loss:0.01734820119136262\n",
            "train loss:0.024934181837651358\n",
            "train loss:0.015272223205880902\n",
            "train loss:0.016760138420784658\n",
            "train loss:0.011894242800270556\n",
            "train loss:0.02461258514445795\n",
            "train loss:0.03373378423507452\n",
            "=== epoch:422, train acc:0.998, test acc:0.8825 ===\n",
            "train loss:0.02488268351738773\n",
            "train loss:0.01638987318196791\n",
            "train loss:0.01682295638267471\n",
            "train loss:0.01944266428923456\n",
            "train loss:0.020545382712958773\n",
            "train loss:0.02498740845212816\n",
            "train loss:0.026556587217956947\n",
            "train loss:0.025139505105680474\n",
            "train loss:0.01864437761731851\n",
            "train loss:0.02063645780309054\n",
            "=== epoch:423, train acc:0.998, test acc:0.8815 ===\n",
            "train loss:0.01536840515404823\n",
            "train loss:0.011937863774594337\n",
            "train loss:0.019409235583952723\n",
            "train loss:0.021336732911907963\n",
            "train loss:0.0156408938322438\n",
            "train loss:0.018022881490414974\n",
            "train loss:0.014146262538636515\n",
            "train loss:0.02516644206095534\n",
            "train loss:0.012850731449441427\n",
            "train loss:0.02110334236264712\n",
            "=== epoch:424, train acc:0.998, test acc:0.8817 ===\n",
            "train loss:0.015082948855161305\n",
            "train loss:0.029916651399808095\n",
            "train loss:0.024694513123390424\n",
            "train loss:0.02114436214099501\n",
            "train loss:0.0577234954068508\n",
            "train loss:0.012297327408124049\n",
            "train loss:0.018218582384024583\n",
            "train loss:0.01454037557952879\n",
            "train loss:0.023007054586113775\n",
            "train loss:0.03180818067339926\n",
            "=== epoch:425, train acc:0.998, test acc:0.8805 ===\n",
            "train loss:0.023536184480352444\n",
            "train loss:0.01602381438458354\n",
            "train loss:0.016157246724427102\n",
            "train loss:0.01911832646744297\n",
            "train loss:0.014207860336104737\n",
            "train loss:0.02382614754340674\n",
            "train loss:0.017663582933064328\n",
            "train loss:0.017285035870079533\n",
            "train loss:0.012839137986527905\n",
            "train loss:0.01638618280092539\n",
            "=== epoch:426, train acc:0.998, test acc:0.8802 ===\n",
            "train loss:0.021482032424124328\n",
            "train loss:0.016596933583368372\n",
            "train loss:0.021633549479935215\n",
            "train loss:0.00947599611331803\n",
            "train loss:0.02501966261354704\n",
            "train loss:0.04359717154971155\n",
            "train loss:0.019248117723420114\n",
            "train loss:0.019892876728895014\n",
            "train loss:0.01901695589697386\n",
            "train loss:0.01698120658716024\n",
            "=== epoch:427, train acc:0.999, test acc:0.8786 ===\n",
            "train loss:0.03540655453628797\n",
            "train loss:0.03181856109141915\n",
            "train loss:0.012310036619004842\n",
            "train loss:0.018726053720642778\n",
            "train loss:0.034891275257461496\n",
            "train loss:0.014839802726116178\n",
            "train loss:0.01879881276276336\n",
            "train loss:0.011288900581027505\n",
            "train loss:0.015376540209194253\n",
            "train loss:0.011599623060906466\n",
            "=== epoch:428, train acc:0.999, test acc:0.8788 ===\n",
            "train loss:0.01882391983741023\n",
            "train loss:0.01813337369451267\n",
            "train loss:0.01854297529417221\n",
            "train loss:0.016921147363729235\n",
            "train loss:0.011539096217310807\n",
            "train loss:0.01205879251126465\n",
            "train loss:0.024156996008495045\n",
            "train loss:0.01579143842519253\n",
            "train loss:0.015727005322069217\n",
            "train loss:0.0168952400589739\n",
            "=== epoch:429, train acc:0.999, test acc:0.8816 ===\n",
            "train loss:0.021583587405109322\n",
            "train loss:0.011892686161711756\n",
            "train loss:0.021801133273278914\n",
            "train loss:0.015255461832783384\n",
            "train loss:0.03608108550000156\n",
            "train loss:0.01780363363084857\n",
            "train loss:0.021588027862969827\n",
            "train loss:0.020139174538191532\n",
            "train loss:0.01712476043837852\n",
            "train loss:0.02021309605861181\n",
            "=== epoch:430, train acc:0.999, test acc:0.8826 ===\n",
            "train loss:0.02987908210233514\n",
            "train loss:0.018816758405691008\n",
            "train loss:0.019855996368273295\n",
            "train loss:0.01753116739163909\n",
            "train loss:0.025768634052887127\n",
            "train loss:0.007682438536952854\n",
            "train loss:0.018573257648820948\n",
            "train loss:0.01771567104778986\n",
            "train loss:0.023030068512116038\n",
            "train loss:0.02069004784346678\n",
            "=== epoch:431, train acc:0.999, test acc:0.881 ===\n",
            "train loss:0.020368591287294232\n",
            "train loss:0.01406136377844986\n",
            "train loss:0.04872411791270073\n",
            "train loss:0.01967904595636517\n",
            "train loss:0.01711347542205906\n",
            "train loss:0.010023938132299499\n",
            "train loss:0.013390164605468262\n",
            "train loss:0.04119725449641658\n",
            "train loss:0.016206074259587297\n",
            "train loss:0.021585813913079344\n",
            "=== epoch:432, train acc:0.999, test acc:0.8818 ===\n",
            "train loss:0.02189770523409672\n",
            "train loss:0.015300803103052842\n",
            "train loss:0.026440705745633487\n",
            "train loss:0.01049195643100448\n",
            "train loss:0.020776575628713618\n",
            "train loss:0.018787688459891486\n",
            "train loss:0.01580360749448981\n",
            "train loss:0.016431934195110826\n",
            "train loss:0.023192424098995194\n",
            "train loss:0.01477619203379326\n",
            "=== epoch:433, train acc:0.999, test acc:0.8818 ===\n",
            "train loss:0.01625739345932424\n",
            "train loss:0.0237814447738482\n",
            "train loss:0.02605787561800672\n",
            "train loss:0.014982566187394249\n",
            "train loss:0.01159283999760376\n",
            "train loss:0.026135513968228156\n",
            "train loss:0.01841117398284954\n",
            "train loss:0.016592288657263313\n",
            "train loss:0.014046670103800033\n",
            "train loss:0.00956506418906657\n",
            "=== epoch:434, train acc:0.999, test acc:0.8819 ===\n",
            "train loss:0.011799476878022462\n",
            "train loss:0.018878523098839365\n",
            "train loss:0.02364501521831068\n",
            "train loss:0.01390580139640357\n",
            "train loss:0.0764257717577251\n",
            "train loss:0.018836455169659715\n",
            "train loss:0.022736832975517308\n",
            "train loss:0.024119012805109356\n",
            "train loss:0.0153317683823535\n",
            "train loss:0.01744160951931918\n",
            "=== epoch:435, train acc:0.999, test acc:0.8823 ===\n",
            "train loss:0.023221096899784018\n",
            "train loss:0.04177229347064167\n",
            "train loss:0.00918034426727761\n",
            "train loss:0.013707472042336305\n",
            "train loss:0.014382817255956075\n",
            "train loss:0.02124884016802242\n",
            "train loss:0.014655306739401403\n",
            "train loss:0.015124505940551113\n",
            "train loss:0.013923685267720339\n",
            "train loss:0.019494495114581564\n",
            "=== epoch:436, train acc:0.999, test acc:0.8829 ===\n",
            "train loss:0.017803492609130347\n",
            "train loss:0.015459587386335823\n",
            "train loss:0.04406554774203299\n",
            "train loss:0.015143337128384013\n",
            "train loss:0.009479932110480548\n",
            "train loss:0.019889556437833564\n",
            "train loss:0.019422397558124832\n",
            "train loss:0.01747327704731117\n",
            "train loss:0.015995030717365324\n",
            "train loss:0.01540907940923385\n",
            "=== epoch:437, train acc:0.999, test acc:0.8811 ===\n",
            "train loss:0.039606639786802816\n",
            "train loss:0.05039278422091027\n",
            "train loss:0.019265825239752468\n",
            "train loss:0.014060385645851485\n",
            "train loss:0.0152925142823391\n",
            "train loss:0.01601360988397655\n",
            "train loss:0.015820179111059783\n",
            "train loss:0.013135286709394806\n",
            "train loss:0.01291767945195191\n",
            "train loss:0.054879583022531764\n",
            "=== epoch:438, train acc:0.999, test acc:0.8809 ===\n",
            "train loss:0.018361602722069797\n",
            "train loss:0.01286691047091261\n",
            "train loss:0.01846928114588971\n",
            "train loss:0.05346165680741194\n",
            "train loss:0.017110734875789887\n",
            "train loss:0.017425139167157554\n",
            "train loss:0.01647892853184774\n",
            "train loss:0.012264102270270805\n",
            "train loss:0.01545970452743991\n",
            "train loss:0.013042517959292904\n",
            "=== epoch:439, train acc:0.999, test acc:0.8809 ===\n",
            "train loss:0.00850155327214152\n",
            "train loss:0.013071024273325854\n",
            "train loss:0.02582228036077193\n",
            "train loss:0.01889340087815065\n",
            "train loss:0.010313421825726745\n",
            "train loss:0.017072338467389574\n",
            "train loss:0.006284099822243793\n",
            "train loss:0.01834479014539846\n",
            "train loss:0.015164450934971697\n",
            "train loss:0.018679245628403614\n",
            "=== epoch:440, train acc:0.999, test acc:0.8815 ===\n",
            "train loss:0.016178478751182713\n",
            "train loss:0.013130623386674357\n",
            "train loss:0.014500439582421866\n",
            "train loss:0.017341867196181644\n",
            "train loss:0.014261813132064706\n",
            "train loss:0.014531268764557714\n",
            "train loss:0.020863322146797533\n",
            "train loss:0.009216169098517885\n",
            "train loss:0.017037043758214635\n",
            "train loss:0.014499421914095353\n",
            "=== epoch:441, train acc:0.999, test acc:0.8825 ===\n",
            "train loss:0.022574074599262715\n",
            "train loss:0.01677655070397003\n",
            "train loss:0.022509265291190038\n",
            "train loss:0.010207669302726739\n",
            "train loss:0.01844109978728728\n",
            "train loss:0.019450872909472516\n",
            "train loss:0.007337998040601297\n",
            "train loss:0.009496160904689242\n",
            "train loss:0.01638269093159159\n",
            "train loss:0.021491676991979437\n",
            "=== epoch:442, train acc:0.999, test acc:0.8814 ===\n",
            "train loss:0.010065635584210171\n",
            "train loss:0.014988501132453496\n",
            "train loss:0.014307335219453838\n",
            "train loss:0.010609511134520846\n",
            "train loss:0.013508787909157357\n",
            "train loss:0.015199719134846775\n",
            "train loss:0.024953153869723237\n",
            "train loss:0.06845518351055514\n",
            "train loss:0.016955950903485506\n",
            "train loss:0.01499376379556578\n",
            "=== epoch:443, train acc:0.999, test acc:0.8813 ===\n",
            "train loss:0.04106918948350657\n",
            "train loss:0.009779341193183484\n",
            "train loss:0.011072871450673065\n",
            "train loss:0.021545577738345773\n",
            "train loss:0.025564741701658372\n",
            "train loss:0.03880330117558814\n",
            "train loss:0.008277375881226363\n",
            "train loss:0.021243621901808386\n",
            "train loss:0.017564544665158964\n",
            "train loss:0.015448016858523346\n",
            "=== epoch:444, train acc:0.999, test acc:0.8811 ===\n",
            "train loss:0.015263510713164105\n",
            "train loss:0.01221529783241174\n",
            "train loss:0.024889540733705782\n",
            "train loss:0.01709369949321297\n",
            "train loss:0.027145972996773647\n",
            "train loss:0.04800459762991374\n",
            "train loss:0.017005453586714302\n",
            "train loss:0.03527676905250845\n",
            "train loss:0.017018408838206406\n",
            "train loss:0.018154220368459918\n",
            "=== epoch:445, train acc:0.999, test acc:0.8829 ===\n",
            "train loss:0.015215613232164839\n",
            "train loss:0.03352568089831144\n",
            "train loss:0.014346196362583776\n",
            "train loss:0.01622832164131726\n",
            "train loss:0.0159470225179746\n",
            "train loss:0.015060911792508022\n",
            "train loss:0.03849719268091164\n",
            "train loss:0.01992662338747161\n",
            "train loss:0.035080168790478504\n",
            "train loss:0.013831545263040469\n",
            "=== epoch:446, train acc:0.999, test acc:0.883 ===\n",
            "train loss:0.014053090352870012\n",
            "train loss:0.011874684043781131\n",
            "train loss:0.0128743161226514\n",
            "train loss:0.01209204760238903\n",
            "train loss:0.012289094347684984\n",
            "train loss:0.020179003414398516\n",
            "train loss:0.01190709975764881\n",
            "train loss:0.013710619381924617\n",
            "train loss:0.012135694157405324\n",
            "train loss:0.011198677656987116\n",
            "=== epoch:447, train acc:0.999, test acc:0.8823 ===\n",
            "train loss:0.020187285057057417\n",
            "train loss:0.006403159454397457\n",
            "train loss:0.013158186579373357\n",
            "train loss:0.01012694256357522\n",
            "train loss:0.012501579807257548\n",
            "train loss:0.019282147388182146\n",
            "train loss:0.012299633807080282\n",
            "train loss:0.015808584696512747\n",
            "train loss:0.009059410754055917\n",
            "train loss:0.011512900598635387\n",
            "=== epoch:448, train acc:0.999, test acc:0.8824 ===\n",
            "train loss:0.017841239390402008\n",
            "train loss:0.014026181724211313\n",
            "train loss:0.020365622313182462\n",
            "train loss:0.018965577886975005\n",
            "train loss:0.012872853832908364\n",
            "train loss:0.013886691735860763\n",
            "train loss:0.01742556487315948\n",
            "train loss:0.01135128776605957\n",
            "train loss:0.015071627918333892\n",
            "train loss:0.015362401484406875\n",
            "=== epoch:449, train acc:0.999, test acc:0.8814 ===\n",
            "train loss:0.015122284565258347\n",
            "train loss:0.020801107661716552\n",
            "train loss:0.009224637906694281\n",
            "train loss:0.01238904540890353\n",
            "train loss:0.00861135937175168\n",
            "train loss:0.01595212612788712\n",
            "train loss:0.01449222866231994\n",
            "train loss:0.012054950684373743\n",
            "train loss:0.011070658759424834\n",
            "train loss:0.014361202191438011\n",
            "=== epoch:450, train acc:0.999, test acc:0.8824 ===\n",
            "train loss:0.014669959285113726\n",
            "train loss:0.021552215094101608\n",
            "train loss:0.011224602650160214\n",
            "train loss:0.012980975809797108\n",
            "train loss:0.010878466464030696\n",
            "train loss:0.0098991917476128\n",
            "train loss:0.01887596130290037\n",
            "train loss:0.011714829426938054\n",
            "train loss:0.01886844463532177\n",
            "train loss:0.007347023902301213\n",
            "=== epoch:451, train acc:0.999, test acc:0.8837 ===\n",
            "train loss:0.017285668097287717\n",
            "train loss:0.041174054135596966\n",
            "train loss:0.01895491376180741\n",
            "train loss:0.013193811692741442\n",
            "train loss:0.010285111437455516\n",
            "train loss:0.015075389139214255\n",
            "train loss:0.0114069503380917\n",
            "train loss:0.017442672729794825\n",
            "train loss:0.013450812030880322\n",
            "train loss:0.00944410182985882\n",
            "=== epoch:452, train acc:0.999, test acc:0.8838 ===\n",
            "train loss:0.01005252392832999\n",
            "train loss:0.008107288479086674\n",
            "train loss:0.010695455282474377\n",
            "train loss:0.011878043420523909\n",
            "train loss:0.017306643416167753\n",
            "train loss:0.01326595782630211\n",
            "train loss:0.06387232934948428\n",
            "train loss:0.01130087741025063\n",
            "train loss:0.014730504481688795\n",
            "train loss:0.03928196484373134\n",
            "=== epoch:453, train acc:0.999, test acc:0.8829 ===\n",
            "train loss:0.014759466300658336\n",
            "train loss:0.011499386374782929\n",
            "train loss:0.01148593642911016\n",
            "train loss:0.012498313564165643\n",
            "train loss:0.01808738502931029\n",
            "train loss:0.016097021119568997\n",
            "train loss:0.033537759038992435\n",
            "train loss:0.006354175442207391\n",
            "train loss:0.013929627883647074\n",
            "train loss:0.013668221051367344\n",
            "=== epoch:454, train acc:0.999, test acc:0.8837 ===\n",
            "train loss:0.011420912585128054\n",
            "train loss:0.010294019248748853\n",
            "train loss:0.009405353788921898\n",
            "train loss:0.009516091438262379\n",
            "train loss:0.015379526221649311\n",
            "train loss:0.00873172360560463\n",
            "train loss:0.006406098667126154\n",
            "train loss:0.010323479119531877\n",
            "train loss:0.007813061469076014\n",
            "train loss:0.037647732320504064\n",
            "=== epoch:455, train acc:0.999, test acc:0.8817 ===\n",
            "train loss:0.010426008915353845\n",
            "train loss:0.014851614584133668\n",
            "train loss:0.009952198231745741\n",
            "train loss:0.012996384722693575\n",
            "train loss:0.009502119692928081\n",
            "train loss:0.015656763453133774\n",
            "train loss:0.010758723537857045\n",
            "train loss:0.01070628438655012\n",
            "train loss:0.01532401371885685\n",
            "train loss:0.009099923693413715\n",
            "=== epoch:456, train acc:0.999, test acc:0.8806 ===\n",
            "train loss:0.013185106160216498\n",
            "train loss:0.009201785496735651\n",
            "train loss:0.019909659834683638\n",
            "train loss:0.01999329059963881\n",
            "train loss:0.008422509469399715\n",
            "train loss:0.011230030913480677\n",
            "train loss:0.014000652462743724\n",
            "train loss:0.01454576737523735\n",
            "train loss:0.01214552082757258\n",
            "train loss:0.009121877323604888\n",
            "=== epoch:457, train acc:0.999, test acc:0.882 ===\n",
            "train loss:0.006736480984816664\n",
            "train loss:0.016036922587669374\n",
            "train loss:0.011436993367024051\n",
            "train loss:0.009481990135862914\n",
            "train loss:0.006905831283208441\n",
            "train loss:0.01378716334857907\n",
            "train loss:0.007404224390629731\n",
            "train loss:0.01000920513290463\n",
            "train loss:0.012561515540459001\n",
            "train loss:0.012734633967913838\n",
            "=== epoch:458, train acc:0.999, test acc:0.8815 ===\n",
            "train loss:0.010047241415061588\n",
            "train loss:0.011156686350704513\n",
            "train loss:0.012622120077566426\n",
            "train loss:0.015004853460070942\n",
            "train loss:0.036014634979813435\n",
            "train loss:0.009300231681564962\n",
            "train loss:0.017533607528141253\n",
            "train loss:0.007531664246432591\n",
            "train loss:0.008420462116276187\n",
            "train loss:0.012396200520580441\n",
            "=== epoch:459, train acc:0.999, test acc:0.8811 ===\n",
            "train loss:0.009934161590504047\n",
            "train loss:0.008833678714761954\n",
            "train loss:0.010522796655865281\n",
            "train loss:0.008082573228796826\n",
            "train loss:0.013085151758601022\n",
            "train loss:0.011071043574085036\n",
            "train loss:0.010823970376719321\n",
            "train loss:0.013506842247143849\n",
            "train loss:0.010960505515975431\n",
            "train loss:0.01626465553161352\n",
            "=== epoch:460, train acc:0.999, test acc:0.8803 ===\n",
            "train loss:0.007861049129029489\n",
            "train loss:0.03405120403660636\n",
            "train loss:0.013635781183056554\n",
            "train loss:0.03575689269752146\n",
            "train loss:0.03885849748426741\n",
            "train loss:0.016188447791378794\n",
            "train loss:0.01267362736001945\n",
            "train loss:0.015417456027009007\n",
            "train loss:0.007721698404075702\n",
            "train loss:0.03234840153389916\n",
            "=== epoch:461, train acc:0.999, test acc:0.8812 ===\n",
            "train loss:0.010713677078652306\n",
            "train loss:0.009737500775467454\n",
            "train loss:0.015769725090952785\n",
            "train loss:0.03659395161351535\n",
            "train loss:0.012322275498576165\n",
            "train loss:0.03670682756860147\n",
            "train loss:0.0162684336150775\n",
            "train loss:0.011307109233175015\n",
            "train loss:0.02045184244174476\n",
            "train loss:0.00853207754496904\n",
            "=== epoch:462, train acc:0.999, test acc:0.881 ===\n",
            "train loss:0.0101509025231027\n",
            "train loss:0.03816863728679224\n",
            "train loss:0.00914548999255263\n",
            "train loss:0.010767088813451784\n",
            "train loss:0.01041775165215259\n",
            "train loss:0.03638240252736971\n",
            "train loss:0.016736394876859767\n",
            "train loss:0.013578091710395639\n",
            "train loss:0.008929050823119965\n",
            "train loss:0.011085118263640528\n",
            "=== epoch:463, train acc:0.999, test acc:0.881 ===\n",
            "train loss:0.011390930360338314\n",
            "train loss:0.0129132115303886\n",
            "train loss:0.015083373630689114\n",
            "train loss:0.02103794181690856\n",
            "train loss:0.008601183835467492\n",
            "train loss:0.011632857866453121\n",
            "train loss:0.04566574570598672\n",
            "train loss:0.011109239453529153\n",
            "train loss:0.011216393081984799\n",
            "train loss:0.008105422027901987\n",
            "=== epoch:464, train acc:0.999, test acc:0.882 ===\n",
            "train loss:0.007554064559499274\n",
            "train loss:0.011765977674703434\n",
            "train loss:0.010433634992038945\n",
            "train loss:0.030261889799935618\n",
            "train loss:0.011290570154463098\n",
            "train loss:0.007074628577560153\n",
            "train loss:0.014684577825306095\n",
            "train loss:0.009409658618098796\n",
            "train loss:0.011789602348070163\n",
            "train loss:0.009512662410907022\n",
            "=== epoch:465, train acc:0.999, test acc:0.8811 ===\n",
            "train loss:0.012766433481177883\n",
            "train loss:0.011758172182144078\n",
            "train loss:0.013022107103204854\n",
            "train loss:0.014606089505618331\n",
            "train loss:0.02940678504813091\n",
            "train loss:0.007865862753622761\n",
            "train loss:0.008994580652815828\n",
            "train loss:0.029937432685327538\n",
            "train loss:0.0095640531288154\n",
            "train loss:0.027728533239598455\n",
            "=== epoch:466, train acc:0.999, test acc:0.8826 ===\n",
            "train loss:0.005660291331425019\n",
            "train loss:0.026135755040207168\n",
            "train loss:0.010896473311537902\n",
            "train loss:0.011272532095090621\n",
            "train loss:0.004666981157335413\n",
            "train loss:0.010728120061912316\n",
            "train loss:0.010422872459371164\n",
            "train loss:0.011130302044814057\n",
            "train loss:0.008561175920165507\n",
            "train loss:0.008431999715383633\n",
            "=== epoch:467, train acc:0.999, test acc:0.8829 ===\n",
            "train loss:0.011490620777414832\n",
            "train loss:0.006532584773265183\n",
            "train loss:0.008337337148964017\n",
            "train loss:0.012146691171243807\n",
            "train loss:0.01450170723060092\n",
            "train loss:0.034818918848334955\n",
            "train loss:0.008177863628411766\n",
            "train loss:0.012486293222429203\n",
            "train loss:0.02826805030711664\n",
            "train loss:0.011581146888228106\n",
            "=== epoch:468, train acc:0.999, test acc:0.8831 ===\n",
            "train loss:0.009337174569045132\n",
            "train loss:0.014783953458298731\n",
            "train loss:0.014703060614673039\n",
            "train loss:0.009234095216632104\n",
            "train loss:0.00804664329985113\n",
            "train loss:0.011301587003979785\n",
            "train loss:0.01021007172238594\n",
            "train loss:0.00813800020509513\n",
            "train loss:0.03094547845906513\n",
            "train loss:0.00799591416272441\n",
            "=== epoch:469, train acc:0.999, test acc:0.8828 ===\n",
            "train loss:0.014393606641832132\n",
            "train loss:0.0075731457480397195\n",
            "train loss:0.012871358903523127\n",
            "train loss:0.013896950939120927\n",
            "train loss:0.008815686654166101\n",
            "train loss:0.007955743709474867\n",
            "train loss:0.012804085055967534\n",
            "train loss:0.011402778540120069\n",
            "train loss:0.010252472472926528\n",
            "train loss:0.019848241326346206\n",
            "=== epoch:470, train acc:0.999, test acc:0.8824 ===\n",
            "train loss:0.007934423801093061\n",
            "train loss:0.026932051240153392\n",
            "train loss:0.009711617627914941\n",
            "train loss:0.00827101368253866\n",
            "train loss:0.014911511168616769\n",
            "train loss:0.012845142210611917\n",
            "train loss:0.01084099302739767\n",
            "train loss:0.010405584155661417\n",
            "train loss:0.0064582431259751815\n",
            "train loss:0.0143383896079042\n",
            "=== epoch:471, train acc:0.999, test acc:0.8811 ===\n",
            "train loss:0.01117346475173287\n",
            "train loss:0.00836916248826876\n",
            "train loss:0.018471716332067865\n",
            "train loss:0.014109658869496175\n",
            "train loss:0.010439264058370812\n",
            "train loss:0.01005840732653333\n",
            "train loss:0.009267229181528298\n",
            "train loss:0.015171042259393237\n",
            "train loss:0.006315317701890604\n",
            "train loss:0.00979452264525986\n",
            "=== epoch:472, train acc:0.999, test acc:0.8821 ===\n",
            "train loss:0.009564237371152277\n",
            "train loss:0.010605596596088104\n",
            "train loss:0.008467916362921334\n",
            "train loss:0.025073763903892366\n",
            "train loss:0.010961999284767458\n",
            "train loss:0.007699617850350441\n",
            "train loss:0.010371389848808612\n",
            "train loss:0.03225407507510438\n",
            "train loss:0.03191645107204717\n",
            "train loss:0.009588409731916148\n",
            "=== epoch:473, train acc:0.999, test acc:0.8823 ===\n",
            "train loss:0.0095915052048809\n",
            "train loss:0.009246708824170781\n",
            "train loss:0.008325649650813534\n",
            "train loss:0.030654280150556427\n",
            "train loss:0.013712530395188023\n",
            "train loss:0.007342689416170374\n",
            "train loss:0.00966308132822575\n",
            "train loss:0.0099562457521616\n",
            "train loss:0.008986061214559908\n",
            "train loss:0.008320904560165668\n",
            "=== epoch:474, train acc:0.999, test acc:0.8823 ===\n",
            "train loss:0.00952874103830656\n",
            "train loss:0.029424384985353613\n",
            "train loss:0.005402374628468978\n",
            "train loss:0.014094642377855777\n",
            "train loss:0.008645654260875452\n",
            "train loss:0.009106032537495177\n",
            "train loss:0.012181039510764555\n",
            "train loss:0.012006076831861978\n",
            "train loss:0.00702862265524461\n",
            "train loss:0.010861370342742385\n",
            "=== epoch:475, train acc:0.999, test acc:0.8826 ===\n",
            "train loss:0.011799236785447295\n",
            "train loss:0.009936603161427877\n",
            "train loss:0.012491542175418984\n",
            "train loss:0.022041226967406527\n",
            "train loss:0.005983740407415026\n",
            "train loss:0.010275254594888759\n",
            "train loss:0.012883656743600288\n",
            "train loss:0.007195633869319305\n",
            "train loss:0.012283735699252058\n",
            "train loss:0.013405813032413663\n",
            "=== epoch:476, train acc:0.999, test acc:0.883 ===\n",
            "train loss:0.007696631084421555\n",
            "train loss:0.01267041176352958\n",
            "train loss:0.024102261707683103\n",
            "train loss:0.010897783404113084\n",
            "train loss:0.006399958169593703\n",
            "train loss:0.014287909988763623\n",
            "train loss:0.007231704177281428\n",
            "train loss:0.010225999905339931\n",
            "train loss:0.009585530695080361\n",
            "train loss:0.012107229094316677\n",
            "=== epoch:477, train acc:0.999, test acc:0.8818 ===\n",
            "train loss:0.009827674804093557\n",
            "train loss:0.008859609497415377\n",
            "train loss:0.009358804185455287\n",
            "train loss:0.03320180437484539\n",
            "train loss:0.00881612163080099\n",
            "train loss:0.010929962052448615\n",
            "train loss:0.01152979942635701\n",
            "train loss:0.00839172205674958\n",
            "train loss:0.0107518888813489\n",
            "train loss:0.014119903012667967\n",
            "=== epoch:478, train acc:0.999, test acc:0.8831 ===\n",
            "train loss:0.007176000340056602\n",
            "train loss:0.013003465066689536\n",
            "train loss:0.009932048992032592\n",
            "train loss:0.012172777842173748\n",
            "train loss:0.011517418150871166\n",
            "train loss:0.010257367469404083\n",
            "train loss:0.012441953981693692\n",
            "train loss:0.012007949944897702\n",
            "train loss:0.007401082872370571\n",
            "train loss:0.012082873967559044\n",
            "=== epoch:479, train acc:0.999, test acc:0.8816 ===\n",
            "train loss:0.011045191053290913\n",
            "train loss:0.01541150539123632\n",
            "train loss:0.010061056410482931\n",
            "train loss:0.0057583707879777755\n",
            "train loss:0.011674938503279851\n",
            "train loss:0.006581354843570647\n",
            "train loss:0.008285120788018645\n",
            "train loss:0.028591329647664875\n",
            "train loss:0.010255976278564324\n",
            "train loss:0.013288930932414537\n",
            "=== epoch:480, train acc:0.999, test acc:0.8818 ===\n",
            "train loss:0.012620992383911851\n",
            "train loss:0.01005848533761624\n",
            "train loss:0.007566601028077316\n",
            "train loss:0.00856218628548419\n",
            "train loss:0.025571431700682042\n",
            "train loss:0.010629692660945178\n",
            "train loss:0.006754674395499697\n",
            "train loss:0.007736484960280281\n",
            "train loss:0.01111622111778709\n",
            "train loss:0.010537887750274548\n",
            "=== epoch:481, train acc:0.999, test acc:0.8827 ===\n",
            "train loss:0.027184063788592523\n",
            "train loss:0.008771774713043768\n",
            "train loss:0.007776727374002586\n",
            "train loss:0.010473764497317168\n",
            "train loss:0.011410240116920892\n",
            "train loss:0.006772759707177458\n",
            "train loss:0.010241932070560312\n",
            "train loss:0.007317980509003547\n",
            "train loss:0.008347984813638952\n",
            "train loss:0.03242029016987613\n",
            "=== epoch:482, train acc:0.999, test acc:0.8825 ===\n",
            "train loss:0.005583034015864757\n",
            "train loss:0.012280510550390207\n",
            "train loss:0.0065125286074530254\n",
            "train loss:0.004259101338132955\n",
            "train loss:0.009753715799589745\n",
            "train loss:0.03164219087249438\n",
            "train loss:0.010753192447170186\n",
            "train loss:0.010211974821479793\n",
            "train loss:0.007153135670386006\n",
            "train loss:0.010656371215911613\n",
            "=== epoch:483, train acc:0.999, test acc:0.8828 ===\n",
            "train loss:0.008845268825794849\n",
            "train loss:0.008105289958499387\n",
            "train loss:0.0068921304193851896\n",
            "train loss:0.014782981350340405\n",
            "train loss:0.0074890420201163856\n",
            "train loss:0.011832377451869207\n",
            "train loss:0.004772410081505494\n",
            "train loss:0.03462489575564561\n",
            "train loss:0.006039719600372714\n",
            "train loss:0.007809653880489273\n",
            "=== epoch:484, train acc:0.999, test acc:0.8823 ===\n",
            "train loss:0.009818199655645107\n",
            "train loss:0.00795377876519377\n",
            "train loss:0.02703227340071168\n",
            "train loss:0.011358130888051425\n",
            "train loss:0.008571440221502068\n",
            "train loss:0.006783226683801649\n",
            "train loss:0.00477755794501722\n",
            "train loss:0.010956509561561158\n",
            "train loss:0.039484030391588\n",
            "train loss:0.006938576079550289\n",
            "=== epoch:485, train acc:0.999, test acc:0.8835 ===\n",
            "train loss:0.007299390476345699\n",
            "train loss:0.006401997845306078\n",
            "train loss:0.008009306660925967\n",
            "train loss:0.010805979786755439\n",
            "train loss:0.006936294120027457\n",
            "train loss:0.010322838196393933\n",
            "train loss:0.006430047768800358\n",
            "train loss:0.008639665478013089\n",
            "train loss:0.005240204977593552\n",
            "train loss:0.02491156448504467\n",
            "=== epoch:486, train acc:0.999, test acc:0.885 ===\n",
            "train loss:0.005433377270886954\n",
            "train loss:0.0072331391274174164\n",
            "train loss:0.008270535601747186\n",
            "train loss:0.013748378705020992\n",
            "train loss:0.010131232163897727\n",
            "train loss:0.009467173909301279\n",
            "train loss:0.01194794135219087\n",
            "train loss:0.0060278152169071005\n",
            "train loss:0.01000539808460123\n",
            "train loss:0.005558881732806778\n",
            "=== epoch:487, train acc:0.999, test acc:0.8831 ===\n",
            "train loss:0.00791474911687038\n",
            "train loss:0.007721200005935648\n",
            "train loss:0.008156993621880453\n",
            "train loss:0.012842352090670639\n",
            "train loss:0.009802518372602374\n",
            "train loss:0.010809802667634065\n",
            "train loss:0.009855649717774879\n",
            "train loss:0.013615057835451423\n",
            "train loss:0.008012587158777028\n",
            "train loss:0.007117163905325879\n",
            "=== epoch:488, train acc:0.999, test acc:0.8826 ===\n",
            "train loss:0.004988204601129734\n",
            "train loss:0.0038239325250258973\n",
            "train loss:0.009160078307952908\n",
            "train loss:0.011795577675257487\n",
            "train loss:0.010294866159848775\n",
            "train loss:0.005321065504714983\n",
            "train loss:0.00705800901005123\n",
            "train loss:0.007578210142374955\n",
            "train loss:0.0278772191186624\n",
            "train loss:0.012736399012469996\n",
            "=== epoch:489, train acc:0.999, test acc:0.8839 ===\n",
            "train loss:0.006125880524996498\n",
            "train loss:0.006958088012363913\n",
            "train loss:0.010511531320949953\n",
            "train loss:0.011621354685433188\n",
            "train loss:0.013010096519670396\n",
            "train loss:0.008636970534258426\n",
            "train loss:0.016784363717684627\n",
            "train loss:0.007675412347534359\n",
            "train loss:0.021695000605514946\n",
            "train loss:0.007411934218731375\n",
            "=== epoch:490, train acc:0.999, test acc:0.885 ===\n",
            "train loss:0.007631316188435814\n",
            "train loss:0.006080211785131505\n",
            "train loss:0.008003550964144216\n",
            "train loss:0.010605352350904677\n",
            "train loss:0.024479455398748184\n",
            "train loss:0.00973223671986855\n",
            "train loss:0.007634777609232411\n",
            "train loss:0.009337111703866615\n",
            "train loss:0.005594303822045222\n",
            "train loss:0.009299325974385576\n",
            "=== epoch:491, train acc:0.999, test acc:0.8849 ===\n",
            "train loss:0.008441003654051383\n",
            "train loss:0.01196706895896276\n",
            "train loss:0.005734893567731662\n",
            "train loss:0.006130734326399017\n",
            "train loss:0.02228685218892954\n",
            "train loss:0.009204990584778356\n",
            "train loss:0.013465973280589653\n",
            "train loss:0.00604885120070141\n",
            "train loss:0.025884298528924075\n",
            "train loss:0.01317509844010747\n",
            "=== epoch:492, train acc:0.999, test acc:0.8846 ===\n",
            "train loss:0.0065218983480672\n",
            "train loss:0.01039328552196549\n",
            "train loss:0.01029454257232727\n",
            "train loss:0.008176632630403292\n",
            "train loss:0.006337642258863291\n",
            "train loss:0.00440245175310173\n",
            "train loss:0.007473291690881441\n",
            "train loss:0.008639080380373145\n",
            "train loss:0.010538054225144526\n",
            "train loss:0.009405674062398941\n",
            "=== epoch:493, train acc:0.999, test acc:0.884 ===\n",
            "train loss:0.00803611850273513\n",
            "train loss:0.007181745186546965\n",
            "train loss:0.011543280519106526\n",
            "train loss:0.007628342575204918\n",
            "train loss:0.009748388925490448\n",
            "train loss:0.008178715813625337\n",
            "train loss:0.010678711164143732\n",
            "train loss:0.011868947311766772\n",
            "train loss:0.006701269204628316\n",
            "train loss:0.007919391664902077\n",
            "=== epoch:494, train acc:0.999, test acc:0.8851 ===\n",
            "train loss:0.012232905160005102\n",
            "train loss:0.0094570431191055\n",
            "train loss:0.00877333534975483\n",
            "train loss:0.0087558542549631\n",
            "train loss:0.026260919696745554\n",
            "train loss:0.009081591682891238\n",
            "train loss:0.00848139535600835\n",
            "train loss:0.007288375158198723\n",
            "train loss:0.006541722335691591\n",
            "train loss:0.011094545949633888\n",
            "=== epoch:495, train acc:0.999, test acc:0.8856 ===\n",
            "train loss:0.007170585748731222\n",
            "train loss:0.02393739960582154\n",
            "train loss:0.02400046563934647\n",
            "train loss:0.007795704853693206\n",
            "train loss:0.008614579579818265\n",
            "train loss:0.024524896880710093\n",
            "train loss:0.006871627194129425\n",
            "train loss:0.007870281756022357\n",
            "train loss:0.007284237718488672\n",
            "train loss:0.00592571221601222\n",
            "=== epoch:496, train acc:0.999, test acc:0.8829 ===\n",
            "train loss:0.005800669802528029\n",
            "train loss:0.01037434846362105\n",
            "train loss:0.012168269394140986\n",
            "train loss:0.008714253555738398\n",
            "train loss:0.004312221991279684\n",
            "train loss:0.006341583316490976\n",
            "train loss:0.009569059699401326\n",
            "train loss:0.012503200458784185\n",
            "train loss:0.00845308676674925\n",
            "train loss:0.026056246061598863\n",
            "=== epoch:497, train acc:0.999, test acc:0.8839 ===\n",
            "train loss:0.009701235752892962\n",
            "train loss:0.006152388198554607\n",
            "train loss:0.004732198994407205\n",
            "train loss:0.012941005804054455\n",
            "train loss:0.007036599791777146\n",
            "train loss:0.013183528511981964\n",
            "train loss:0.006003508708493232\n",
            "train loss:0.008951032621942303\n",
            "train loss:0.0038858570080641088\n",
            "train loss:0.005757610486974663\n",
            "=== epoch:498, train acc:0.999, test acc:0.8834 ===\n",
            "train loss:0.009889999701224768\n",
            "train loss:0.007713879894533644\n",
            "train loss:0.008466692408803267\n",
            "train loss:0.00724251254733817\n",
            "train loss:0.0038570622931677206\n",
            "train loss:0.025072087924034828\n",
            "train loss:0.007768274629387863\n",
            "train loss:0.006173396504929556\n",
            "train loss:0.0030015854848518086\n",
            "train loss:0.02113591690061605\n",
            "=== epoch:499, train acc:0.999, test acc:0.8834 ===\n",
            "train loss:0.007504697520218004\n",
            "train loss:0.006000101847481125\n",
            "train loss:0.006928547011930828\n",
            "train loss:0.003690584471087889\n",
            "train loss:0.006669481099055748\n",
            "train loss:0.006343951123690014\n",
            "train loss:0.012289853596251512\n",
            "train loss:0.006569042075440944\n",
            "train loss:0.008998243716802377\n",
            "train loss:0.010356895304773675\n",
            "=== epoch:500, train acc:0.999, test acc:0.8824 ===\n",
            "train loss:0.0076523430253675594\n",
            "train loss:0.0268348277139342\n",
            "train loss:0.008907146542221028\n",
            "train loss:0.010632423489704423\n",
            "train loss:0.009515599397645196\n",
            "train loss:0.005064266028069785\n",
            "train loss:0.013726481508987814\n",
            "train loss:0.007603168875000038\n",
            "train loss:0.007473796938193805\n",
            "train loss:0.023625431645135104\n",
            "=== epoch:501, train acc:0.999, test acc:0.8829 ===\n",
            "train loss:0.009658575630535208\n",
            "train loss:0.01037621746305857\n",
            "train loss:0.008438451840079126\n",
            "train loss:0.004002143705099815\n",
            "train loss:0.010155681146696767\n",
            "train loss:0.010708168642300966\n",
            "train loss:0.011256078244108245\n",
            "train loss:0.008155610585102545\n",
            "train loss:0.006713863209248113\n",
            "train loss:0.007277638127449959\n",
            "=== epoch:502, train acc:0.999, test acc:0.8828 ===\n",
            "train loss:0.005231028897180301\n",
            "train loss:0.011123294918995883\n",
            "train loss:0.006630453267079791\n",
            "train loss:0.021566763201884175\n",
            "train loss:0.008849404187388702\n",
            "train loss:0.006161774960629457\n",
            "train loss:0.024781817244999328\n",
            "train loss:0.006150240722079539\n",
            "train loss:0.004649870250512226\n",
            "train loss:0.00997669381964355\n",
            "=== epoch:503, train acc:0.999, test acc:0.8839 ===\n",
            "train loss:0.007926013371283605\n",
            "train loss:0.022762332520253822\n",
            "train loss:0.006691577412586704\n",
            "train loss:0.00767111846198556\n",
            "train loss:0.007567131776940135\n",
            "train loss:0.006761654554155973\n",
            "train loss:0.006764185086804914\n",
            "train loss:0.008423044275602878\n",
            "train loss:0.011068186873810953\n",
            "train loss:0.009383787714675865\n",
            "=== epoch:504, train acc:0.999, test acc:0.8848 ===\n",
            "train loss:0.008441068316984279\n",
            "train loss:0.006131846128370728\n",
            "train loss:0.009761063175801898\n",
            "train loss:0.029089682415668096\n",
            "train loss:0.0072797728855966545\n",
            "train loss:0.007105821075539412\n",
            "train loss:0.007786030380226231\n",
            "train loss:0.0048919912072389275\n",
            "train loss:0.010030274690041287\n",
            "train loss:0.007050591077415335\n",
            "=== epoch:505, train acc:0.999, test acc:0.8853 ===\n",
            "train loss:0.006986751616968675\n",
            "train loss:0.009859106883979698\n",
            "train loss:0.007402510119888715\n",
            "train loss:0.009789500433196853\n",
            "train loss:0.02088239214633939\n",
            "train loss:0.00872672089477066\n",
            "train loss:0.008953487908482754\n",
            "train loss:0.0031829791187902496\n",
            "train loss:0.007752317828056218\n",
            "train loss:0.009148501581629028\n",
            "=== epoch:506, train acc:0.999, test acc:0.8851 ===\n",
            "train loss:0.011264568606547044\n",
            "train loss:0.005485550298135891\n",
            "train loss:0.02357448305703468\n",
            "train loss:0.0062095763455025125\n",
            "train loss:0.019593630689508472\n",
            "train loss:0.007034921611394372\n",
            "train loss:0.00800063457967911\n",
            "train loss:0.009178310755253239\n",
            "train loss:0.007321164025212465\n",
            "train loss:0.010941418288450602\n",
            "=== epoch:507, train acc:0.999, test acc:0.8863 ===\n",
            "train loss:0.008647654325442632\n",
            "train loss:0.010684489709112854\n",
            "train loss:0.009517725582080928\n",
            "train loss:0.006204017384415319\n",
            "train loss:0.012262699990917357\n",
            "train loss:0.022783800196107776\n",
            "train loss:0.004488890169447552\n",
            "train loss:0.0033403766749720994\n",
            "train loss:0.0052715692366614\n",
            "train loss:0.018044878208617623\n",
            "=== epoch:508, train acc:0.999, test acc:0.884 ===\n",
            "train loss:0.0052408443630232926\n",
            "train loss:0.003980689104248452\n",
            "train loss:0.002924736036201353\n",
            "train loss:0.009638617382234203\n",
            "train loss:0.004823371548391885\n",
            "train loss:0.008374249357526706\n",
            "train loss:0.006814366192179311\n",
            "train loss:0.005021976591343248\n",
            "train loss:0.00625683879639219\n",
            "train loss:0.007422612464699765\n",
            "=== epoch:509, train acc:0.999, test acc:0.8837 ===\n",
            "train loss:0.0050780123717837754\n",
            "train loss:0.00466413988550237\n",
            "train loss:0.006838396736146143\n",
            "train loss:0.009229435878478139\n",
            "train loss:0.00706326561820077\n",
            "train loss:0.008385755782810244\n",
            "train loss:0.004686616224573034\n",
            "train loss:0.004013843844390361\n",
            "train loss:0.006308013383828374\n",
            "train loss:0.006104449023733007\n",
            "=== epoch:510, train acc:0.999, test acc:0.8832 ===\n",
            "train loss:0.006373457614783604\n",
            "train loss:0.03886533768573046\n",
            "train loss:0.005778594748826623\n",
            "train loss:0.007173021558270523\n",
            "train loss:0.004745981825495086\n",
            "train loss:0.0049000703331953\n",
            "train loss:0.008021207279432247\n",
            "train loss:0.0047726391835169815\n",
            "train loss:0.005019618214593232\n",
            "train loss:0.006638994991134007\n",
            "=== epoch:511, train acc:0.999, test acc:0.8832 ===\n",
            "train loss:0.005748483670438797\n",
            "train loss:0.006633499315410922\n",
            "train loss:0.0067112614289052295\n",
            "train loss:0.010719272420273129\n",
            "train loss:0.0069011724246103336\n",
            "train loss:0.006458905762046779\n",
            "train loss:0.011641607993640503\n",
            "train loss:0.021369127742539587\n",
            "train loss:0.00750778649968895\n",
            "train loss:0.004784054253943311\n",
            "=== epoch:512, train acc:0.999, test acc:0.8817 ===\n",
            "train loss:0.005224669183002869\n",
            "train loss:0.0036756478279388947\n",
            "train loss:0.007397852784600203\n",
            "train loss:0.006913095591816871\n",
            "train loss:0.006327859751835313\n",
            "train loss:0.007704737634175146\n",
            "train loss:0.0201956770754354\n",
            "train loss:0.005747819850625759\n",
            "train loss:0.004418173024336643\n",
            "train loss:0.008249891834117513\n",
            "=== epoch:513, train acc:0.999, test acc:0.8839 ===\n",
            "train loss:0.025330883790613847\n",
            "train loss:0.008512745752170042\n",
            "train loss:0.006902284153473448\n",
            "train loss:0.006589348231717963\n",
            "train loss:0.005261547057360072\n",
            "train loss:0.0072410330401650345\n",
            "train loss:0.02281460902666846\n",
            "train loss:0.007933140779960685\n",
            "train loss:0.007672984423191157\n",
            "train loss:0.0059390599926641115\n",
            "=== epoch:514, train acc:0.999, test acc:0.8849 ===\n",
            "train loss:0.006038235363858471\n",
            "train loss:0.003043036632381235\n",
            "train loss:0.006520132805215394\n",
            "train loss:0.021055426240135063\n",
            "train loss:0.007807152175124594\n",
            "train loss:0.003749183347656665\n",
            "train loss:0.005339670972289253\n",
            "train loss:0.005975639212559725\n",
            "train loss:0.007251664136059378\n",
            "train loss:0.0036618960933900236\n",
            "=== epoch:515, train acc:0.999, test acc:0.8841 ===\n",
            "train loss:0.004858814917830465\n",
            "train loss:0.005201146954300568\n",
            "train loss:0.007532547943043944\n",
            "train loss:0.006856147455910607\n",
            "train loss:0.0074580956665768776\n",
            "train loss:0.007332039649544642\n",
            "train loss:0.009424841628590528\n",
            "train loss:0.0035779565313805027\n",
            "train loss:0.010132246153788818\n",
            "train loss:0.005348370020881852\n",
            "=== epoch:516, train acc:0.999, test acc:0.8835 ===\n",
            "train loss:0.005792419695863787\n",
            "train loss:0.0065213584188962125\n",
            "train loss:0.0065465051523950525\n",
            "train loss:0.0028155406306835623\n",
            "train loss:0.008540484278346784\n",
            "train loss:0.006342240463329322\n",
            "train loss:0.008010251207232894\n",
            "train loss:0.007405526435259835\n",
            "train loss:0.006059939313461683\n",
            "train loss:0.02192926634900131\n",
            "=== epoch:517, train acc:0.999, test acc:0.8841 ===\n",
            "train loss:0.006155046347951787\n",
            "train loss:0.004261123200656052\n",
            "train loss:0.006796029277715368\n",
            "train loss:0.0074237067645254\n",
            "train loss:0.006182284935426299\n",
            "train loss:0.00514460404896378\n",
            "train loss:0.009793459234773075\n",
            "train loss:0.004624876967356947\n",
            "train loss:0.006197121386930726\n",
            "train loss:0.005194364814767811\n",
            "=== epoch:518, train acc:0.999, test acc:0.8861 ===\n",
            "train loss:0.009211642921914964\n",
            "train loss:0.0054099265072900145\n",
            "train loss:0.0048506857660555016\n",
            "train loss:0.006850459968020868\n",
            "train loss:0.003987064959190597\n",
            "train loss:0.020860727008807554\n",
            "train loss:0.004619701925328109\n",
            "train loss:0.005948754699763283\n",
            "train loss:0.005211163895512231\n",
            "train loss:0.006524291177094799\n",
            "=== epoch:519, train acc:0.999, test acc:0.8859 ===\n",
            "train loss:0.0033006532195483927\n",
            "train loss:0.006068463795644174\n",
            "train loss:0.006357214118125714\n",
            "train loss:0.00653473066025421\n",
            "train loss:0.008030141475791832\n",
            "train loss:0.005789307464741615\n",
            "train loss:0.0053076942518141415\n",
            "train loss:0.005323797708635102\n",
            "train loss:0.006672633199468516\n",
            "train loss:0.005486717818139478\n",
            "=== epoch:520, train acc:0.999, test acc:0.8842 ===\n",
            "train loss:0.007043969797639553\n",
            "train loss:0.005687093220390116\n",
            "train loss:0.006138846472196563\n",
            "train loss:0.005943022688080175\n",
            "train loss:0.005963901596723243\n",
            "train loss:0.006954455931953528\n",
            "train loss:0.0042262366006184035\n",
            "train loss:0.008040123401210304\n",
            "train loss:0.009707157607496388\n",
            "train loss:0.009786999431080268\n",
            "=== epoch:521, train acc:0.999, test acc:0.8851 ===\n",
            "train loss:0.004344282726629542\n",
            "train loss:0.00911222699369025\n",
            "train loss:0.0055457284220288595\n",
            "train loss:0.0069594031163348015\n",
            "train loss:0.004998688137530036\n",
            "train loss:0.022748452225431346\n",
            "train loss:0.004762952399456471\n",
            "train loss:0.006422552061881842\n",
            "train loss:0.010136387346820631\n",
            "train loss:0.00607804147932968\n",
            "=== epoch:522, train acc:0.999, test acc:0.8837 ===\n",
            "train loss:0.008807731410637289\n",
            "train loss:0.005909092216887873\n",
            "train loss:0.00656157771526691\n",
            "train loss:0.0035981635972797176\n",
            "train loss:0.004854552403815129\n",
            "train loss:0.0033184169887360082\n",
            "train loss:0.00498421068685149\n",
            "train loss:0.005206926114514486\n",
            "train loss:0.003708181283656692\n",
            "train loss:0.007152448977806838\n",
            "=== epoch:523, train acc:0.999, test acc:0.8839 ===\n",
            "train loss:0.024820638675180556\n",
            "train loss:0.0033454890574996675\n",
            "train loss:0.005973549647056563\n",
            "train loss:0.005111489768395014\n",
            "train loss:0.03928503550551576\n",
            "train loss:0.005388599121108712\n",
            "train loss:0.004031491217441132\n",
            "train loss:0.006474725534614368\n",
            "train loss:0.00636180682771746\n",
            "train loss:0.003774524508540923\n",
            "=== epoch:524, train acc:0.999, test acc:0.8831 ===\n",
            "train loss:0.006525864634523982\n",
            "train loss:0.007191592457958775\n",
            "train loss:0.02039890767571567\n",
            "train loss:0.006004810797610555\n",
            "train loss:0.006656984443106575\n",
            "train loss:0.007427476923220945\n",
            "train loss:0.005239797311991391\n",
            "train loss:0.019195174889361375\n",
            "train loss:0.009574064559127182\n",
            "train loss:0.005311206052305931\n",
            "=== epoch:525, train acc:0.999, test acc:0.8839 ===\n",
            "train loss:0.008451681943513607\n",
            "train loss:0.004575273373259295\n",
            "train loss:0.003711036382778145\n",
            "train loss:0.004950527256041117\n",
            "train loss:0.003950513263913411\n",
            "train loss:0.004442127717261542\n",
            "train loss:0.006874356911506856\n",
            "train loss:0.004983295744157882\n",
            "train loss:0.004543751383957127\n",
            "train loss:0.006129951396636857\n",
            "=== epoch:526, train acc:0.999, test acc:0.8843 ===\n",
            "train loss:0.004901272642221457\n",
            "train loss:0.009288756445272675\n",
            "train loss:0.005677435475613026\n",
            "train loss:0.005312737991308905\n",
            "train loss:0.006204333428018695\n",
            "train loss:0.004857981034922208\n",
            "train loss:0.001877211756135392\n",
            "train loss:0.004264121502119752\n",
            "train loss:0.006687886945153048\n",
            "train loss:0.009869789761189402\n",
            "=== epoch:527, train acc:0.999, test acc:0.8831 ===\n",
            "train loss:0.005847828039420038\n",
            "train loss:0.00688961788557373\n",
            "train loss:0.00469842235918223\n",
            "train loss:0.007002097309617593\n",
            "train loss:0.01897257886076452\n",
            "train loss:0.005651738744872731\n",
            "train loss:0.018608091907809685\n",
            "train loss:0.008993907407177018\n",
            "train loss:0.00653670951175664\n",
            "train loss:0.005405798251584609\n",
            "=== epoch:528, train acc:0.999, test acc:0.8834 ===\n",
            "train loss:0.022562360576829348\n",
            "train loss:0.0074344130606315804\n",
            "train loss:0.005679243163481055\n",
            "train loss:0.004848846689108943\n",
            "train loss:0.0042609666763195175\n",
            "train loss:0.004298511080509149\n",
            "train loss:0.0058696338021354795\n",
            "train loss:0.005582299270107377\n",
            "train loss:0.007165067002123594\n",
            "train loss:0.004658755438593339\n",
            "=== epoch:529, train acc:0.999, test acc:0.8833 ===\n",
            "train loss:0.008630510348772283\n",
            "train loss:0.007017448304266875\n",
            "train loss:0.004404277745155461\n",
            "train loss:0.008304301400677516\n",
            "train loss:0.00544188231322202\n",
            "train loss:0.0043838705026269095\n",
            "train loss:0.004500919432481892\n",
            "train loss:0.004948262531390118\n",
            "train loss:0.0026461480123343584\n",
            "train loss:0.003669564308433998\n",
            "=== epoch:530, train acc:0.999, test acc:0.8832 ===\n",
            "train loss:0.006529359265888989\n",
            "train loss:0.005704160522381825\n",
            "train loss:0.005632099761726393\n",
            "train loss:0.003911214283581253\n",
            "train loss:0.0035947124172634147\n",
            "train loss:0.006625671568221875\n",
            "train loss:0.022682559582983756\n",
            "train loss:0.007237449165906007\n",
            "train loss:0.007649619338113064\n",
            "train loss:0.007505939397114969\n",
            "=== epoch:531, train acc:0.999, test acc:0.8824 ===\n",
            "train loss:0.006594410868786454\n",
            "train loss:0.004407512888806\n",
            "train loss:0.02120081035905992\n",
            "train loss:0.00598982627343538\n",
            "train loss:0.02019738115919126\n",
            "train loss:0.021153380327460898\n",
            "train loss:0.0230939394233632\n",
            "train loss:0.008628051945009008\n",
            "train loss:0.0043217116795936945\n",
            "train loss:0.02138923974080086\n",
            "=== epoch:532, train acc:0.999, test acc:0.8828 ===\n",
            "train loss:0.004203480564899761\n",
            "train loss:0.006288447721710038\n",
            "train loss:0.01827983383146011\n",
            "train loss:0.0068423906328539475\n",
            "train loss:0.004356481514383471\n",
            "train loss:0.005436647540154669\n",
            "train loss:0.007162214388627333\n",
            "train loss:0.004982536078818837\n",
            "train loss:0.006035738548155566\n",
            "train loss:0.003980566608724374\n",
            "=== epoch:533, train acc:0.999, test acc:0.8838 ===\n",
            "train loss:0.00438925243725351\n",
            "train loss:0.0031716890475158356\n",
            "train loss:0.0057497132924483815\n",
            "train loss:0.005074686820897996\n",
            "train loss:0.006165396546903018\n",
            "train loss:0.00587216168168757\n",
            "train loss:0.005142305468549486\n",
            "train loss:0.005300323233357174\n",
            "train loss:0.004485201274187322\n",
            "train loss:0.01853112429078546\n",
            "=== epoch:534, train acc:0.999, test acc:0.8835 ===\n",
            "train loss:0.006080164268023377\n",
            "train loss:0.006879325402936487\n",
            "train loss:0.0057288947933038315\n",
            "train loss:0.004343302970208141\n",
            "train loss:0.030050825896581767\n",
            "train loss:0.005128489285773451\n",
            "train loss:0.018324399436962527\n",
            "train loss:0.0035183969894326855\n",
            "train loss:0.004882521010991334\n",
            "train loss:0.004782448234704944\n",
            "=== epoch:535, train acc:0.999, test acc:0.8849 ===\n",
            "train loss:0.0058216869570299834\n",
            "train loss:0.005824962916533941\n",
            "train loss:0.005320647211021006\n",
            "train loss:0.00439040631984192\n",
            "train loss:0.004550382385116942\n",
            "train loss:0.004234837701595478\n",
            "train loss:0.004991898945586115\n",
            "train loss:0.006745871939868464\n",
            "train loss:0.004881373538168733\n",
            "train loss:0.011810218113190161\n",
            "=== epoch:536, train acc:0.999, test acc:0.8832 ===\n",
            "train loss:0.00466219969224366\n",
            "train loss:0.016966887208142684\n",
            "train loss:0.0027292811921276012\n",
            "train loss:0.003337378900157288\n",
            "train loss:0.004960011547598614\n",
            "train loss:0.005933400759944417\n",
            "train loss:0.0050631617535775155\n",
            "train loss:0.0033036505751997285\n",
            "train loss:0.006702592000668366\n",
            "train loss:0.003355428141661883\n",
            "=== epoch:537, train acc:0.999, test acc:0.8845 ===\n",
            "train loss:0.0041464914367159615\n",
            "train loss:0.0028154005797920508\n",
            "train loss:0.007534650550162745\n",
            "train loss:0.0037163183104164904\n",
            "train loss:0.006953413592832621\n",
            "train loss:0.005749349472302534\n",
            "train loss:0.018359260928308637\n",
            "train loss:0.007074105306883549\n",
            "train loss:0.0038434435994243337\n",
            "train loss:0.004157597500458136\n",
            "=== epoch:538, train acc:0.999, test acc:0.8844 ===\n",
            "train loss:0.004030398872563882\n",
            "train loss:0.004553994394253155\n",
            "train loss:0.00587184170614172\n",
            "train loss:0.004253502941915972\n",
            "train loss:0.0034302859770651306\n",
            "train loss:0.003775365464812735\n",
            "train loss:0.006689433473604951\n",
            "train loss:0.003419562455726915\n",
            "train loss:0.004208362010403799\n",
            "train loss:0.005706343115902238\n",
            "=== epoch:539, train acc:0.999, test acc:0.886 ===\n",
            "train loss:0.00655558613700549\n",
            "train loss:0.0034763221269462252\n",
            "train loss:0.004055915322028103\n",
            "train loss:0.006463321157036448\n",
            "train loss:0.004799981665427241\n",
            "train loss:0.006977123081360654\n",
            "train loss:0.006405765899535504\n",
            "train loss:0.005022643814755791\n",
            "train loss:0.0037032802562290083\n",
            "train loss:0.00596306891753419\n",
            "=== epoch:540, train acc:0.999, test acc:0.8851 ===\n",
            "train loss:0.0030761587391832106\n",
            "train loss:0.0066291885089428855\n",
            "train loss:0.003368162104911549\n",
            "train loss:0.006101388994275662\n",
            "train loss:0.0056946175328402016\n",
            "train loss:0.03150091284855433\n",
            "train loss:0.005177833494001007\n",
            "train loss:0.003723599810029905\n",
            "train loss:0.004006747583792717\n",
            "train loss:0.0035357993327636396\n",
            "=== epoch:541, train acc:0.999, test acc:0.8844 ===\n",
            "train loss:0.005507562120953363\n",
            "train loss:0.005565117749965167\n",
            "train loss:0.0058659279315677\n",
            "train loss:0.004807743618803068\n",
            "train loss:0.0032535916969119337\n",
            "train loss:0.00647604007331353\n",
            "train loss:0.007064265019709887\n",
            "train loss:0.004817816738489536\n",
            "train loss:0.005490407884893246\n",
            "train loss:0.0027827967238909703\n",
            "=== epoch:542, train acc:0.999, test acc:0.8844 ===\n",
            "train loss:0.003955708416121975\n",
            "train loss:0.003795431020077325\n",
            "train loss:0.005384296876913552\n",
            "train loss:0.004716698948054787\n",
            "train loss:0.004784462674711607\n",
            "train loss:0.00249391063909337\n",
            "train loss:0.0042560465186975175\n",
            "train loss:0.005343719602184433\n",
            "train loss:0.003936837867678786\n",
            "train loss:0.0054279416045569\n",
            "=== epoch:543, train acc:0.999, test acc:0.8856 ===\n",
            "train loss:0.01755366377894292\n",
            "train loss:0.004789701889198233\n",
            "train loss:0.018021266640161904\n",
            "train loss:0.004074900992955696\n",
            "train loss:0.003061431123153499\n",
            "train loss:0.0074124758374621924\n",
            "train loss:0.004747620463442924\n",
            "train loss:0.0072694701908683716\n",
            "train loss:0.008189543970200518\n",
            "train loss:0.02032184269540048\n",
            "=== epoch:544, train acc:0.999, test acc:0.8845 ===\n",
            "train loss:0.0041109476427645085\n",
            "train loss:0.006858518719662481\n",
            "train loss:0.004926369490398322\n",
            "train loss:0.00858683416047694\n",
            "train loss:0.004401522456571124\n",
            "train loss:0.005301303898286594\n",
            "train loss:0.0049155291021997175\n",
            "train loss:0.004252497742510963\n",
            "train loss:0.006363953947364414\n",
            "train loss:0.004485029509444296\n",
            "=== epoch:545, train acc:0.999, test acc:0.8839 ===\n",
            "train loss:0.0030963899224072766\n",
            "train loss:0.00345140436875642\n",
            "train loss:0.018480863389799106\n",
            "train loss:0.004042287091765793\n",
            "train loss:0.006366554679267766\n",
            "train loss:0.0039703597743498634\n",
            "train loss:0.006634226116283047\n",
            "train loss:0.00384486120215927\n",
            "train loss:0.005578672985660417\n",
            "train loss:0.0047813106848410706\n",
            "=== epoch:546, train acc:0.999, test acc:0.8846 ===\n",
            "train loss:0.005151278373865757\n",
            "train loss:0.0034340621753784968\n",
            "train loss:0.003730365626775462\n",
            "train loss:0.006300725528283849\n",
            "train loss:0.006696024838805099\n",
            "train loss:0.005005280169512471\n",
            "train loss:0.0039942371678342295\n",
            "train loss:0.005505690562841047\n",
            "train loss:0.004394287440283236\n",
            "train loss:0.005234721197271081\n",
            "=== epoch:547, train acc:0.999, test acc:0.8832 ===\n",
            "train loss:0.003386149108262081\n",
            "train loss:0.003723447753985003\n",
            "train loss:0.0028305277764883578\n",
            "train loss:0.003290007166156177\n",
            "train loss:0.005166045749945195\n",
            "train loss:0.004486056850058053\n",
            "train loss:0.007429507447250345\n",
            "train loss:0.006145944733080151\n",
            "train loss:0.0032445081109812326\n",
            "train loss:0.003400061373763752\n",
            "=== epoch:548, train acc:0.999, test acc:0.8834 ===\n",
            "train loss:0.005030838204996546\n",
            "train loss:0.005443677574789474\n",
            "train loss:0.00427118435115015\n",
            "train loss:0.005693747650440446\n",
            "train loss:0.004679742756119475\n",
            "train loss:0.004423469126561907\n",
            "train loss:0.00417503405619928\n",
            "train loss:0.004305239170468837\n",
            "train loss:0.002574668079433336\n",
            "train loss:0.0042035351524382\n",
            "=== epoch:549, train acc:0.999, test acc:0.8845 ===\n",
            "train loss:0.005655360480243253\n",
            "train loss:0.005212496649580669\n",
            "train loss:0.002581165097898029\n",
            "train loss:0.003479461873998512\n",
            "train loss:0.0047604762478774\n",
            "train loss:0.002973621098586735\n",
            "train loss:0.01807049716715385\n",
            "train loss:0.007121608878932796\n",
            "train loss:0.003485052028209818\n",
            "train loss:0.004312321029123194\n",
            "=== epoch:550, train acc:0.999, test acc:0.8861 ===\n",
            "train loss:0.004262765452117428\n",
            "train loss:0.003970501269370784\n",
            "train loss:0.0024840713567705714\n",
            "train loss:0.018088904953777026\n",
            "train loss:0.004853318449898367\n",
            "train loss:0.006552293446260475\n",
            "train loss:0.003567803481893226\n",
            "train loss:0.0052144474010594735\n",
            "train loss:0.003831092145059195\n",
            "train loss:0.0054380407583942665\n",
            "=== epoch:551, train acc:0.999, test acc:0.8859 ===\n",
            "train loss:0.003243981917493786\n",
            "train loss:0.004560220570955613\n",
            "train loss:0.004238584514050174\n",
            "train loss:0.002909140200878806\n",
            "train loss:0.006700142502491182\n",
            "train loss:0.004368010849660301\n",
            "train loss:0.006146766142183978\n",
            "train loss:0.003834619591662458\n",
            "train loss:0.006630745953564557\n",
            "train loss:0.006693749930885181\n",
            "=== epoch:552, train acc:0.999, test acc:0.8867 ===\n",
            "train loss:0.003823781391613651\n",
            "train loss:0.00462296700168863\n",
            "train loss:0.0033763046404665983\n",
            "train loss:0.0026165180710474613\n",
            "train loss:0.003004955563358266\n",
            "train loss:0.004416898505479393\n",
            "train loss:0.0023252568184248166\n",
            "train loss:0.004374021580102162\n",
            "train loss:0.006087720502711469\n",
            "train loss:0.004654652938881738\n",
            "=== epoch:553, train acc:0.999, test acc:0.8864 ===\n",
            "train loss:0.0035744499182122965\n",
            "train loss:0.005263059533401833\n",
            "train loss:0.004765978245858579\n",
            "train loss:0.003571804895703212\n",
            "train loss:0.0024249564241122148\n",
            "train loss:0.005021415934740444\n",
            "train loss:0.005716646293262565\n",
            "train loss:0.006592392283200566\n",
            "train loss:0.0036515902430943378\n",
            "train loss:0.0025063403684607503\n",
            "=== epoch:554, train acc:0.999, test acc:0.8864 ===\n",
            "train loss:0.0026930846335913154\n",
            "train loss:0.0038054696758031054\n",
            "train loss:0.007951852386612225\n",
            "train loss:0.0038921671947531205\n",
            "train loss:0.0047470038741804265\n",
            "train loss:0.005592707099794723\n",
            "train loss:0.004590211127438901\n",
            "train loss:0.0028981497488303276\n",
            "train loss:0.004828020699510025\n",
            "train loss:0.00666812974709222\n",
            "=== epoch:555, train acc:0.999, test acc:0.8858 ===\n",
            "train loss:0.004302255534168537\n",
            "train loss:0.004364499498686158\n",
            "train loss:0.006758892548871259\n",
            "train loss:0.004704719365793627\n",
            "train loss:0.006491640819807755\n",
            "train loss:0.002830784729028351\n",
            "train loss:0.002729384520579993\n",
            "train loss:0.0029430119185892135\n",
            "train loss:0.0033125701191937863\n",
            "train loss:0.0021731289608722033\n",
            "=== epoch:556, train acc:0.999, test acc:0.8862 ===\n",
            "train loss:0.004463127195625514\n",
            "train loss:0.006885537562895142\n",
            "train loss:0.0040379891403902884\n",
            "train loss:0.004164281878884937\n",
            "train loss:0.018708066722438285\n",
            "train loss:0.0054511052900748655\n",
            "train loss:0.0034981074393521504\n",
            "train loss:0.005652433708561191\n",
            "train loss:0.006523390702258737\n",
            "train loss:0.005578056562206487\n",
            "=== epoch:557, train acc:0.999, test acc:0.8867 ===\n",
            "train loss:0.00349180661131457\n",
            "train loss:0.004451273633455686\n",
            "train loss:0.0033651158951353375\n",
            "train loss:0.01820083494100358\n",
            "train loss:0.003183662570750072\n",
            "train loss:0.00315770123039672\n",
            "train loss:0.003463763152755605\n",
            "train loss:0.003139586429233833\n",
            "train loss:0.005873617102170013\n",
            "train loss:0.01801431411079305\n",
            "=== epoch:558, train acc:0.999, test acc:0.8857 ===\n",
            "train loss:0.0027447012571399807\n",
            "train loss:0.005826958377934628\n",
            "train loss:0.003871959252997579\n",
            "train loss:0.01591811388652673\n",
            "train loss:0.0037231026329678724\n",
            "train loss:0.004024848961704879\n",
            "train loss:0.0039626799305354215\n",
            "train loss:0.0034310324443614566\n",
            "train loss:0.005855715106008825\n",
            "train loss:0.005587901445803072\n",
            "=== epoch:559, train acc:0.999, test acc:0.8864 ===\n",
            "train loss:0.02089843787715244\n",
            "train loss:0.003672636066937489\n",
            "train loss:0.003448540027021034\n",
            "train loss:0.006321067893868144\n",
            "train loss:0.0031062889205682115\n",
            "train loss:0.005635162840378107\n",
            "train loss:0.0019098513168865092\n",
            "train loss:0.0033120830949716256\n",
            "train loss:0.0026563907050281364\n",
            "train loss:0.018479589007876142\n",
            "=== epoch:560, train acc:0.999, test acc:0.8865 ===\n",
            "train loss:0.004319092221861478\n",
            "train loss:0.0039396860132993525\n",
            "train loss:0.0037264795194355193\n",
            "train loss:0.005186594418687318\n",
            "train loss:0.006002108976698879\n",
            "train loss:0.005419946551328509\n",
            "train loss:0.004807804676017871\n",
            "train loss:0.0033084238219216145\n",
            "train loss:0.0030605270688856285\n",
            "train loss:0.0033846274500165027\n",
            "=== epoch:561, train acc:0.999, test acc:0.8879 ===\n",
            "train loss:0.006457958864128877\n",
            "train loss:0.004995638530740431\n",
            "train loss:0.018030304022612055\n",
            "train loss:0.005026854824869236\n",
            "train loss:0.002857190634328541\n",
            "train loss:0.017754302159134774\n",
            "train loss:0.004750163544364931\n",
            "train loss:0.0033271431751811607\n",
            "train loss:0.004354711090586094\n",
            "train loss:0.00470683346556499\n",
            "=== epoch:562, train acc:0.999, test acc:0.8877 ===\n",
            "train loss:0.005317882169317444\n",
            "train loss:0.004964650968731068\n",
            "train loss:0.00520986248157293\n",
            "train loss:0.004825415178609518\n",
            "train loss:0.003977148306101748\n",
            "train loss:0.003345992739039659\n",
            "train loss:0.01930950740287448\n",
            "train loss:0.0041785835547236885\n",
            "train loss:0.003497238036942359\n",
            "train loss:0.003341554514805704\n",
            "=== epoch:563, train acc:0.999, test acc:0.8875 ===\n",
            "train loss:0.004219000712810586\n",
            "train loss:0.003933234552564808\n",
            "train loss:0.005429538718713888\n",
            "train loss:0.004236080613258358\n",
            "train loss:0.004257868612761981\n",
            "train loss:0.004229764326723825\n",
            "train loss:0.004787944298742385\n",
            "train loss:0.03930562388302011\n",
            "train loss:0.0037284227649916095\n",
            "train loss:0.0031693533677766765\n",
            "=== epoch:564, train acc:0.999, test acc:0.8853 ===\n",
            "train loss:0.0035339076721201284\n",
            "train loss:0.003795919681569865\n",
            "train loss:0.0028657670047199557\n",
            "train loss:0.004539072186168711\n",
            "train loss:0.004648461778829402\n",
            "train loss:0.003031899954967125\n",
            "train loss:0.0032430993491340938\n",
            "train loss:0.0030267165246004495\n",
            "train loss:0.0037386500807054576\n",
            "train loss:0.003381049362904813\n",
            "=== epoch:565, train acc:0.999, test acc:0.8863 ===\n",
            "train loss:0.0026455678766007682\n",
            "train loss:0.005658838144587207\n",
            "train loss:0.0030217575826501403\n",
            "train loss:0.004186426177229957\n",
            "train loss:0.0023638488676257217\n",
            "train loss:0.004367520839179828\n",
            "train loss:0.002823105708443661\n",
            "train loss:0.002713677789570891\n",
            "train loss:0.005148047618485249\n",
            "train loss:0.00376673139258272\n",
            "=== epoch:566, train acc:0.999, test acc:0.8854 ===\n",
            "train loss:0.004707206072258336\n",
            "train loss:0.0032966607649392147\n",
            "train loss:0.00530059392006949\n",
            "train loss:0.006026221592352905\n",
            "train loss:0.003228437483984365\n",
            "train loss:0.0036209751314090787\n",
            "train loss:0.003254022646879642\n",
            "train loss:0.002349877443703471\n",
            "train loss:0.002941040325242601\n",
            "train loss:0.0028435766144311926\n",
            "=== epoch:567, train acc:0.999, test acc:0.8867 ===\n",
            "train loss:0.018036586632956094\n",
            "train loss:0.016938116339902855\n",
            "train loss:0.004327190057570063\n",
            "train loss:0.01658556474876992\n",
            "train loss:0.002103853057526946\n",
            "train loss:0.003527022533472388\n",
            "train loss:0.0028692169974063614\n",
            "train loss:0.004028252521218016\n",
            "train loss:0.003363656772460685\n",
            "train loss:0.004520345120788907\n",
            "=== epoch:568, train acc:0.999, test acc:0.8863 ===\n",
            "train loss:0.0038115219747859646\n",
            "train loss:0.0028730811496714952\n",
            "train loss:0.0028577801633482697\n",
            "train loss:0.003086211158627325\n",
            "train loss:0.006296260391479402\n",
            "train loss:0.004746147436485737\n",
            "train loss:0.01613445047267366\n",
            "train loss:0.005253708874275248\n",
            "train loss:0.004969939584740851\n",
            "train loss:0.00498361820091675\n",
            "=== epoch:569, train acc:0.999, test acc:0.8854 ===\n",
            "train loss:0.005488022195117991\n",
            "train loss:0.002465307404370847\n",
            "train loss:0.005734240039572101\n",
            "train loss:0.0034595229462962727\n",
            "train loss:0.0027569123473442235\n",
            "train loss:0.0033741843930421016\n",
            "train loss:0.0021760895846117782\n",
            "train loss:0.0019349755602936197\n",
            "train loss:0.003413303171228545\n",
            "train loss:0.006351738641713409\n",
            "=== epoch:570, train acc:0.999, test acc:0.885 ===\n",
            "train loss:0.005354117601863345\n",
            "train loss:0.017647681374718994\n",
            "train loss:0.00606074875584678\n",
            "train loss:0.0033801396455783147\n",
            "train loss:0.0037005634172230808\n",
            "train loss:0.016585601355766297\n",
            "train loss:0.003381661104781906\n",
            "train loss:0.003745356009728836\n",
            "train loss:0.0018445878935790128\n",
            "train loss:0.0029356468797087244\n",
            "=== epoch:571, train acc:0.999, test acc:0.8862 ===\n",
            "train loss:0.020853357163457025\n",
            "train loss:0.0033183760791320894\n",
            "train loss:0.0042481888163433965\n",
            "train loss:0.003207638669483715\n",
            "train loss:0.0045370468636429405\n",
            "train loss:0.0022008424240550274\n",
            "train loss:0.003628735441219156\n",
            "train loss:0.004536881614628402\n",
            "train loss:0.005531475560910129\n",
            "train loss:0.015380563081192735\n",
            "=== epoch:572, train acc:0.999, test acc:0.885 ===\n",
            "train loss:0.004328201249092088\n",
            "train loss:0.004364609471926278\n",
            "train loss:0.0028925397323154157\n",
            "train loss:0.004117387004686013\n",
            "train loss:0.0034609138380656142\n",
            "train loss:0.004159071495181707\n",
            "train loss:0.005161153854695193\n",
            "train loss:0.00356567905852868\n",
            "train loss:0.005562750962884536\n",
            "train loss:0.015445823345669938\n",
            "=== epoch:573, train acc:0.999, test acc:0.8844 ===\n",
            "train loss:0.004186847439085338\n",
            "train loss:0.003853109925752417\n",
            "train loss:0.017387768950825836\n",
            "train loss:0.005049861387344927\n",
            "train loss:0.0035968656989641117\n",
            "train loss:0.0035899277875216175\n",
            "train loss:0.02837162786567098\n",
            "train loss:0.0032676617319673997\n",
            "train loss:0.006229418280743287\n",
            "train loss:0.0024058863394674558\n",
            "=== epoch:574, train acc:0.999, test acc:0.8855 ===\n",
            "train loss:0.015275319039287541\n",
            "train loss:0.004393075578913879\n",
            "train loss:0.0030087109316277423\n",
            "train loss:0.003637514671387616\n",
            "train loss:0.003298242257065929\n",
            "train loss:0.002973673680534688\n",
            "train loss:0.004820364045494925\n",
            "train loss:0.005033012598481114\n",
            "train loss:0.01736856161028586\n",
            "train loss:0.0028959118686991735\n",
            "=== epoch:575, train acc:0.999, test acc:0.8864 ===\n",
            "train loss:0.0047649488886024275\n",
            "train loss:0.01683665482256901\n",
            "train loss:0.005145670945641885\n",
            "train loss:0.0025077243466017566\n",
            "train loss:0.025266750551869416\n",
            "train loss:0.0020752231039472074\n",
            "train loss:0.002186695894088668\n",
            "train loss:0.0038072384739578045\n",
            "train loss:0.004189140828785936\n",
            "train loss:0.0029898278803571926\n",
            "=== epoch:576, train acc:0.999, test acc:0.8872 ===\n",
            "train loss:0.015248355521616989\n",
            "train loss:0.004395167826438541\n",
            "train loss:0.004864973440387145\n",
            "train loss:0.0030189470969858518\n",
            "train loss:0.004018589686417211\n",
            "train loss:0.003683204197104937\n",
            "train loss:0.004294944709850365\n",
            "train loss:0.003472859563463536\n",
            "train loss:0.002165537572986315\n",
            "train loss:0.005034501271078511\n",
            "=== epoch:577, train acc:0.999, test acc:0.8842 ===\n",
            "train loss:0.0019389690588749622\n",
            "train loss:0.003962108473685446\n",
            "train loss:0.004584820436518278\n",
            "train loss:0.0030995330832779312\n",
            "train loss:0.003719631977145195\n",
            "train loss:0.007052638458587446\n",
            "train loss:0.0038300825563952422\n",
            "train loss:0.005398744322614875\n",
            "train loss:0.005745016565392165\n",
            "train loss:0.0034458980091267156\n",
            "=== epoch:578, train acc:0.999, test acc:0.8834 ===\n",
            "train loss:0.00506852658717428\n",
            "train loss:0.004763910638165336\n",
            "train loss:0.0034574352451775736\n",
            "train loss:0.0037105795383719775\n",
            "train loss:0.003166267195077138\n",
            "train loss:0.003703774449520945\n",
            "train loss:0.003986623839932992\n",
            "train loss:0.0017210064615008525\n",
            "train loss:0.0027342484018994563\n",
            "train loss:0.004575634511438909\n",
            "=== epoch:579, train acc:0.999, test acc:0.884 ===\n",
            "train loss:0.002090652403497746\n",
            "train loss:0.003603931709966734\n",
            "train loss:0.0026712961208301784\n",
            "train loss:0.004411899475505128\n",
            "train loss:0.002475960583562164\n",
            "train loss:0.003622236296769884\n",
            "train loss:0.0036670984639380014\n",
            "train loss:0.002660271653215285\n",
            "train loss:0.013952365393492195\n",
            "train loss:0.013246790957270186\n",
            "=== epoch:580, train acc:1.0, test acc:0.8849 ===\n",
            "train loss:0.0031354228349030123\n",
            "train loss:0.003966240141646859\n",
            "train loss:0.0027666384521615444\n",
            "train loss:0.002376451342592153\n",
            "train loss:0.0023704649834943264\n",
            "train loss:0.00397272665502608\n",
            "train loss:0.002686441063304662\n",
            "train loss:0.002874952929827001\n",
            "train loss:0.006962239319451499\n",
            "train loss:0.015172116882134963\n",
            "=== epoch:581, train acc:1.0, test acc:0.8856 ===\n",
            "train loss:0.002463508585574402\n",
            "train loss:0.003945046613030399\n",
            "train loss:0.003760949330530886\n",
            "train loss:0.0027676862902378235\n",
            "train loss:0.0022961984235776492\n",
            "train loss:0.0023027153833387994\n",
            "train loss:0.0035463421056325974\n",
            "train loss:0.004227638600146032\n",
            "train loss:0.004244300350354366\n",
            "train loss:0.004577706933677566\n",
            "=== epoch:582, train acc:0.999, test acc:0.8866 ===\n",
            "train loss:0.003220476220954719\n",
            "train loss:0.01374556528203874\n",
            "train loss:0.00209521569674746\n",
            "train loss:0.0034462109631552894\n",
            "train loss:0.013176473361620564\n",
            "train loss:0.004361198754648314\n",
            "train loss:0.004468284128335706\n",
            "train loss:0.0028601226262477057\n",
            "train loss:0.0016272869510696917\n",
            "train loss:0.006478782492354277\n",
            "=== epoch:583, train acc:1.0, test acc:0.8875 ===\n",
            "train loss:0.004503123785787907\n",
            "train loss:0.0019813581337920928\n",
            "train loss:0.002978545307078957\n",
            "train loss:0.002493636612058036\n",
            "train loss:0.004228560460436011\n",
            "train loss:0.004502300654765131\n",
            "train loss:0.003930872473536418\n",
            "train loss:0.0038392954532013575\n",
            "train loss:0.0039137139640221625\n",
            "train loss:0.0035417321900355235\n",
            "=== epoch:584, train acc:0.999, test acc:0.8859 ===\n",
            "train loss:0.013087979746831381\n",
            "train loss:0.0029778838886957678\n",
            "train loss:0.004249967674933767\n",
            "train loss:0.0020009124800447935\n",
            "train loss:0.0025242424662736927\n",
            "train loss:0.0021537352714656563\n",
            "train loss:0.004194809075683393\n",
            "train loss:0.0035580530385227378\n",
            "train loss:0.002890730934308228\n",
            "train loss:0.0025129653190093426\n",
            "=== epoch:585, train acc:0.999, test acc:0.887 ===\n",
            "train loss:0.00437179365129321\n",
            "train loss:0.005210134767107991\n",
            "train loss:0.003982339788744328\n",
            "train loss:0.0033767296643928122\n",
            "train loss:0.004563170064360206\n",
            "train loss:0.003374275793158121\n",
            "train loss:0.004829047990574429\n",
            "train loss:0.003394803967563868\n",
            "train loss:0.003044552055273939\n",
            "train loss:0.0041385421495458\n",
            "=== epoch:586, train acc:0.999, test acc:0.8856 ===\n",
            "train loss:0.003362544900547909\n",
            "train loss:0.0029328456264846843\n",
            "train loss:0.004246724427799466\n",
            "train loss:0.003237538572320996\n",
            "train loss:0.0033660189700741904\n",
            "train loss:0.002877327483865623\n",
            "train loss:0.014720250834784706\n",
            "train loss:0.004641082968456756\n",
            "train loss:0.002450557806431477\n",
            "train loss:0.002542412547854345\n",
            "=== epoch:587, train acc:0.999, test acc:0.8847 ===\n",
            "train loss:0.003938258484778833\n",
            "train loss:0.02471187001485824\n",
            "train loss:0.004461609999187567\n",
            "train loss:0.001077660325876487\n",
            "train loss:0.0032786508043618503\n",
            "train loss:0.0018088776233531768\n",
            "train loss:0.011655935529440704\n",
            "train loss:0.002514817258578814\n",
            "train loss:0.0025701300889912643\n",
            "train loss:0.0026381601534856596\n",
            "=== epoch:588, train acc:1.0, test acc:0.8855 ===\n",
            "train loss:0.003224624909814887\n",
            "train loss:0.003664596893081635\n",
            "train loss:0.001620407931150761\n",
            "train loss:0.004099407935185827\n",
            "train loss:0.0030173443313460495\n",
            "train loss:0.0029367994468533372\n",
            "train loss:0.002526059412134242\n",
            "train loss:0.0042804370005432215\n",
            "train loss:0.004592735149798855\n",
            "train loss:0.013253714542409999\n",
            "=== epoch:589, train acc:1.0, test acc:0.8865 ===\n",
            "train loss:0.0026662833647253105\n",
            "train loss:0.002904000074270668\n",
            "train loss:0.005272138327054873\n",
            "train loss:0.004927226631135779\n",
            "train loss:0.004096154636201657\n",
            "train loss:0.0024591096620232952\n",
            "train loss:0.002138026642972425\n",
            "train loss:0.0021457431551396206\n",
            "train loss:0.004137983521690644\n",
            "train loss:0.0017962737553012728\n",
            "=== epoch:590, train acc:1.0, test acc:0.8844 ===\n",
            "train loss:0.0040540259208729\n",
            "train loss:0.0036298403167332517\n",
            "train loss:0.0038726374794170455\n",
            "train loss:0.0015738348488412407\n",
            "train loss:0.013320255744587972\n",
            "train loss:0.004541833110463923\n",
            "train loss:0.0029149524182658453\n",
            "train loss:0.0032958731295785982\n",
            "train loss:0.002594579441586657\n",
            "train loss:0.0035366346087596697\n",
            "=== epoch:591, train acc:0.999, test acc:0.8848 ===\n",
            "train loss:0.0019792632722529417\n",
            "train loss:0.0027778422902200455\n",
            "train loss:0.004021443153753837\n",
            "train loss:0.0024655111710768364\n",
            "train loss:0.004183004450185824\n",
            "train loss:0.0028369075788635617\n",
            "train loss:0.002597721912005893\n",
            "train loss:0.004354373455583264\n",
            "train loss:0.0031126260134793447\n",
            "train loss:0.012775152257894738\n",
            "=== epoch:592, train acc:1.0, test acc:0.8865 ===\n",
            "train loss:0.003617016811582601\n",
            "train loss:0.002221811473938609\n",
            "train loss:0.0022260210365965035\n",
            "train loss:0.002399861666375802\n",
            "train loss:0.0019552538051032164\n",
            "train loss:0.0026725500637464145\n",
            "train loss:0.001975772390959766\n",
            "train loss:0.0021038518069664714\n",
            "train loss:0.0027088767490371095\n",
            "train loss:0.0025231301812316926\n",
            "=== epoch:593, train acc:1.0, test acc:0.8858 ===\n",
            "train loss:0.003357590282730498\n",
            "train loss:0.0023752830575331143\n",
            "train loss:0.0027970469482636795\n",
            "train loss:0.003922129079498272\n",
            "train loss:0.005178193845513106\n",
            "train loss:0.003953121474715705\n",
            "train loss:0.00204461228875134\n",
            "train loss:0.002995289045526817\n",
            "train loss:0.0024218514180400735\n",
            "train loss:0.003008266980727338\n",
            "=== epoch:594, train acc:1.0, test acc:0.8859 ===\n",
            "train loss:0.003155140184160249\n",
            "train loss:0.014625102349587362\n",
            "train loss:0.0020657508679312207\n",
            "train loss:0.002296354519034796\n",
            "train loss:0.002962414673877647\n",
            "train loss:0.0017362109961956693\n",
            "train loss:0.002253151849654137\n",
            "train loss:0.0015123771671738363\n",
            "train loss:0.0031967466245643415\n",
            "train loss:0.0035295139181198434\n",
            "=== epoch:595, train acc:1.0, test acc:0.8857 ===\n",
            "train loss:0.0048366165622501294\n",
            "train loss:0.0027466257464422643\n",
            "train loss:0.0029599673356431842\n",
            "train loss:0.002694069838427325\n",
            "train loss:0.0023671290151863543\n",
            "train loss:0.0025350257262869787\n",
            "train loss:0.002765722414496374\n",
            "train loss:0.00370616349746828\n",
            "train loss:0.003144543045937873\n",
            "train loss:0.001913955295886279\n",
            "=== epoch:596, train acc:0.999, test acc:0.8859 ===\n",
            "train loss:0.0037246645665913853\n",
            "train loss:0.0034943238287363336\n",
            "train loss:0.0033529735054994465\n",
            "train loss:0.001922713088335746\n",
            "train loss:0.013640736294883908\n",
            "train loss:0.002485873605257104\n",
            "train loss:0.003193246098557892\n",
            "train loss:0.0026380119598965685\n",
            "train loss:0.0031792561357032127\n",
            "train loss:0.0028070986578118346\n",
            "=== epoch:597, train acc:0.999, test acc:0.8854 ===\n",
            "train loss:0.012870186284253595\n",
            "train loss:0.0032981765059770037\n",
            "train loss:0.011413789432015556\n",
            "train loss:0.0032356488018978613\n",
            "train loss:0.0017805251037904856\n",
            "train loss:0.003958280060046715\n",
            "train loss:0.0027546957620071507\n",
            "train loss:0.021742079906318393\n",
            "train loss:0.0041027699444824975\n",
            "train loss:0.003084932664154133\n",
            "=== epoch:598, train acc:1.0, test acc:0.8843 ===\n",
            "train loss:0.0031044405182946338\n",
            "train loss:0.0016914462942121463\n",
            "train loss:0.002878313147220059\n",
            "train loss:0.004362842358979797\n",
            "train loss:0.002509086293232662\n",
            "train loss:0.003917131605643917\n",
            "train loss:0.0035756124304259706\n",
            "train loss:0.0046558735116469805\n",
            "train loss:0.0031590708695049753\n",
            "train loss:0.0038368010376045795\n",
            "=== epoch:599, train acc:0.999, test acc:0.8843 ===\n",
            "train loss:0.0014213064821891695\n",
            "train loss:0.003994007657971997\n",
            "train loss:0.0032413593017078333\n",
            "train loss:0.0025266652227968873\n",
            "train loss:0.0015958717652665862\n",
            "train loss:0.0029527239093106133\n",
            "train loss:0.003360005345573536\n",
            "train loss:0.00229144244218841\n",
            "train loss:0.002362000013280175\n",
            "train loss:0.002882588570916587\n",
            "=== epoch:600, train acc:1.0, test acc:0.8838 ===\n",
            "train loss:0.002304315822979523\n",
            "train loss:0.010976733645266135\n",
            "train loss:0.010831398837322082\n",
            "train loss:0.010545865151033387\n",
            "train loss:0.0021601975854002513\n",
            "train loss:0.0027390422680327203\n",
            "train loss:0.0025769299108094313\n",
            "train loss:0.0030167933119707334\n",
            "train loss:0.003974722186739734\n",
            "train loss:0.011577862577133264\n",
            "=== epoch:601, train acc:1.0, test acc:0.8831 ===\n",
            "train loss:0.002414045901595475\n",
            "train loss:0.002612483444931461\n",
            "train loss:0.0035833388238035945\n",
            "train loss:0.005115943413546291\n",
            "train loss:0.010437677622857142\n",
            "train loss:0.011288406682734292\n",
            "train loss:0.01163466608949499\n",
            "train loss:0.0023586304704187756\n",
            "train loss:0.002916202263260042\n",
            "=============== Final Test Accuracy ===============\n",
            "test acc:0.8851\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "ハイパーパラメータ最適化の実装\n",
        "\"\"\"\n",
        "# coding: utf-8\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mnist import load_mnist\n",
        "from multi_layer_net import MultiLayerNet\n",
        "from util import shuffle_dataset\n",
        "from trainer import Trainer\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
        "\n",
        "# 高速化のため訓練データの削減\n",
        "x_train = x_train[:500]\n",
        "t_train = t_train[:500]\n",
        "\n",
        "# 検証データの分離\n",
        "validation_rate = 0.20\n",
        "validation_num = int(x_train.shape[0] * validation_rate)\n",
        "x_train, t_train = shuffle_dataset(x_train, t_train)\n",
        "x_val = x_train[:validation_num]\n",
        "t_val = t_train[:validation_num]\n",
        "x_train = x_train[validation_num:]\n",
        "t_train = t_train[validation_num:]\n",
        "\n",
        "\n",
        "def __train(lr, weight_decay, epocs=50):\n",
        "    network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
        "                            output_size=10, weight_decay_lambda=weight_decay) # weight_decay係数の初期値は0\n",
        "    trainer = Trainer(network, x_train, t_train, x_val, t_val,\n",
        "                      epochs=epocs, mini_batch_size=100,\n",
        "                      optimizer='sgd', optimizer_param={'lr': lr}, verbose=False) # 学習係数の初期値は0.01\n",
        "    trainer.train()\n",
        "\n",
        "    return trainer.test_acc_list, trainer.train_acc_list\n",
        "\n",
        "\n",
        "# ハイパーパラメータのランダム探索(初期値でパラメータ探索してから)======================================\n",
        "optimization_trial = 100 #100組み合わせ探索する\n",
        "results_val = {}\n",
        "results_train = {}\n",
        "for _ in range(optimization_trial):\n",
        "    # 探索したいハイパーパラメータの範囲を指定===============\n",
        "    weight_decay = 10 ** np.random.uniform(-8, -4)\n",
        "    lr = 10 ** np.random.uniform(-6, -2)\n",
        "    # ================================================\n",
        "\n",
        "    val_acc_list, train_acc_list = __train(lr, weight_decay)\n",
        "    print(\"val acc:\" + str(val_acc_list[-1]) + \" | lr:\" + str(lr) + \", weight decay:\" + str(weight_decay))\n",
        "    key = \"lr:\" + str(lr) + \", weight decay:\" + str(weight_decay)\n",
        "    results_val[key] = val_acc_list\n",
        "    results_train[key] = train_acc_list\n",
        "\n",
        "# グラフの描画========================================================\n",
        "print(\"=========== Hyper-Parameter Optimization Result ===========\")\n",
        "graph_draw_num = 20\n",
        "col_num = 5\n",
        "row_num = int(np.ceil(graph_draw_num / col_num))\n",
        "i = 0\n",
        "\n",
        "for key, val_acc_list in sorted(results_val.items(), key=lambda x:x[1][-1], reverse=True):\n",
        "    print(\"Best-\" + str(i+1) + \"(val acc:\" + str(val_acc_list[-1]) + \") | \" + key)\n",
        "\n",
        "    plt.subplot(row_num, col_num, i+1)\n",
        "    plt.title(\"Best-\" + str(i+1))\n",
        "    plt.ylim(0.0, 1.0)\n",
        "    if i % 5: plt.yticks([])\n",
        "    plt.xticks([])\n",
        "    x = np.arange(len(val_acc_list))\n",
        "    plt.plot(x, val_acc_list)\n",
        "    plt.plot(x, results_train[key], \"--\")\n",
        "    i += 1\n",
        "\n",
        "    if i >= graph_draw_num:\n",
        "        break\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "一回目\n",
        "Best-1(val acc:0.75) | lr:0.00734563505417722, weight decay:3.4982681023798305e-06\n",
        "Best-2(val acc:0.75) | lr:0.00917025995582448, weight decay:1.9330692185316456e-05\n",
        "Best-3(val acc:0.75) | lr:0.009696137955062318, weight decay:3.443040108251928e-08\n",
        "Best-4(val acc:0.75) | lr:0.009371095391258326, weight decay:2.7044651353312123e-06\n",
        "Best-5(val acc:0.73) | lr:0.007988144265542188, weight decay:3.0601071330310714e-06\n",
        "→lr:0.007~0.01ぐらいか、weight decay:10 ** np.random.uniform(-8, -6)ぐらいか\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "QuJ9N_cCpzsV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2057854-a896-4a8f-ee8d-74310b162ccc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val acc:0.68 | lr:0.006032773171371581, weight decay:5.9451103296846924e-05\n",
            "val acc:0.75 | lr:0.00734563505417722, weight decay:3.4982681023798305e-06\n",
            "val acc:0.33 | lr:0.002380892942187949, weight decay:2.3302649665211884e-07\n",
            "val acc:0.26 | lr:0.001546435795697157, weight decay:9.142745445185679e-05\n",
            "val acc:0.75 | lr:0.00917025995582448, weight decay:1.9330692185316456e-05\n",
            "val acc:0.12 | lr:0.00018726128088162005, weight decay:5.393340184912176e-07\n",
            "val acc:0.08 | lr:9.100633798559106e-06, weight decay:3.483978692325686e-08\n",
            "val acc:0.7 | lr:0.008014329090042861, weight decay:2.1137383249158372e-05\n",
            "val acc:0.18 | lr:0.0005100242133954801, weight decay:4.932845208576917e-07\n",
            "val acc:0.68 | lr:0.0060742355654829945, weight decay:3.2381611414337716e-06\n",
            "val acc:0.25 | lr:0.0012958385019852764, weight decay:4.285639259390181e-08\n",
            "val acc:0.03 | lr:0.0007073125688744968, weight decay:6.154142532890233e-08\n",
            "val acc:0.12 | lr:4.068871395482677e-06, weight decay:7.303457964669094e-08\n",
            "val acc:0.19 | lr:0.0006632014681023802, weight decay:6.285549205769319e-07\n",
            "val acc:0.15 | lr:2.031714832665987e-06, weight decay:7.730040956608624e-08\n",
            "val acc:0.32 | lr:0.0023887598902881833, weight decay:1.1646471692142182e-06\n",
            "val acc:0.14 | lr:3.993954519073011e-06, weight decay:6.405554236069988e-08\n",
            "val acc:0.5 | lr:0.003174158739189675, weight decay:5.486296286811447e-07\n",
            "val acc:0.11 | lr:3.782279651471375e-06, weight decay:5.724038939166333e-08\n",
            "val acc:0.11 | lr:2.722701840166938e-06, weight decay:2.7682700249636126e-07\n",
            "val acc:0.13 | lr:5.9482398959996364e-05, weight decay:1.3704823643472928e-08\n",
            "val acc:0.07 | lr:4.454431988971566e-06, weight decay:8.525483195419311e-05\n",
            "val acc:0.31 | lr:0.0012425108546575787, weight decay:3.526465697162149e-07\n",
            "val acc:0.09 | lr:1.2865519445576078e-06, weight decay:3.48965169799584e-08\n",
            "val acc:0.12 | lr:8.6136576739235e-06, weight decay:1.74704882140476e-05\n",
            "val acc:0.08 | lr:1.3641519727311392e-06, weight decay:1.2977990312054716e-06\n",
            "val acc:0.09 | lr:0.00018233286532091844, weight decay:2.8361506713331655e-06\n",
            "val acc:0.1 | lr:2.178418845452447e-05, weight decay:2.3674058153954197e-05\n",
            "val acc:0.12 | lr:1.4805812307445036e-06, weight decay:1.1451895766048086e-06\n",
            "val acc:0.27 | lr:0.0020055848689936053, weight decay:1.952710700217722e-08\n",
            "val acc:0.08 | lr:1.2595559307553641e-05, weight decay:2.9890855463883174e-07\n",
            "val acc:0.09 | lr:0.0006506238072358367, weight decay:6.505600640406694e-08\n",
            "val acc:0.12 | lr:0.00010992816927155238, weight decay:6.831077456180403e-06\n",
            "val acc:0.69 | lr:0.004594243821175519, weight decay:5.660601718929727e-06\n",
            "val acc:0.12 | lr:1.0910292852641526e-06, weight decay:8.659516688942651e-06\n",
            "val acc:0.09 | lr:3.6281785559801265e-06, weight decay:1.8856551660666077e-06\n",
            "val acc:0.09 | lr:7.389794688371255e-05, weight decay:3.5408802920379754e-06\n",
            "val acc:0.71 | lr:0.00698361617063246, weight decay:2.3756705321438063e-05\n",
            "val acc:0.45 | lr:0.002521478179170882, weight decay:4.927499505401584e-07\n",
            "val acc:0.07 | lr:3.613867510486649e-06, weight decay:4.928930634443836e-07\n",
            "val acc:0.07 | lr:3.024615588164035e-05, weight decay:1.443865758682015e-06\n",
            "val acc:0.7 | lr:0.007143141326879673, weight decay:7.274265019197833e-06\n",
            "val acc:0.12 | lr:6.976388932537596e-05, weight decay:4.0172366264791884e-08\n",
            "val acc:0.13 | lr:0.0003515993569845091, weight decay:1.423319281850864e-05\n",
            "val acc:0.12 | lr:0.0012286927956970917, weight decay:1.007924215016431e-05\n",
            "val acc:0.11 | lr:0.0003576350143191711, weight decay:9.510815267714342e-08\n",
            "val acc:0.11 | lr:6.768547941996084e-05, weight decay:7.280981282640681e-06\n",
            "val acc:0.51 | lr:0.0037299275071116514, weight decay:2.731948683454416e-07\n",
            "val acc:0.09 | lr:0.00020054968181992873, weight decay:1.108479371822266e-05\n",
            "val acc:0.13 | lr:4.81237926342038e-06, weight decay:1.6289042944114735e-07\n",
            "val acc:0.1 | lr:0.0003435461497416033, weight decay:1.0772153465841927e-05\n",
            "val acc:0.17 | lr:1.1535138595996034e-06, weight decay:2.531833455807254e-06\n",
            "val acc:0.75 | lr:0.009696137955062318, weight decay:3.443040108251928e-08\n",
            "val acc:0.55 | lr:0.0036035754095624026, weight decay:3.367318369794955e-07\n",
            "val acc:0.06 | lr:4.334387277816841e-05, weight decay:2.167249268594019e-06\n",
            "val acc:0.01 | lr:3.409348985449561e-05, weight decay:9.826227812546796e-05\n",
            "val acc:0.36 | lr:0.0017054376326099642, weight decay:8.454527753934344e-08\n",
            "val acc:0.12 | lr:3.763405844062246e-05, weight decay:1.7386235934844056e-07\n",
            "val acc:0.11 | lr:2.775960020684087e-06, weight decay:2.2554480332300083e-05\n",
            "val acc:0.13 | lr:1.3369267831824007e-05, weight decay:4.865115473695228e-07\n",
            "val acc:0.05 | lr:1.9088062641664365e-05, weight decay:5.596598552240726e-08\n",
            "val acc:0.05 | lr:1.774171756772057e-05, weight decay:5.618632265067395e-07\n",
            "val acc:0.1 | lr:0.0008215806136282698, weight decay:1.3902578754165933e-06\n",
            "val acc:0.07 | lr:1.1941801908333873e-06, weight decay:2.7522101128751853e-06\n",
            "val acc:0.07 | lr:4.065891763542939e-06, weight decay:1.1417544549098189e-08\n",
            "val acc:0.08 | lr:0.0005855657069959506, weight decay:1.5022656715747036e-07\n",
            "val acc:0.16 | lr:0.0004822535358910119, weight decay:9.924521278287774e-06\n",
            "val acc:0.12 | lr:0.00021884156260392642, weight decay:5.915695513345687e-08\n",
            "val acc:0.11 | lr:5.636959486198425e-05, weight decay:2.9049552006731636e-06\n",
            "val acc:0.09 | lr:0.00015530071919179486, weight decay:2.1557902108465108e-05\n",
            "val acc:0.11 | lr:2.6544504921944438e-06, weight decay:4.9651938214866775e-05\n",
            "val acc:0.06 | lr:1.8521481932431044e-06, weight decay:2.8870303209663855e-05\n",
            "val acc:0.27 | lr:0.001576239874036799, weight decay:2.976720483081806e-06\n",
            "val acc:0.1 | lr:0.000481053350373193, weight decay:8.700826244631566e-06\n",
            "val acc:0.52 | lr:0.00528240453999515, weight decay:1.1941766203785043e-08\n",
            "val acc:0.11 | lr:8.130922133999203e-06, weight decay:4.869962485460433e-07\n",
            "val acc:0.03 | lr:2.973665459744421e-05, weight decay:3.357611481118962e-07\n",
            "val acc:0.09 | lr:2.7187798836928266e-05, weight decay:4.1319344729186896e-05\n",
            "val acc:0.15 | lr:0.00028555841310358795, weight decay:1.7457034190015547e-07\n",
            "val acc:0.1 | lr:0.0007638703462328659, weight decay:2.1189135761387286e-06\n",
            "val acc:0.18 | lr:0.00026967098674570425, weight decay:5.2133177959659776e-08\n",
            "val acc:0.11 | lr:5.410763883171604e-06, weight decay:7.909219408024689e-05\n",
            "val acc:0.11 | lr:8.570489516427052e-06, weight decay:7.868802581001126e-08\n",
            "val acc:0.06 | lr:1.7733756347180152e-06, weight decay:5.6655759966213025e-08\n",
            "val acc:0.29 | lr:0.0019452431697412527, weight decay:3.09493063844228e-08\n",
            "val acc:0.1 | lr:1.5597124310521772e-06, weight decay:1.0253018861069769e-06\n",
            "val acc:0.62 | lr:0.005631476027973298, weight decay:2.3859043764972626e-06\n",
            "val acc:0.75 | lr:0.009371095391258326, weight decay:2.7044651353312123e-06\n",
            "val acc:0.13 | lr:0.000527591308477126, weight decay:7.850620462693391e-06\n",
            "val acc:0.11 | lr:9.251928208470821e-05, weight decay:2.1394915299938644e-05\n",
            "val acc:0.26 | lr:0.0016573898777493806, weight decay:2.3101093348830877e-05\n",
            "val acc:0.07 | lr:0.0002738600263609795, weight decay:1.7013982142809328e-08\n",
            "val acc:0.11 | lr:0.0002574830949778686, weight decay:2.7760936132874457e-07\n",
            "val acc:0.73 | lr:0.007988144265542188, weight decay:3.0601071330310714e-06\n",
            "val acc:0.6 | lr:0.0049070801318782465, weight decay:4.465519688915418e-05\n",
            "val acc:0.15 | lr:0.00037846238566399725, weight decay:8.278743453548049e-07\n",
            "val acc:0.12 | lr:4.05337842829637e-06, weight decay:3.156958405663634e-05\n",
            "val acc:0.14 | lr:0.0008299960941572518, weight decay:1.2456045408500277e-08\n",
            "val acc:0.59 | lr:0.004961772163928295, weight decay:3.2026855334612534e-08\n",
            "val acc:0.15 | lr:0.00039433803167959026, weight decay:1.9468999722666637e-08\n",
            "=========== Hyper-Parameter Optimization Result ===========\n",
            "Best-1(val acc:0.75) | lr:0.00734563505417722, weight decay:3.4982681023798305e-06\n",
            "Best-2(val acc:0.75) | lr:0.00917025995582448, weight decay:1.9330692185316456e-05\n",
            "Best-3(val acc:0.75) | lr:0.009696137955062318, weight decay:3.443040108251928e-08\n",
            "Best-4(val acc:0.75) | lr:0.009371095391258326, weight decay:2.7044651353312123e-06\n",
            "Best-5(val acc:0.73) | lr:0.007988144265542188, weight decay:3.0601071330310714e-06\n",
            "Best-6(val acc:0.71) | lr:0.00698361617063246, weight decay:2.3756705321438063e-05\n",
            "Best-7(val acc:0.7) | lr:0.008014329090042861, weight decay:2.1137383249158372e-05\n",
            "Best-8(val acc:0.7) | lr:0.007143141326879673, weight decay:7.274265019197833e-06\n",
            "Best-9(val acc:0.69) | lr:0.004594243821175519, weight decay:5.660601718929727e-06\n",
            "Best-10(val acc:0.68) | lr:0.006032773171371581, weight decay:5.9451103296846924e-05\n",
            "Best-11(val acc:0.68) | lr:0.0060742355654829945, weight decay:3.2381611414337716e-06\n",
            "Best-12(val acc:0.62) | lr:0.005631476027973298, weight decay:2.3859043764972626e-06\n",
            "Best-13(val acc:0.6) | lr:0.0049070801318782465, weight decay:4.465519688915418e-05\n",
            "Best-14(val acc:0.59) | lr:0.004961772163928295, weight decay:3.2026855334612534e-08\n",
            "Best-15(val acc:0.55) | lr:0.0036035754095624026, weight decay:3.367318369794955e-07\n",
            "Best-16(val acc:0.52) | lr:0.00528240453999515, weight decay:1.1941766203785043e-08\n",
            "Best-17(val acc:0.51) | lr:0.0037299275071116514, weight decay:2.731948683454416e-07\n",
            "Best-18(val acc:0.5) | lr:0.003174158739189675, weight decay:5.486296286811447e-07\n",
            "Best-19(val acc:0.45) | lr:0.002521478179170882, weight decay:4.927499505401584e-07\n",
            "Best-20(val acc:0.36) | lr:0.0017054376326099642, weight decay:8.454527753934344e-08\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 20 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD9CAYAAACsq4z3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOyddXgVR9uH74m7ESGEhAQIBHcpToEWivUtXijSUqjwUm9pP2q8VeputIWWYqWGluJa3DUkBOLucpIj8/0xBwiQkBNIciLnvq5z5ezunN3ZJ7u/nX3mmWeElBILFixYsFDzsTJ3BSxYsGDBQsVgEXQLFixYqCVYBN2CBQsWagkWQbdgwYKFWoJF0C1YsGChlmARdAsWLFioJVgE3YIFCxZqCTVC0IUQF4UQBUKIXCFEhhBirRAisAL2ObCMMmOFEHuEEPlCiG23c7yKxow2eV8IcV4IkSOEOCuEmHw7x6xIzGiT+UKIGCFEthDikhDipds5ZkVjLrsUK+slhEgRQuy6nWNWJGa8VhYKIYqMx738sb6d4xanRgi6keFSShfAH0gCPquCY6YDHwPvVMGxbgVz2CQPGA64A1OAT4QQParguKZiDpt8D4RJKd2AHsBEIcR9VXDc8mAOu1zmXeBMFR7PVMxlk/lSSpdiH31F7bgmCToAUkoNsBJoCSCEsDe2GqOFEElCiK+FEI7Gbd5CiDVCiEwhRLoQYqcQwkoI8TMQBKw2PiGfL+VYm6SUK4D4Kjq9W6KKbfKqlPKslNIgpdwH7ATuqJozNZ0qtsk5KWVesVUGoGnlnuGtUZV2Me6jB9Aa+LHyz+7WqGqbVCY1TtCFEE7AOGCvcdU7QDOgPeomCgBeMW57BogFfAA/4CVASikfAKIxPqGllPOr7gwqHnPZxHiRdwFOVdzZVAxVbRMhxBwhRK5xP87Akgo/qQqgKu1idCV8DswCqm2OETPcP48ZHwaHhBCjKvRkpJTV/gNcBHKBTECLajG3AQTKBdCkWNk7gCjj93nAX0DTUvY50MTjTwe2mdsO1ckmxvKLgL8BYW57VAebGI/TAXgdcDW3PcxtF+Ap4Cvj96nALnPbohrYpCNQD7AB7gFygJ4Vdl7mNmw5jD/Q+N0auA/l3w5CPfkzi32ygFxjWVfgA+CC8TOnNOMDXxv/wbnAS9cdv7oKujlt8h5wCHAzty2qi02KlZkDfGhue5jTLkADIArwMm6fSvUT9OpwrXwNfFBh52Vuw5bX+MXWpQBjgXwgwIR9tAaSgQHG5ajr93mT31ZrQa9qm6BaoCeBeua2Q3WxyXX7mAv8ZW57mNMuwL2ABkg0frKAIuN367pok1L28RUV+PCviT50IYQYCXiifLffAR8JIXyN2wOEEHcbvw8TQjQVQgjUBaVHdViB6tVuXMaxrIUQDqjXIyshhIMQwrZSTuw2qGKbvAjcj7pw0yrlhCqAqrKJsUNsphDC03jMrsDjwOZKO7nboAqvlfVAMMoP3R7lgz4CtJcVGNVREVTx/TNaCOFivG7uAiYBqyrsZMz9pCzH07QA9eqSg2odTjRucwDeQr3+ZKPCo2Ybtz1l/G0eqiPj5WL7HInqxMgEni3luFNRr1/FPwvNbQ8z20QChVx9lSz1dbIu2AQVWPA36nU9FwhHuRyqRb+COa+V6+owlerncjHH/bMT9SDIBo4B4yvyvITxIBYsWLBgoYZT41wuFixYsGChZMoUdCHED0KIZCHEyVK2CyHEp0KICCHEcSFEx4qvpgULFixYKAtTWugLgcE32T4ECDV+ZqB6bS1YsGDBQhVTpqBLKXegOnxKYyTwk1TsBTyEEP4VVUELFixYsGAaNhWwjwAgpthyrHFdwvUFhRAzUK14nJ2dO4WFhVXA4as3hw4dSpVS+phS1tvbWwYHB1dyjcxPeWwCdcMuFpuUjOX+uZGb2aQiBN1kpJTfAt8CdO7cWR48eLAqD28WhBCXTC0bHByMxSY3UhfsYrFJyVjunxu5mU0qIsolDiieR7ihcZ0FCxZKQ6sxdw0s1EIqooW+CpglhFgGdAOypJQ3uFssWKizZMZA6jnIzwArazizGtLOwyPVZr4HC7WEMgVdCLEU6Ad4CyFigVcBWwAp5dfAOlTWsAhUDoRplVXZakvUTji8CPzbQY//mrs25idyC5xdC0X5YO8C97xn7hpVLQY9JJ0Cv9ZgZQX/fgH7igV/ObhD98fNV7/qSuIJsHEE72qZSr5GUKagSyknlLFdonJX1C1WTIa8NLCxh8jN4OgFfq3MXSvzICUIoUTs5O+w51OQBrC2gz7Pmrt2VYdeB2dWwdY3IS0Cej0FA1+Dzg9CyxHqGtHmgV8bsLEzd23Ni8EAx5dBYDd13ez9EqL/hQGvQO9nzF0786HJgvMbwSsE6reF9S9Ah4kQ0Mmkn1dpp2iNRUp1gxr04NVY3YydH4S/X1TC1ftZ6PMc2DqYu6ZVg1YD+Wmw/nlIPK7OveNkEFaw831o0AEm/Q72rmBd7XKZVQwGPcQfgYad1fK/X8DeryErGrybw8gvoekAtc2nGWq+hDqOrhBi9im7dZwM0Xvhz0fVNvcguOtNaDPavHU0B/npyhXn4A473oM9n4GwhnpNlauu+T0m78oi6DcjMxrCN8DJ31TrASBsGIxZBI37wWP/mrN2VcOlPXB0CYz4TLXCfxkL5zeobXYu0GwwuPipZd8WMDdZtcyFMF+dK4uUcDi2FGyd4NgSKMqDZ8PVtqgd4BEIQ95RNrGqsHl/az6Hf4Z/5kJRLhh0qlF0xyzo9yK4NVDXTfOhYF2H5Ch8g3qTy7ikrqP298OIT6HvHAi9WzUQsmJh9I8QatJc3IBF0G/O/m/V09KtIdz9Fjj7qJZ6QQa4mBwyXHOJ3AJL7wePoKsCHdhFtcClAdqMMbY+i2FjX/X1rCx0hVCYA87eSrAXjwZ9odrWsItyD1xm7E+169xvF4NePdTSImHtM1C/DTTuCw06qr9W1uDmD/3mmLumVUNBBjh6qu+rZqs+N+/m6h6ydYC249Q2excI6a0+t4BF0IuTnQD7v4HgXtB0IHR7FDpNUy2K2tjiLI3seDixEja/Dj5hMPmvq9v6PGe+elUlmixYPEq9bUxbp3yYHSZC3xeUa8nF99ryFjFXxB+FnR8oIX90N3gGw51zod34G21WF9Bq4O8X4MhiePqMskGjHuDZSL2lVPB1YxH0tEjV8ZByDrJiAKn8w00HgnuAuWtnHlbNhoiNynVw37fKt1eXMBhUp3f8ERj+iVpn5wzDPrqt3UopEbWxYWAwKLdkQQZsfEWJVPuJoC9S33vONncNqxa9DlbNUvbIuAQpZ6DbI6ohAOrhVklY0uf+Mxdi9kOjO6D/S/Dfw8pffIvsiUjl7fVnqDF55vNS4cgv6kZMj1Lr7ngMpq2H+5fftphrtHoSsgp4avlRcgt1FVDhKmD3R3BhG9zzPnSYVCG7XHUsnu5vbyYiOReAmPR83lhzmkOXMipk/1WOlKpTsyADinJg48uw/jnlRpl1EAa/dUutzx92RbFsf3TNuX+Kc36jEvDLHZzhf6s3vYm/wZB3leuukqmbLXS9DrT54OCmblohVOdMOcjML8LF3gYbaysKivTEZeaz5Wwy7204R4i3M7P6N8XVoRpHeBTmwG8Pw/l/4PKMYIW5MOxDaHJnhRzig3/O8dW2SFwdbNDqJVN6BNM+0KNC9l1p7PkMNs+DliOh01STfpKWW0hGvpbgek78czqJTWeSAGjX0IMHujfi71OJvLDyOAVaPR/8cw4rK8H6EwkIIfD3cKRTI89KPKFKYvPrsOsjePyA6kd5ZBekhqvIjHL2L2UVaEnJKcTO2or5G84yoIUf47sGVVLFK4mY/fDLaBUw4dlICfjdbyttKeOtTErJNzsu4OVkR0KWhg5BHvRppmx46FIGS/dHY5CSD8e2L7MadUvQtRr11Dy0UL0OTll9S26VDacSmb30CPWc7RjbJZBl+2NIzFZDufs28+HTCR2qt5iDCrk8vwF6PgGt/gNeTVSHjImk5hbi6WTHx5vCcXe0pUOQJ9vPJaOXkjvDfDl4MYPPtkTQzijgb/+nDS0buFXW2VQcrUep66T309fciBHJOSzbH8NTg5qRW6jjq22RzOjTmE82nWfl4Vj0BkmorwsXUvPwcLTFxlrw++E4lu6P5mxiDo29nQnzd2XdiUTsbayY0acJU3o0wt/d0YwnW04iNqtxBppMOLtGRXzVMw4CcvYuVws0Oi2fAE9HLqblce8Xu8nR6LC2ElhbCeYMrmFJ+3SF8PcccPaFJv2vrrcyzQGyPyqdd9afvbJcz9mOPx/vSUx6Po/+chiDlLg7mqYndUfQU8Jh0TDITVJhZ3e9YXJomZSSMwk5NK/vyvnkHB775TCtG7jhaGfNx5vOU9/NgffHtKO5nyttGlYzf7OUqjWuyYLdn0DoIGh2txLywG7Q8YFy7zIyJZchH+/E38OBS2n5V9ZbCRBC8MXWSAB6h3rz3eTOONjWgBC+I7+oiAO3BtD32o7fHI2Wh386RFRqHueScohMziU+S8PuiFTOJ+cyoWsQzf1cePfvcwR5ObFqVk+c7GyYtGAf+6LSeHV4SybfEUxitoZCrYHH+jetOa3yjEvg6q/GXlzYCqf/VKGH/V5Sg8ZMFK3LGAyS+RvO8fX2SAK9HNHqJLbWVswf1ZYtZ5O5o0k9Ar2cKulkKoGcRPhtOsQdglHfm+yivJCSyzvrz1Kg1ZOaW4SXsx1fTuxIVoGWRxYfovf8rQC42tuw+r+9CPZ2Nmm/dUfQt8wDbQE88AcE9y7XgJfPt0TwwcZwAr0ccbazwcXehkUPdsXDyY7zSTl4OdtRz6UaRjlkxsAfM+HSbrC2Vy1OZx8l6N6h6lMOotPyeWPtaQq0eiSSmPR8hrb15793NiUhU0OonwtWQnAuMQc/N4ea0SIH5Qv+6zEwaG9ws0gpmfP7CaLT8xnW1p81xxNo5udCXz8ftoenEODhyP9GtsLG2opBrerjaGt95e3sh6ldiM8qoImPevMJ8HDk+6ldqvrsbg29DpJPw9LxKjyz3XjoP1d9rO3KLeT7LqTx1fZIbKwEm84kM7xdA3I0Wgq1Bp4cGEq3xvUY2yWw7B1VB/Taq/qxYjIkHIP/fGPSoKhCnZ5f9kbz2ZbzGCT4utpzPjmXpwc1o3vjegA8d3dz4jML6NfMlxYN3AjwMP0trnYLeuwh1WET3AecvKHH7DL9w3GZBXyyKZyDlzII8HDk7lb1+WhTOH2a+VBQpOPAxQzmjWyFh5Mauh3q51oVZ3JrnFihIjW6PQq6Auj1tPLvlYMtZ5P4ZW80b93Xhkd/OcSp+GwAJnQNYtadTfFztcfG2oqw+lfFu0E5LkCzI6Ua4OHso1roxYjNyOfDjeGsPZ7AC4PDeKRvY54c2IwmPs5cSM1j8Mc7eLh3CDbWStyuv/Ec7ayviHmNIum0Eqq082DvdjWlhYkjoaNS8wAIMbYqE7M0PL7kMJn5WnQGyXN3N+exfk1qZsTP9vfUaOgJy5R75Z731Rv/TfLPrDgQw7c7L+DhaIteSo5EZ9Il2JP3x7QjyMuJi2n5BBV7K3ms363nsqm9gh6+AVY+pAYxNO4Hwz826Wezlx7hVHwWfUJ92BOZxs7zqXQM8uCriR1xtrchKVuDr2s1bI2XROeHlEh5lL+D6XhsJgcuZvDRxnByC3X0f38b+UV65o9qS2RqLg/2DMHPrYanOijMUaMYo3bA4HfAzpmTcVk429uQo9Ey7ccD5BbqeKhXCDP7NEYIQVNfJdBNfFzYM2cA3i61LCfLhW1qNLCjhwrZDOmr8oqYSF6hjnHf/Eu2Rkv3xvXI0ehIySkkv0jPuid64+ZgS333GnjdJJ5QLssTv6r76fSfStDrt7lpp+ehS+m8+McJwuq7klWg5VJaPp+Mb8/I9lf77kJMdKeYQu0T9Oi9sOl1iN6jRmKZkOlv69lkfFztKdTpOXQpg9eGt2RqzxDOJmbzz6kkZvRpfMUPXO1FTFcIW99Sozlb3atuTBPZcjaJTzZHEJ6YQ4FWRb74udkzrWcwP+yK4rMJHRjernzRQNWac3/DhhehyQDoOpPU3ELGf7sXexsrrKwEjnbWrHjkjlJb2T415cFeHtwDlUtu6AdlDgTS6g2sOBhDRl7RlXUn47JJzimkmZ8LJ2Kz8HCyJb9Ixy/Tu9GsOr/N3oy8VPj5PyqQosMkGPqh+g6livmBi+lICS/9cQJ/dweWzuiOq70NuYW6Sg2YqF2CnnoefroXnOrB4Heh87QSY2GllCzeF00jLyd2R6TyzY4L2NlY4etqj7ujLWM6K19eWH23a1wJ1R5tASwaAbH7lXul1b0m/ez3w7Hsu5DO8oMxNPZ25v5uQTSq58TgVvXxcLLDzsaKJwaEXnEt1HgMBuUDDugI934NYUPJLtLz+urTaLR69AaJRLL48V4102VSXo6vgNN/wb1fQr0mMO7nmxbPLdSxaM9FdoSnsC/qxumGp9zRiFeHt0KiOsp1BtXxWWNxqqcyQDa5E3yaq3Ul6MrKQ7F0buRJgVbPpAX7KNQZAPjmgU64GUW8sqPfaoegJ55QnX71mqqe945TboiFzdFo+WHXRab3DmHz2WRe/vPklW1jOjUkLrOAvEId79zXFmf7GmqWtc8qMR/1vclZ6+IzC3jm12PYWAnu6xDAW/e1KTEqpdaIeVokrJymkiCF3QP1mqDR6hnywXbiMguY1b8pA1r4YpCS5vVraIvSVKRUA+v+/RwadlWRUGVEaUgpeX7lMdadSMTd0ZZ37mvDqE4NrylzvXjbWtdAXzmovoS0CJX6uPujNy16IjaLZ389Rq+m3iRla3B3tKV9oAe2Nlbc1dKviipsoqALIQYDnwDWwAIp5TvXbZ8KvMfVqec+l1IuqMB6ls7Wt2H7O6pFOvDVUvNvrzwUy0ebwknJ1bD1bAot/d2YdWdTQrydaeFfg1rhpXFpDxxdrOxQjhSkfxyJQ0rY/HQ/gurVoHCxW+Hkb6pfxcYeHD3JKtDi7mjL74fjiMss4JsHOnF3q/rmrmXVceJXJeZdpsOQ+TcN4z0dn82CXReISM7leGwWc4aE8UjfJlVY2SomNQJ+HKxiy1sML3Nw0Hc7LwCwKyJVLU/uzKAqFPLLmDJjkTXwBTAIiAUOCCFWSSlPX1d0uZRyViXUsXQSjikxDxum8pOXgMEgSczWsP5kIgCL90ZjZ2PFJ+Pb0znYqyprW7nEHlA5pU1MnlWo0/P2urOsOhZPtxCv2i/muckq619AJ+S4xXx1OI/5X/3DR+PasWDXBdoEuFdpS8rsaLJg02tqlq0h75UYhpiWW8iSfdGk5RWx4VQiORodId7OvPmf1kzoUsNGcpaH8xtVPiMrG5j0W5liHpuRz9oTCYzu1JB1JxLoEOTBwBbmSURmSgu9KxAhpbwAYJw7dCRwvaBXPXs+Vzm5R35RauffR5vC+WxLBELAhK6BpOcV8VCvxrVLzEENFOoyHexME+af9lxi4Z6LtA5Qbyq1ni3/U6kN7v2StRcl8/8+h521FS/+fgKN1sBXEzvWzDC6W8XaToUkDn73BjE/l5jDD7ui+ONoHEU6A3Y2ViDh98d60Dqgmg2cq2j+eFTluvduDqOWmRTm++Puiwjg6UHNmNGnMT4u9ma7lkwR9AAgpthyLGoy6OsZJYToA4QDT0kpY64vIISYAcwACAq6zSd8+gU49Tt0nVGqmMek5/PNjgt4OtmSo9ExrWdIze1pL43t89UEAS2Gq4yAJaDR6q/EvuoMkt8Px/Hp5vP0a+7Dwmldq7jCZsKvNfR+Bo1HU97+fjst/N2Y1jOY51cep0uwJ4Nb1wFXi64Qdn+qkq/ZOcPM7dd07uVotDz76zE2nErCwdaKMZ0aMq1nCN4udmQVaGlUr+LC66ot9i5q5qSuD5eZXOxkXBbz1pzmaEwmw9r6V4vxFxXV+7caWCqlLBRCzAQWATeM4JFSfgt8C9C5c+fbS6fm6AU9n1SGL4Gzidk8tvgw1kKwZnZvbK0Fvq7VPOSwvCSehG1vq5Z5i+GlFnt99WmW7o/Gy9kOrc5ATqGO1gFuvD6iDsyBenm+024zAVi2O4q4zALmj25Ll2AvTsdnM7FbUO1vncfsV0PUMy+puPI2o68IlpSSVcfi+WTzeaLT8nl6UDMe6N4IT+erMfaXB9LVSgwGOPi9inoqI8w5r1DH7ohUhBA8uewILg42DAjz5YmB1WOKQVMEPQ4oPia3IVc7PwGQUqYVW1wAzL/9qt0Eg0G1yge8fMOm9zacZcm+aDLyVYfXTw91LdfQ2RqDlLDhJXDwUGl/r+NMQjaX0vJxc7Bh+YFoBrbww8PJFltrwcj2AXQL8ar9IpadAL9OVQ/9NqPRGyTf746iY5AHPZuqRFKv1YWHWmEOrHxQPdge+POaBFJZBVrm/32WX/ZF08zPhUUPdr1imzpB7EFYOBR0Gujx3zInY563+jTLDyrnQwt/NxZO61KtxqaYIugHgFAhRAhKyMcD9xcvIITwl1ImGBdHAGcqtJbFubAN1s+BUd+pUVrFKNIZ+OnfSwR5OTGzbxPGdg7Ey7mWtiyOL4eo7TDkPfT2Hugv+zqBreeSeXTxITRaFQfr62rP+2Pa1u5WVnEuP+z2faN8xbZOSClZczyemPQC/u+eFuauYdWy5Q01P+WDGyDoqrd085kknlim8tTP6NOYOYPDsLKq5Q/54ugK4a9Z6m2/zWjo/lipRaWUbA9PYcWhGIa29SfU14WHeoVUu6yqZQq6lFInhJgFbECFLf4gpTwlhJgHHJRSrgJmCyFGADogHZhaKbWNOaBGbNULvTo/XzF2R6aSo9Hx9KBmDGhRiyMW8lJh3XMQ1IO8tlMY+O4WErI0TO8VwoRuQcz65TBNfFx4tF8Tsgq0DGvbwOT0m7WCIz/D3i+h3QTo/QzfnLLipz+3YpCSFv5uDGpZB/zll9EVwoXtKgqsmJj/su8SL/95klYN3HlnVBtaNajlnZ0lsfEVNZvQ/SvU6NibMG/NaX7cfZEAD0fe+k+bans/meRDl1KuA9Zdt+6VYt9fBF6s2KqVwN4vwd4Vpm8CBzeKdAa+23mB7o3r0djbmcX/XsLF3oZeobX8ldHZWyXQb9STFYfjScjS0KeZDwt2RbH8YAz2ttYsmNK5ZuXarihyktTDLqQvjPyC+OwiPtq0jUKdASnhgzHtsK5LrVAbe5i54+pQdWDT6ST+74+T9G/uw+f3d6y5A+lul46TVV4Wo5hnFWjJzL9qJ4OEbeeSORydyepj8UzsFsTcoS1xtKu+6aBrzn8yJwnOrFZRLUYxf2jRAXaeT8XO2gorK9BoDczq3xR7m+pr8NvCYFAZ8HyaQ/v7ydZoWbBzJ12CPfl+SmdmLz2C3iB5cmCzuinmAK5+MO4Xsuq1Jyouh9dXn0JKWPV4L7IKtPSoS/7hwlw1WMjWUeUzN/LltgiCvJz4dnLnmj0k/1Yx6JVd/FohfVuSkFlAel4RY7/5l/wi/Q3FfVztuadNfV4b0ara26vmCHrkZpWvuvODSCl5a90Zdp5P5eVhLdkflYankx3TeobU7uHae7+ALW/CY/+S6xzI2K//JSlbw3uj22JrbcVXk27eoVOridoJhTlEePXm+xN+/H74AIXGfoVPx7evfhOPVAUHvlPTxM0+Ck5eKknW3mgOR2cyb2T1F6dKIS8VlowD72bE9n2Px5Yc5XhsFtZWAh8Xe/43svU144ia+bnWqNj7miPo7e+HRj1Js63P5M92cSo+m6k9gnmoVwgP9TI9vWeNJTtepTlorNKZfvH3Wc4m5rBwWpe61eq8jvjMAr77bR0vxj1OgnUD7sp5HRsbG+7rEEC/5r40r+9aoelJawwGPRxaBL4twcmLdScSePH3E2QVaOka4sXo6/Kv1AkyLqo+uOx4tHc8weNLjhKVmsdTA5txPDaTWXc2pUNQDZlJqhRqhqDrCpUv0LMRC/85x+mEbN4d1YbRnWrIDCcVwcEfQKehaNDb/LTzAt/viroiWnURnd7A0v3RfL/5BN9pXyELW2aKOTw5KIyJ3YKq5wxSVcn5jZARRVr3F9i4P5rXVp+iuZ8rrwxvSccgz9ofsloSa5+BvDSYspo3jzhzLPYiX0/qVKsGlVV/QTcYYMEAaDaE/F4v8PPeS9zV0o9xtTmXREmcW48+sDvT/kpmd0QaXUO8mDOkhk2mW0FotHpmLTnMljOJLHH7nKZWCWSOWsZfYQNqb/9JechNga1vUuRUn4Hr3cjQnMDPzZ7vJnfGtxrFTFcp8UchYhMMeIXtBSEs3LOfB3uG1Coxh5og6Ed/Uelxez7J6mPxZOZrmd67sblrVbXkJCGTT/OH1wz2JqTzwZh2N6QsrUu88tdJNp9NZmG3BLof2wuD38Wz9V3mrlb1IWIjhtRwntPNwsvVmUXT29PU1wUnu+p/u1cajp4qP0uX6SxaFo6fm32tbBBV7/9wSjisfwGCekCr+1j57V4a+zjTuabMmF5BxGhdebfBcnZEZvD8kOZ1WszXnUhgxcFYZvVvSt+77oF2zdQUgxbUxM7WNiQ1vo//OrpyJseOddO6EuhVyzNpmoJnI5i5g+QCFYo4s2+TKwPxahPV94xykmDJGBVyNfp7wlPyOHAxgzGdAuuW/y8rjnmrjrM1xsDMuzvxcF17OymGRqvn3TXHWeb6MU81iVdD2Rv3M3e1qgd5afBVD3LDtzP2m385lWXL15M6WcT8wPfw1+Og1XA8ScODiw5gkNTaTuHq20LPTYT8DHjgD6KK3Jm44F/cHW0Z1Smg7N/WFjRZFH0/hMEZQbTq+yGP968DaW5vwspDsQzK/YvutvtBm2vu6lQfpIQ1TyDTL/Dp9jjiMjxYNqN77UsRXV4yLsLGVzEEdOR0koaHFh3EWgjeH9Ou1k4tWL1a6HodnPxdXaD+7eC/h6BhJxbujiK7QMvKR+6ofRkTb0Lh2jlYZ8ewUg7kge5l52Wu7ew7F83jtquhcf+bZpesU+h18OejcGY1kW2e4ttId565q7lFzLPiYPkDSCF4WjOdYZ/vJrtAy8IHu9Ta1jlUtxb6jvXmJYkAACAASURBVPmw/V1w8lKv0i4+GAySv08l0q+5D6G1LZf5TYiPPInfiWX8ZBjMlPHj63wYnsEgaR31I55kQ7/KzzJRY/hnLhxbSkHPOcw42p0Qb1E3xmXcjPObkL9PR1tYyIL6L/PnBWse7h3C2M6BtV5DzC7oqw9FMjBhAY6pJ+DiTmg7/hq/6JGYTJKyCxnS2t9sdaxqZMYlCpZMpggbOkx4jfYtaldo1a1w4ewRHpJ/cClwBI2CSppfpe5xMjaD2GNRFDqM5I39Xcgq0PDj1C61srOvPEi3BiQ5NGFC5gSiLvgTVt+VFwaH1Z6Jzm+CWQU9LrOApD/mYm+9nmz3prj2ncMbOcMo+vMk47oEcjohm+92XMDR1po7zTRHnznYn2KDo9bAoY5v0KtFc3NXp1qwPc2Dz7SPMGf4k+auSrXBxsaa5b5PI5B0sLHh4T6N6VLHXS1Z+VomrkjjZMLT9A71ZvmYdtjbWNcJMQcz+9ADPBzpN+N95rm/Rr+8t/lUP5rv90Tz895LDPtsF8+vPE5StobMH2fg5+mGi4sLnp6eDB06lJiYG2a4KxfBwcFs2rSpzHKbNm2iY8eOODs707BhQ1asWHFbxzWFb/fEM832PToPnV5qmeDgYBwdHavcJq1atcLFxeXKx8bGhuHDK9+fXd/dEdF2LP5+padFNpdN0tPTGTduHPXq1cPb25uJEyeSnZ19W8c1hbD6bvz4YDd+eLA7307uXKKYm8smcXFxjBw5Ei8vLxo2bMjXX399W8c0FTdHG0J9XXnzP62vDKRyd7I1mx1WrFhBjx49cHJyol+/fjdsP3r0KJ06dcLJyYlOnTpx9OjR26qTSYIuhBgshDgnhIgQQswpYbu9EGK5cfs+IUSwqRVoGhTAqLHTyMgv4qNN4QwI8+XLiR156Z4wtj7bj39fHIC9jRWrV68mNzeXhIQE/Pz8+O9//2v6Wd4ip0+f5v777+fNN98kKyuLY8eO0alT5SbAklLSrbEXsweE4mB781GP5rDJqVOnyM3NJTc3l5ycHAIDAxkzZkylH3doW38+Ht+hzHLmsMncuXPJyMggKiqKyMhIkpKSeO211yr9uKZiDptMmjSJkJAQkpKSWLt2LS+99BJbt26t9OMKIfhoXHsmdmt0w/1jDjt4eXnx5JNPMmfODbJJUVERI0eOZNKkSWRkZDBlyhRGjhxJUVFRCXsyESnlTT+oSS0igcaAHXAMaHldmceAr43fxwPLy9pvp06dZHH+Ohon15+Il1qdXl5Po0aN5MaNG68sr127VoaGhkoppdRoNPKZZ56RgYGB0tfXV86cOVPm5+dLKaVMSUmRQ4cOle7u7tLT01P26tVL6vV6OWnSJCmEkA4ODtLZ2Vm+++67NxxTSiknTJgg586dW+I2U0FNAlKmnUuyyc0wl02Ks23bNuni4iJzc3NNrreU5bOJLIddzGWTwYMHyy+++OLK8ueffy7vuuuuOmuTnJwcCcjk5OQr6x5++GE5adKkctmkvHa5mU3Mfb989913sm/fvtes27Bhg2zQoIE0GAxX1gUGBsr169ffsk1MaaF3BSKklBeklEXAMmDkdWVGoiaGBlgJDBDlHP0zol0DBrf2L9PXlZ+fz/Lly+nevTsAc+bMITw8nKNHjxIREUFcXBzz5s0D4IMPPqBhw4akpKSQlJTEW2+9hRCCn3/+maCgoCtP7Oeff77EY+3duxeANm3a4O/vz6RJk0hPTy/PaVUJVWmT4ixatIhRo0bh7Fz9shlWpU0ef/xx1qxZQ0ZGBhkZGfz2228MGTKkys7VVKrKJkpzrv69/P3kyZNVcJZlY6775XpOnTpF27Ztrxko2bZtW06dOnXrJ1fWUw8YDSwotvwA8Pl1ZU4CDYstRwLeN9tveVujzs7O0t3dXdrY2Eh/f395/PhxaTAYpJOTk4yIiLhSds+ePTI4OFhKKeXLL78sR4wYIc+fP1/iPos/sUvC1tZWNmrUSJ47d07m5OTI++67T95///0m11vKym2hm8Mml8nLy5Ourq5y69atJtf5MuWxiSxna9QcNomLi5MDBgyQQggphJADBw6UhYWFJtX5MrXNJj179pSzZs2SBQUF8tChQ9LT01M2a9bMpDoXp6LuH3PfLyW10OfNmyfHjRt3zbr7779fvvrqqzfd181sImSxp2hJCCFGA4OllNONyw8A3aSUs4qVOWksE2tcjjSWSb1uXzOAGcbF5sA5E587bYCLQI5x2QMIBk4bt10/zYgAjqD6CBoAl5O/pACJpewzCKhn/J5gLNceSDIuAzgBzYDy9Fw0klL6mFJQCJECXDJxv+ayyWW8gADghIn1LY7JNoFy2cVcNmkOFACxxvUNURFkF0yo82Vqm03sjOudgUIgD3AEwk2oc3Eq6v4x9/3ibdxWXPN8ATcgoti6psb9JZVyHnAzm5Sm9Jc/wB3AhmLLLwIvXldmA3CH8bsNkArqYVERH6PRBl63LgUYC+QDASbsozWQDAwwLkddv88SfrMTeKXYckcgo6LOqybapNhvNwLzzG2H6mATIBdoV2y5PZBrbntUh+uk2D6WAG/XVTsA04Ft1627C9UIEMXWXUI1jm/pPE3xoR8AQoUQIUIIO1Sn56rryqwCphi/jwa2SGPtKhqhGIl6Yp4CvgM+EkL4GrcHCCHuNn4fJoRoavTnZ6GewgbjrpJQHb0340dgmhCisRDCCZgDrKnwk7pNqtgmCCEaAv252m9S7ahimxwApgshHIUQjqi30OMVflK3SVXaRAjRQgjhKoSwE0JMQonXh5VyYuWkiu1gLYRwQDV0rYQQDkIIW+Pmbcb9zTZGCl72emy55ZMz8elyD+pVKRL4P+O6ecAI43cH4FfUq8N+oHElPF0LUC2hHJTPfmKxY7+Fer3NBs4As43bnjL+Ng/1JHy52D5HAtFAJvDsTY79OupJngL8DHiaq5VRjWzyIrDT3DaoLjYBQoDVQBqQDvwNhJrbHma2yZPGeyYP2AV0rqN2mArI6z4Li23vABwy1u0w0OF2zrNMH7oFCxYsWKgZ1I3xsBYsWLBQByhT0IUQPwghko2RLCVtF0KIT42jRI8LITpWfDUtWLBgwUJZmNJCXwgMvsn2IUCo8TMD+Or2q2XBggULFspLmYIupdyB6ugpjZHAT1KxF/AQQtSdXLcWLFiwUE2oiPS5AUDxtGWxxnUJ1xcsPrDI2dm5U1hY7Zt1+3oOHTqUKk0cGOHt7S2Dg4MruUbmpzw2gbphF4tNSsZy/9zIzWxSpfnQpZTfAt8CdO7cWR48eLAqD28WhBCmjvwkODgYi01upC7YxWKTkrHcPzdyM5tURJRLHBBYbLmhcZ0FCxYsWKhCKkLQVwGTjdEu3YEsKeUN7hYLFixYsFC5lOlyEUIsBfoB3kKIWOBVwBZASvk1sA41kjQClRNhWmVV1oIFCxYslE6Zgi6lnFDGdgk8XmE1slC7iD8KJ1dC72fA0bPs8hYsWLhlzDpJdK0hNxnSoyByC0RshGnrwcbe3LUyLwnHYddHcGY1GLTQfqJF0C1YqGQsgl4eDAZIiwBHD3DxhZRzsO0dOLcOdBpVplEvyE8DtwbmrWtVc34TeIVAvSYQuRWWTVQPtbZjoe8L4NnI3DW0YKHWYxH0stBkwf5vIXovxB4ETSYMfge6PwrCGuIOQst7oc1oJWZeZWafrX0knoAlY+ChjWr53Dr10Ju6pm7aoyykhNRwsHMB9wBz16Z6kHAMbJ3A3g1c/cxdmxqLRdCvJ/4oJB6H0LvB2RtWTIYL28G3BbQcAQ27QuN+qqx3U3jyVibsqYFkxiiXUpvRYOcM/8yF479CUS4U5YGzD3iGqLJ3vwV3vw3WlsvrGrQa+OEuyI6HvBR1HU3+y9y1Mi/JZ2HjK3B+g1q2cYQXYy3Xzi1isdpl8lLh6BLY8j/QFylR6v4YhA2DNmOhw0Rz19A8SAlb34Id89VyYFf1cGvUEwoywM4V7Jyg1X3gbJx9y9q29P3VJXJTIGYv5CZB54fA1gHaTVD9C0HdoF6ouWtofk6sgOh/YcCrYO+q1hm0FkG/Reqm1Qpz4chiCOgEgV0g/gj8Mka1mkL6woBXwKc5CAFdHzZ3bc2DwQC7P4I9nynhbjcBej2t3EoAzYeoj4WSObIY1r+g3mAQENQD/FoqV11d5tIe2P0p+LeD/i+qe63XU1fF3MJtUfcEPT0KfhwCOQlw15tK0FMjwNYRZmyHBu1vedeRKblcTM2jbzMfbKxreKp5gxbOrIHAbtBmDLQepR5wJpKUreHgxQwGtPDFwda6EitaDTm0CFbPhpA+0H8uuDe0+MpP/Qlrn4H8VHD1v1bALWJeYdQdQZcSLu6EDf8H2nzVgRfYVW1rdjeEDlIdedehN6gZnRKyCth2LoWeTb0p1OmZteQIcRkFdGrkSdcQLxrVc+KtdWdIyi4kyMuJDU/2wdGuBguZjb3y79q7lkvIAfKLdEz5YT9nE3OwtRa4O9oxqlMAD/UKwdfVoZIqXE0wGOD4CmgyACYsLTV8VUrJR5vOc1+HAIK9nau4klVM8hn4Yyb4hKnxCJ2mqH6YEsgr1KEzSNwdLW67hIOryctIoumg6Sb/pu4I+rn1sGwCWNvB2J/QB3ThstwWWDmz6lgcvm5F9A31IUej40hMBt/vimLn+dQSd+fras+4LoH8fTKRXRGqjJ2NFa+PaEVaXlHNE3OtRvm+i/Jg48vKp+nkZfLPNVo9fx2N48fdFzmbmAPAS/eEkZZXxMXUPBbsjGJ0x4a1V9C1GsiJV1E9k/8EbUGJYl6o0/Pzv5fIzNfy+dYIHG2tebRfEzNUuJKJ2gknf4Mh74JXE+g4Bfo+rwINSiElp5AHFx7A3dGWnx/qiihnQ6JWkJsCOfHoIrfhv+kV3tBPprN/AoejM3lxSFiZNqn9gl6Yo1qZzYfAhOXQqAdxGlvufXsz03oGYzBIFuyKIjNfixDg7+ZAfJaKKfd1tWdmn8Y429vgYGtFjybe7ItKR6PV858OATTwcOTV4S0p0hvYfi4FVwdb7mhSz8wnXE60GvhppOq8s3NVoq7JgtajIaR3iT/JLdThbGd95eLSGyQTvtvLkehMwuq7MntAKO0aujOgxdXws5ScQnxca+lgq6w45cazcYBZ+5UNS+kY/nH3Rd5ZfxaAvs18mNmnloR16nVw6Ed17QBsf1dFrPR9Xo3JuGd+qT9dsPMC5xJz2HQmCY3WwOf3d6ibYr7lDeSujxAGHTbAbn0rVhr6sWDxYfzdHZjeu+w33Not6CnhsGgY3P0WsvUoLnj1Qptp4LPNZ0jJKWT+3+cAGNjCjwd7BfPrwVjiMguY2jOYAA8nBrX0w87mWl946wD3a5aFENjbWHNXq/pVdloVijSoiAu/liCs1ACpsOHXiLnBIIlMycXW2oq4zAKm/LCfFv5uhBhdBXY2VhyJzuSNe1szsVtQiTdjrRXz3BRYPAry02HkZ6UWi0zJ5ettkaw/mUifZj6M6hhA/zBfrKxqsHBJCRGbIXQgWFnDjvchN1Ft820JU9eW+ZZ3KS2PN9aewc3Bhu6N6/HkwGa0bOBWBZU3M3odHF0McYeh6UAu+g5ga3wg1rpB7NaFcVH60ap9d55t5MW6Ewl8OLa9SW+3tVrQ5frnkTot8Q7NmP7JziuuAIAHe4YQnZ5Pz6b1mNZTxU/3aFL662Ctxc4JBs0rcdP+qHS+3RHJ+eRcLqXlA2BjJWjo6YiVgBNxWRTpDMRlFtAxyKNUMa+1aLLhpxGQcREm/nrDG41GqycpW0NyTiEP/3QQnV4S6ufCvBGtaofffPPrsH8BzLmkBP2xf5VvXJMFjl4mhR7+fVI9ANbO7k2gl1Nl17jaYNj5AVbb3kJv68KZbEfuO2sL0pfh7V5kQIgXYf6utG2o+vQmdTd9lHXtFfTovYgLW3lXP5Ed67KIyyzgfyNb4e1ij6OdNX1CfWp26+h2MRhg1SwVjliCa0VKyf/WnOZiWh7tGnrwaN8m5Bfp2R6ewsvDWtDU1/VKuVPx2fi7O9QtMQfY/QmknIVJv19jw9TcQo7FZPLhxnBOxWdjbSVo5OXEwmldCapXw0VLSki/AMeXq1w9HaeoNzu42hp38TV5d+tPJtI6wK3uiLmukPh/PsZ3/7us0vfgSc3j2J7U066RO19O7Iiv2+31MdVKQU9OTsRh2Qw00oOfdAPIT8hm7tAWPHBHsLmrVn3Y9QEc/QWC7ihR0PdFpXMiLos3/9Oaid2uthAe7BVyTTkhxA1uqDpDn+egUQ9o0v+a1U8sO8LuiDSc7Kx5uHcIablFzB3WEi9nOzNVtAL581E4tlR9bzcBhn1U7iioy8Sk53M0JpPn7m5egRWs3pyIyyJ033scsG6HvPt9fvb2xdpK0KmRJ/Y2tx9IUSsF/fuly5mdl8hLNi/z/eR+bA9PYbJFzCFiE/w+Axw8ID1SdXx2mHRDMY1Wz+urT+PtYseojg3NUNFqjq4IDDrlrmo64JpNMen57I5IY2qPYB7r36TmRvUYDGqEa/IpOLES+r8EHkFqPEL9tuDdTD3IrEwXoX0X0nhz3RkGtvAj0MuRs4k5CAH3dqjlMfpSQsx+DP7teXnNeaxtP+SrJ8ZyRyVcGyYJuhBiMPAJYA0skFK+c932qcB7XJ167nMp5YIKrKdp5KVyLM2abxKa4t57NR8N6FgzI08qksIcNRI2pI8ardi4v1rX8QHoOvOG1lWhTs8zK45xJiGbH6d2qXuDgkojcqsaGNOkP1jbw+m/YMY2cLl2rt5fD8YgBDzcp3HNFfOcRFg6Xl03ALbO0PlBJeihg9SnnCRla3h8yREKinQcj826sr5XU28CPBwrqubVBiklHyz/h5DoX+lVtAc/XRxHnXpxNP0x3hvdv9KuDVNmLLIGvgAGAbHAASHEKinl6euKLpdSzqqEOpqGXgs/DuGQw2Rc7ZvxgFHM6zRSwsqHVGa/J46qFuXo70stbjBIHv/lMJvOJPPSPWH0DzPdF1rrSTyuHoSHf1K5flqPukbMt51LZnt4Cj/9e4k7m/vWXJHSa+H7QZCXBne9AfXbQEBnsHcpubhBsvxADCHezlxKy6N1gDvpeUVkFWhxtLXmh91RxGYUoDdI8gp1/Pl4T3xc7dkdkcrLf51kWs/gqj2/KmDr2WRO7t/Mg5HP4ibyOShas9R5ND/ndmFmn8aV+tZrSgu9KxAhpbwAIIRYBowErhd083JgAaSGc9Iqh4Et/SxiDupV+fwGlS+jFDRaPel5Raw7kcChSxlsOpPMK8Na3uArr5NkRsO5v1WGyZ5PqGRt6VFw5Cfo+dSVYueTcnho0UH0BsmAMF8+Hn/r6SPMQmGumoik7TgVP99/LtRvDX6tbvqzi6l5vLH2NJvOJF9ZZ2djRZHOcGXZ392BRvWciEkvYNmM7jSvrzrTh7drwLC2/rWnI70oH07+Rl7TYTy+5DAP6LcjHB2xmrmd7j5N6Q48WQXVMEXQA4CYYsuxQLcSyo0SQvQBwoGnpJQx1xcQQswAZgAEBQWVv7alEbEZNr1GXmBffj/flvmN67CL5TJ5qbD+eZWArGfJl1JuoY4+87eSnlcEgKu9DRO7BdXKVlO5kFKlB977pYrT9wpRbgZrW/BpplquV4pK/rf2DE521mx/rn/N6vjMTlA5Zy7uBm2eCjlsOQLajbuhaERyLn+fTGB678Zk5mt5+a+TbDqThI2VYO7QFtRzsaOesz1fb4/Ez82BEe0aUKgzMKCFL7al5DWqNWIeewjD0vFY5SVztJOO/CJfhkx5Cs9Gb5VrtHVFUFGdoquBpVLKQiHETGARcOf1haSU3wLfAnTu3FlWyJGz41XO8nqhrG36OpyPp3tdF3SDAVbNVi6CEZ+X2nG17kQC6XlFPDEglLtb1a8bAzrKQqtRvvKji6HDA9D76at53ktg0Z6L7AhP4dXhNSyKJfEE/D4TMi9B+wmqdX45t9F1GAySZ1Yc5VhsFmuOJ5CRX0SuRses/k15oHuja0Lt+jTzKXEftZYL25BLxhOrdeNDxzc4cDKIEG9r2oU1u+Xon9vBFEGPAwKLLTfkaucnAFLKtGKLC4DSx/lWNDH7QVgTf/e3LFmfQQN3BwK9aqj/sqKQBjXcetA8NQK0BM4n5bBkXzSNvZ15cmBo7WktlQcp4dJulWmzXig4uMGeT5WY93leRXbcxC6/HozhjbVnGBDmy5SaFEVVlKeS1GVegnGLbwi7vExqbiGL9lzk38g0jsVmMbpTQ07HZ9PQ04l5I1vRqkEdDVeVEoRAnvwd+ccjpNoFMDr/OYIbhOCcX8Sj/ZqY7X4yRdAPAKFCiBCUkI8H7i9eQAjhL6VMMC6OAM5UaC1vRqt7iffuwT3fHCW/UM/cYS3qpjiBeoUuyFAiPvR9deGVwKpj8cxeqiIY5piQ8KdWIiVseg12f6yWh34AXaardMGTfoOmA2/6802nk3hu5XF6NfXm4/Hta9YgNTtndY5FeSVmGAU4HpvJwz8dJDmnkNYN3JnUPYh5I1rXrPOsaDTZsOFFcPFD3/9lvjhpR5Oidryc9yA924Xx2YQO5q5h2YIupdQJIWYBG1Bhiz9IKU8JIeYBB6WUq4DZQogRgA5IB6ZWYp0V2fGQcJzMwDt55NdwdHrJ+id708Sn5N74Wk9hrspbg4DH9yk3i1Go/zgSyzfbL1xJBRydnk+nRp7MGRJG+8CSb+haTW4KrHtGhR52mgpN7lS5RwAa9735Twt1/Howho82htOqgRsLpnSuOaGd2gL452Xo8yy41i9RzPddSOOLbZHsCE+hvpsDq2f1qrsDx4qj18LyiciLu/jDeRy/Re1jd4RgXOcP6Ks3MHtA9Zh9yiQfupRyHbDuunWvFPv+IvBixVbtJuSlwsKhaLOTmGHzAWdzPPhiYse6K+YA//wfpEXClNVXfOY/7o7iux0XiM/S0KqBG419VP6QDkEePD2oOfXda2ic9O1ydo2avGPQPOgxu0xfZ1RqHucScyjU6Zn750lyNDo6Bnnw8bgONUfMAdY8rUZ5BnaFtmOvrNZo9fxzOokzCdl8vT0Sbxd7nhnUjEndG+FZk/oFKgMp4cSvKlz14k6+cH+WD5M7ItPSeG14S6b2rF7RYDVqpGhuoY4dh44z+MyLGDLjGFfwIoX+DfllfCu6BFdtb3K14vBPcGihimYJ6Y2UkjXHE5i35jQdgzwZ1yWIR/s1uSFzZJ1BStj5PuQkKVdUhwcguLea5LvUn0j+jUzjh91RbD6bfMV71T7Qg1eHt6RDkGcVVb6COL0Kji1R6QrajiWvUMfKQ7HEZuTz2+G4K5FOd7X04+Px7XGyq1HSUHkIAWufBSsrLvV4i/e3BDN3aAtGd2qIh1P1e9jVmP9aUraGhd+8z1O5H4KQPGeYhX3IHfw6vRvWddmvF7kFVj+h3AZ3vkxWvpZHFh/i3wtphNV35eeHutbdmzMtUsVXn/9HdX7eYRz3Zm1Tppg/ufwofx2Nx8vZjv/2b0qHRp6cScjmwZ4hNatVDmrk5+onwL899H2BzPwiHvh+PyfishACBoSp9NFh9d1qVqROZaLXgb4Q7JwxzNjOtnhrnvvzHN4uMK5LYLUd51Lt73QpJdvDU/i/P05yR34hkU5tmZE1Gdf6ofx0f4e6LeYAjXpBn+dJbz+TJdujWPTvJTLzi/jfva0Z27lhhST8qZGknofv74KCdHAPgiHzoeuMG4rlF+lwtLUmPa+IFQdjScgqIDW3kHUnEnm0XxOeGBB6RcD7N6+hI2e3vqX856MWgLUt8zec4HRCNt9N7kzfZj51982tNAoy0K18mKTMPLZ0/pINp5LZFZFKcD0nvp/apdqKOVRzQddo9Ty1/CinTh1DujVi6sxnaer3Gs+fSqJfc59qbdhKJ/msSlPq5MXBkJlM/+wgmflaeod689SgZnSsaS6BisbeVc0sP2S+GgxUAquOxfPsr8cI8nIiOj2fIp0BDydbBDCmU0Oeu6t57YjqGPy2ijP3DuVcYg7L9kcz+Y5gBrX0K/u3dYWUc2rKvHPrkanhoNPylXYyi/86jY2VYN7IVozvElTtH37VWtA/3HCakLPf8IX9SvRj/sTW2Ns+vF0DM9fMzGTFweL7wKsxCf/5lck/7MfPzYGlD3enhX8dHxykLVAf1/pqbs9S2HwmidlLj9Au0ANbK0GXjg15qFfwlTzvtQIpVd4ZO2cI7gnAV9vUPKZPVJOoDLNj0KsggoRjyO3zkYHd2OI8lC9SO/DUlPGMcrDB2kpcmWyiulNtBd1gkIQd/h/32WyAFiOwCrnD3FWqHqRFqinPCnPg7jd57+9z6AySnx7sWncmCSgNrQZ+GAzuDWH8LzdsPhmXxVfbImkX6M4XWyNp6e/G8hnda55P3FRO/KrcLVNWg0cgcZkFrD6ewLQewXU+ekWj1ZN0aBUNc46x0X8mi3d5c0zzHZ5p3kSn5/N/97SokaNeq62gRx5Yz32GDZxvPJnQsZ+aZRhttSPhOCwcClbWyEm/88UZJ34/Es5j/ZpYxBzUlGgJR6HXUzdsSs7RMPPnQ8RlFrD2RALN/Fz4alLH2ivmeh1s+R841QO3AFJzC3ls8SGsBEyr44nXNpxKZN7vB1mmfY7jwoNHCzvRwMOZUT1asnjvJQa19GN675ppo+op6FoNXpuf5ZL0w3fkGxYxv8yeT9V0XzO2s+y84P1/TnBfhwCeHFiyj7jOYNDDxldUMq0uD0Ore9HpDczfcI6Np5MAiM8sQEr47dEeeDjZ0tjbuXaPkD2zSmWLHPwOWgkzfz7EuaQcvpzYqeam9r0FIpJzySvUYW9rxY+7LnIu6iKtMrey0HEngVYprGr0Ml907sxdLf2wsbZiZt/GeLvY19hro1oK+rbILFblDiesRWtmuFtGqV1h2EeQdJpIXT1eXbWT3qHevDemnSXSGh1HxwAAIABJREFUZ+Mr8O/nKopl8DtIKXnm12P8dTSefs19cHOwpV9zHyZ2C6pdPvKbsfdL8GoCzYbw/t/nOHQpg08ndKhTHaF5hTomfLeXlJxCABxsrVjm+hXtbfcgbT1h1C883mLYNb/xd6/ZD7vqJehpkWhPr+HlnS1w9LmHt8b3MneNqgdaDegKwNETgrrx1sID2Ftb8cHYOizmeq3q/HRwgzZjwCcMOj7AP6cS2Xwmmb+OxvP0oGbVZkh2lZIWCbEH0A14nd8PxfHNjgtM7BbEiDoUTFCo0/Pu32f/n73zDq+i6Br4b9N77x1CCCX00HuVDiIqIAIqgq8NfW2or6/1tfdPLIAUUYpiA6QIAlKVXgOkQALpvZd7c+98f8wFQ0jCBQK5udnf8+xDdmd29+zh7tmZM+fMkFVUztP9/HG2t2Jst9a4V7aD/Asowd2uafm8xoLpGHS9Ht2vj6FLOUp5ybu8N2m4+fo3jSX/PBz7Hg4tBUsbmL2TpQcy+eN0JnNHtGq8S5zdKNnx8Osjckm0OxZAQEdyXdvwf2tPsnh3IiAjoR4dWHvykDlT7hjAJ+6vsPo3L7I4RodgN14aXfOsm+ZIfGYx9y/ex+jClRx12orrviw56Vr/DWARJAfNzZSGN+g6LWTGoDu9Ecvzu3lB+yD9Okc17TnN9XrY9ALs+0pOhRvSC3rP4dtDWby85iRDWvs23UUo/vpSzltjZQ/dHkSr0/PGuhhW7r9ARaWee3uE8tLoNiYfL3zT0Gn538YElqW15MG+zegU4n7JP9wUyC6u4PEvfuFZvme09Z+I0MEQ0gOCuppli7w6DW/QT/4MPz2IJbBTF0W32+cwoYv5fkGNofDor7j8/QWnAyeS0/lRVsWC/qDg95MxDIj05qt7uzQ9V4sQsO1/sOM9isNuI3fQuwQHh/LehtMs3ZvEXdFBzOzbnJa+TcRHXhP55ylZPh3HlJbc33sOL45qOq3yi3g52fJotCMjDuyC3nNQhrzapIIqGvyzfcymA1/7v8Q92v8wP+gtJnQJolmzZtjb2+Pk5IS7uzujRo3iwoUrVrS7JsLCwtiyZUuddb7//nt69eqFg4MDAwYMuKJ81qxZREZGYmFhwZIlS25IntoQQjBhqztTNC8wPOF27vkhlT0JOXz96EjOvjee1Y8NwsvTwyR0Ehsby7hx4/D29sbDw4PbbruNM2fO3JBMtfHbX8co2LWAdVZDaH/6Xvp9fhI7D3/+M64jqZ/cyYIHB/Dk/ZMaXCfZ2dn07t0bT09P3Nzc6NmzJ7t3774hmepEr4Pzf8GWV9F/1g0l8xRvff49b93VxeTen4t88803KIrCwoULb0im2hg5YhzK03FyNk2DMQ8LCzNJm6IoCo6Ojjg5OeHk5MTMmTNvSCajDLqiKMMVRTmjKEq8oihzayi3VRRllaH8b0VRwoy5bmp+GeOWxvNxWjva9h7NJ1N7XAoXWrt2LcXFxaSlpeHr68tjjz12DY91fXh4ePDEE08wd+4VjwhAhw4d+Pzzz+ncufNNk0FRFF4ZG8Wrcx7m2eGtmNwtmJ3PDsTXxY6N638zKZ3k5+czduxYzpw5Q0ZGBt26dWPcuHE3RY48xY0nXT/me7+neeuODvx3dBusLS3493sLKTEhnTg5ObFo0SKysrLIy8vjueeeY8yYMVRWVta7HJpKPQnLHoFFt8GuD9lY0Y7x4n3sHJxM8v0ByMvL480336Rt27oXoL4hLCzA8UqXranq5OjRoxQXF1NcXHzjHzkhRJ0bclGLBKA5YAMcBdpUq/Mw8KXh70nAqqtdt0uXLkIIIbbEpIvicq2oSmhoqNi8efOl/d9++01EREQIIYQoLy8XTz31lAgODhY+Pj5i9uzZorS0VAghRFZWlhg1apRwdXUV7u7uok+fPkKn04mpU6cKRVGEnZ2dcHR0FO+8846oiwULFoj+/fvXWt67d2+xePHiOq9xEeQiIFfVc1Wd1ISp60QIIXJycgQgsrOz600nog69mLpOdDqdWLNmjQBERkZGvevkj1PpYtTcT8Wzr7wiOj/3nXhgyT5RWKYxab3Mnj1bzJs3T/Tv318sWLCgzutcq14a4/sDiLi4uKvqodo5terEmBZ6NyBeCHFWCKEBVgLVm2HjkAtDA6wGBitGRuYPbu2Lo23trvzS0lJWrVpFjx49AJg7dy6xsbEcOXKE+Ph4UlJSeO211wD44IMPCAoKIisri4yMDN58800URWHZsmWEhIRc+kI/++yzxohmspiqTnbs2IGfnx+enrd+QNvUdNK+fXvs7OwYO3YsM2fOxMen/mdqHNDSh7n3T+atl/7LT8+M46t7o6+YsM6U9LJv3z4OHDjAQw89dGMPfoOYkk4A+vXrh5+fHxMmTCAxMfGGnk0Rtaw7eamCokwEhgshZhr27wW6CyEerVLnhKFOsmE/wVAnu9q1ZgEX5zCNBGpzuLZDDtgKpFuoEogDyoBOQAxQYajriOw9HAcCAHsguUp51WsmAkV1PrDEC/CsQ75IIBvIqaW8KqFCCKMmhVAUJQtIqqXY1HViDbQ23Cf3KtcyWidQp15MXScK4G7492q/lfrSCZiuXloD54ES5DuUg3yP6sLc3x8npD4sgEDAGTh5lWvVrpPamu4XN2AisLDK/r3AZ9XqnACCquwnAF5Xu3Yd90wEhoh/XD4TkEYiBPkfkl9lKwCKDXWdgQ+As4Ztbk3XNOx/CRQbtheq3X8msL0O+XYBM673+cxNJ4A38oV4UdVJjXKeAjo0Zb0AjyHXI764vx2Y2ZR1UoOMlkjj3u66n9MIRfQENlXZfx54vlqdTUBPw99WyK+uUh/Kr3IsC7gLKAUCjbhGFJAJDDbsn6t+zTrONWmDbko6QbZADwNv30p9mLJOaqgXD9zelPUC/ALkAemGTYM0nJ8Zc01z1EkNdSyRH4P21/ucxvjQ9wMRiqI0UxTFBjnouaZanTXAdMPfE4GtwiDhjaJIxiENx0lgAfCRoig+hvJARVFuM/w9WlGUFgb/fQGgA/SGS2Ugu1F13ctSURQ75EfJQlEUO0VRrKuU2xjKFcDaUH7LQz9NRSeKorggP+a7hRC1D+PfAkxIJz0URelj+K3YK4ryHOAL/F3vD20EpqIXYAbS5dLRsB0AXgVerLeHNRJT0YmiKG0VReloqOOE7AmkIHt014eRX5eRQCzSlfKi4dhrwFjD33bAD8iWyD6geT18TcuQX6sipEvnnir3ehPZ/Sk0PPzjhrInDeeWIH1eL1W55jik/y4feLqW+85Adr+qbkuqlG+voXzALWxhmJROkB9xYbh2cZUtpAnrpD8yEqwI2aX/E+h3K/Rhynqpoe52br3LxaR0AgxC+tRLkC3/X4CIG3nOqw6KqqioqKg0Dho8U1RFRUVFpX64qkFXFGWRoiiZhtDEmsoVRVE+VWSW6DFFUW5eGqWKioqKSq0Y00JfAgyvo3wEEGHYZgFf3LhYKioqKirXylUNuhBiB3UniowDvhGSvwA3RVH860tAFRUVFRXjqI/pcwOBqtOWJRuOpVWvWDVT1NHRsUurVq3q4famzcGDB7OFkZluXl5eIiws7CZL1PBci06gaehF1UnNqO/PldSlk1s6H7oQYj4wHyA6OlocOHDgVt6+QVAUpbZU5CsICwtD1cmVNAW9qDqpGfX9uZK6dFIfUS4pQHCV/SDDMRUVFRWVW0h9GPQ1wDRDtEsPoEAIcYW7RUVFRUXl5nJVl4uiKCuAAYCXoijJwMvImfUQQnwJrEdmksYj50S472YJq6KioqJSO1c16EKIyVcpF8Aj9SaRioqKisp1oWaK1idpx2DTi1BR3NCSqKioNEFUg15f7PoIvuoL++ZD+rGGlkZFRaUJohr060FTAsdXw6LhkHJIHgvqCsPegKdjIbRXw8qnoqLSJLmlcehmQV4iLBgEpTng3gw0BvdKWB+5qUgqK8DKVv6ddhTsPcAtuO5zVFRUbgjVoF8L2nL4+SHQaeHeX6BZP7CwbGipTIezf0JmDBQkw8mf4cFt4Owr3VHO/jD8rYaWsOGp1ICVjfw7cZfaCFCpV1SDfi2c2wHn98KEhRA+sKGlMR30etjwDOxfKPctrKDVKORc/kCXGRDQhCfhTD8BO96DnATZo3v4L7C0gZhfVYMOUJorx576PweKAsVZ4GT0LAgqVVANel2U5UPyfrBzheBu0HIY/Gsv+LZpaMlMA50WLK2hJBPObIQej0DvOWBtD3Yu/9RrPqChJGx4kg/AdxMBBQI7Q+BIqCwHazu47c2Glq5hEAJOr4NdH0PuWfmREwJajQahB49mDS1ho0U16NWpKIatr0PSbijOhOIMsLCGf+0G70ijjLleL7CwUG6BsA1A8kHY8Kw02lmnYeYWcA+Dh3aCvbtsYalIyvJh6Vhw9IRpa640VJbWNZ9n7mSdgVVTwTMC2t4uf0tRd4BfVENL1uhRDXp18s5BzBpppLw9YPTHoFiAR3idp6UVlLHvXC5/n8slNr2IHx7qiWJOxq2iGLa9CQcWgYMHOHhCxDDQVcpyB4+Gla8h0evlxy1uE1jZy2PdZ4O9G4yfB836N239XKQsT370fVrJMaiwvmCpmqD6RNXmxTVVS7LAzg382sGco/8MXNXBX2dzCPFwwNrSgnGf7SazqAIbKwtu7xhIuVaPvU0jHzDNjoOUgxA5EqwdpNFqPQZu+x84+TS0dKbBuR3w/XQoq7pkgALN+4NPa9kCVYG4zfDjA7KBFDVBHYMylsoKGWDQ/m6jer9N16DrtHBgMex4F/Q6qCiEfs/CgOdqNOblWh0bTqQxtI0fCvDF9gQ+2xaPp6MNHo42FJRp+faB7rQLdMXVoZF3pZMPwJ/vyhYnwFNnpE986o9G/ajmbYvnr7M5DI/yY9Guc0zoHMQ93UNwc7j6R7JRcG6HdMOF9gSvSAgfBC0Gy5Z4Zbkc8FRDNCXFmbDpBTj+g+zlhvRoaIkaD0Xp0jWVvB9cg4waQG+6Bv37aXBmvez2uYeCg5dsOVTjZGoBW2Iy+TM2k0Pn82nuFU92cQWF5ZWMbu/PiZQCdEIwb0pn+kR4NcCD1CMVxbD6PtmacvSCAc9Dm3HgaGiNG2HM/ziVwXubzgCwMy4bLycb3tt0hv/bGsd3M7vTJbSRuh4qimQy2dntEPMLNB8I036RYZkTv77my1Xq9FTqBZYWCtaWZprft+5J6aJTLGDgi3LA/GJugkrtVGpg/VNw+Ds5znLnUqOjoZqWQS9MBSdfGTvefKAMp4sYVquhWrnvPHN/Og6As60VjwwMZ9X+ZPpEePFAn2Z0DnFHCHm6WfjLrR3kIHD3h2DQi2DrbNRpReVafjmSil4v+HBzLG38XRjaxpdNJ9P5bmZ3soorWPH3edoGuN7kB7hJlOXDtxOk+8naEfo9A33+fU2XyC/VYGVpgZOtFafSCpmy4C/ySrU8N7wV/xpQ9/iMySOE1I1eB/sXwJBXZIuyxRCZfBc+yOgBzxX7zmNloXBndBPu4Wx6AQ59A91mQdcHwbul0ac2DYOeexZO/Ci/eEFd4Y4F0H1WjVW3xGSw6WQ63s62LN93nm5hHiyYFn3JjfLMbZcvm9fo7Xj+efjtKRj4AgR0gtk7rul0nV5wxxd7iM2QGbPOtlZ8fk9nwrwceXKo/CF6Otny6rhGHMGQcgAyYuCub2Ro3TUkk+n0glfWnGTZX0lYWSjMGRzBz4dTsLK04NnhkXRv3kh7LBepKIIfZkD8FrlvaSv9va5BhlyEK8kpruCrHWfp08KLvhFepBaUs3LfeWIzith0MoMhrX2Y2CXIPBpJxpB/Af58G3zaQM9H5IewWV/ZO75GjDLoiqIMBz4BLIGFQoi3q5XPAN7jn5WKPhNCLLxmaW4GB5fAb0+DXivjyaNrnq5dCMHCnef43/pTuDtYU1heiV4IXh7bpvH7xGtCUyL1EvOLTAQqy7uuy2w8kU5sRjHv39mBEA8HHG0tCfNyrGdhGwi9Hiws5Av2xLErBoKziirwdLSpMUS1pKKSs1klfPJHHFtOZTClewjJeWV8sDkWZzsrFk6Lpntzz1v1JDePbW9CwjYY9j9wDQS/9uBZe48jMbuE6Yv3kZRTyvwdZwlytyetoBwhBH4udszoFcaLo1o3DWMet0UmnKUclO9g3zB5PHL4pSrlWh0/HLjAnoQcPr+n81X1YswCF5bAPGAocgHo/YqirBFCxFSrukoI8ei1PM9Np7wA1s6RL+S4eeDsd6nofE4pvq62vL/pDPY2VlzILeXnwymMaufPB3d1ILdEQ2ZRReN1E9RF5mnY+Jwc3Os8DXo9XudLWBMFZVr+91sM289kEebpwO2dArE0h9h7vR4OL5O+y5hfodO90Hr0FcZ8V1w20xb9zYBIH7ycbAh0cyCnpAJ7a0v0QrBy3wWKKipRFHhtXFum9QyjUqdnZ3w2XcM8cLJtpJ1jbRkcXSF7un7toPVYacQ71rlsAgAJWcXc+eVehBCsnNWD5Lwyfj6czMh2/kzrGUqQu8MteAATYfvbsP0tcG9GfsdZxARM4Mez1mR+/TcAET7O9I/05t2NpzmZWkiHIFfyS7W4O9YdWGDMr6obEC+EOAugKMpKYBxQ3aCbBoe/lS2GiV/LGOm+T8mU4iqDMTvjspi2aB++znakF5YDYGNlwcMDwnl6WCQWFgoBbvYEuNk31FPcXFIPw7mdMoSsy/RrOrVSp2fDiXQ+2hLLhdxS2ge5Mbtfc/Mw5kLA9/fKLMaLRAy7rEpFpY41R1J5e8NpvJ1t2XYmEwdrS0o0OmytLKjUyzDYEVF+jGrnTzNvR1r5yaxZK0sLBkY2wnBPTQmc2QCJOyH9uGxRDnpJGvTQnnK7CkJI11OlTs8vj/SmubcTABO7BN1s6U2HtGMyEzagowxntbBil89k7l16BCEycLa1IsLXCZ2Ab/Ymsmj3ORxsLJl/bxeGtvE1qtdijEEPBC5U2U8GutdQ7w5FUfoBscCTQogL1SsoijILmAUQEhJixK2vkeOr4ddHIKSXnEjL0RMG//dS8ZEL+byy5iSxGUUEuNqTVVTB2A4BzB3RCjtrSzyu8vVrtFRWwN9fgo0jdJ0pY8lbjZQuKCPZGZfFOxtPk15QTnaxhjBPB5be341e4Y08sqcqOi24hcrfTEWR3KLvp7BcyxfbE9h6KpOMonLyS7W08nPmsymdsbRQ8HWxJbdEg5OtFRqdHgT4uNg19NPcGBdH+wH+eE3+fqwdZMTKnUuv2b/7e0wGO+Oy+c+o1peMeZOiJFuGILoEopn2G3+ku5DMBD7//iQRPk68Pi6KtoGul3pumYXlnM0uIczTET9X439L9dXvWwusEEJUKIoyG1gKDKpeSQgxH5gPEB0dLerp3pKErXImxNA+Ml7a+h8llGt1fLwljiV7zuHpaMvwKD8eHxSBi701bvbW5pumD7I19cvDMikociR0ngG2Nb9QRy7kcyw5H4Agd3tOpRXxZ2wWQ1v78s7G04R4ONCnhRej2wcwqJWP+egt4yTkJcmP3PDL51fR6QUPf3uIPQnZ9G7hRVSgKxM6B9Ir3POyFpODTSN1odREeSGsmARDXoXgrtKtEtrLMNeKuKbsztwSDb8dS+UDQ/TTtJ5hN09uU0Ovh10fwomfIDsWEGQNm8ecxfvYk5ADQIdgNz66q8MVHzkfF7vrahQY8z+TAlSNIQrin8FPAIQQOVV2FwLvXrMkN0LMGvhxppxrZfLyy4w5yCSgL/9MYFQ7f14Z2xZv5yYQCysE7HxfDlo5+cGUH+TkYrWwct95XvzlBDr95d9ZKwuFfedy6d3Cky+ndsHZzkwGiMvy5Xw9eUmw+b8yEajlbVdEsHy2NZ5d8dm8PaEdk7rdhF6lqZGXJN1OGSdl9jRAWO/rupQQgoeWHWRfYi4ejjbMu6czNlZmGnNfEzlx8Oc7iKBu7PObzHupURxaVoilhcLbE9rRr6U3/q529ToAbIxB3w9EKIrSDGnIJwFTqlZQFMVfCJFm2B0LnKo3CY3B3k22rkZ+cMmNIIRAL0BTqWfZX0kMae3DvHua0BSu53bIgZe2E2D0hzW6VyoqdRSUafl65zm+2nGW/i29efuOdlhbWrDvXC75pVq6NfPgz9gs7u0Raj4vY/wWWDEFdBVyP6yvDEm0sESnF1gY8gp2xGbx8R+x3N4pkLu7mnlctBBwYR+suke66CYtlx+462DTyXQ+2RJHfqmG1IJy/ju6DVO6h2Bn3cinwjCGgmSI28wfDsPZnyRIcvqEDWdcAIVhbXyZEyB7eMEeN2cA+KoGXQhRqSjKo8AmZNjiIiHESUVRXgMOCCHWAI8rijIWqARygRk3RdrqFGeCvQflQb2xDu2LVqcnr6CMSp3gjd9i2JMg51rJLdHwYN/mt0Qkk6F5f3j8MLgGXxYsX67VAfDauhhWH0xGU6kHYFLXYF4fH3Upa3FkO/9L57TwMQOfZ2kuZJ6Src2grtDpHoiaKAfL/TuApTXnc0q5b8k+NDo9vZp78fORFFr6OPPG+CjzD6Mry4NFw2RvbuYfRiezlGvlYLBGp8fawoIvdyTw7sYztPR1ItDdnhBPB6b1DMXKXLNhAZ1Oz8Zfv6Vd8R4Cz61GETpWas6zja408wrkkYG+tPR1ZmyHgJv+OzLKGSaEWA+sr3bsv1X+fh54vn5FuwrFWfBFL4o7PcjgfV2wsrCguKKSgjItIG1YnxZeZBVV8Mb4KLo1a+QJHMaSfwGS9kCHu8HtHxeBEIL3fz/Dl3+eJSrQlaMX8pncLZhwbyd6hXvRJsCljos2co6ugvXPyBkPHz8seyujP7qsyrHkfO5fsp9KvaCljzObT2XQs7knH9/dEcfGGmJoDNoyUCxlHPToj2WIbx3z0AghSMwpJTW/jG/2JrI5JoPm3k6czynFxd6K7GINYzsE8N6d7bG1MtMWeVE65J67FN2T/OltjCrYR4Ww4kd9b5ZaT6J9dBQxY6Nuea+28f5St7+JKM3ljdP+FJRp6RrmgYudNX0ivFCAln7OdA5xb2gpby25Z2HJGLlgQMTQy6Zs/WZvEvO2JRDm6cDRC/nM7t+c50e0bkBhbwFxm+UqSrEbIbQ3jHy/xtTebaczeWT5IdwdbFh5fzfz6JEYQ1E6fHenHPAc8U6NSXeaSj0nUwsQQGx6EYt3J3ImowgANwdrpvYIJSa1kOjOgZzLLmFyNw+eHNLSfAbML5IdDxf+kuG+J36UH77QnuyMy8I5L4dD/o/h3n82XX08uKsBE+san0EvzUW7+VUsDy9lm8t4ViZ78v6d7ZpWPGtNFGfB0nGgLYUZ6y4z5vmlGj7cHEufFl4svb8bh8/n0cncP3bZ8bD8LnAOgJ6PwuCXL82iKYRg/fF01p9Iw9vJlmV/JdHa35lFM7ri49zIww2NJS8Rvp0o5zca+GKNVbQ6PVMX/s2+xH+mBm7t78Lr46Pwc7GjTwuvxj9FtDGseUzOrQJg4wTR96OJfpD1h1N4fV0MHm4f8esDvU0i0qnhJbgGdDodZQvH4JB7im8qh/JO5hjuig5SjXlxJqyYLKMS7lsvEz4M5JZoePCbAxSVa/nP6NZYWihEh5mp+ynrDBxcKuPIvVrAxMVkB/TnQhF0tLSmsEzL3oQcNp5I45cjqbjYWVFYXkn/lt7Mu6dz483evBb0OmmctrwiB0KnrpYt9GokZBXz7sbT7EvM5fkRrYj0c8bdwYb2Qa7mP55QUSwjoML6go0DRI4C71bkBgxgf54Tcbkavl14nvTCcsK9HfliaheTMObQyAz6B5vj2JZ2DxYIIjv2ZsPgiJs2WtyoSNgGGSfgjoVy3UrgQm4pexKy+erPsyTnlzFvSudLGYtmSVYsLBgk/cGRw6FZP055DOK+L/aTXliOn4sdBWVaygyDwk8Oacljg1qQmFNCiIeDWQ/aXUbuWRmm6dsWxn9x2bJ4exNyuJBbSmG5lg83xyIEPD2sJbP7N/LZII1Br4PEXXK2yNjfZQRU7zkw9DWSvPryf8f8WbPuvEwcQ47PvTWhHf1bepuUe6lxGHRtOQlbFvDln2EMa9sdP1c7Hh4Y3nS6x7VxMZuvw90yesNV9lT2JuQwa9kBisorcXOwZvnM7ubbKgc5Y+SqqTJiZfYOcA1id3w2Dy07iIOtJS+MbEVMaiEu9taM6RBAgJs9gYZpHZpM1uLFica8IuCRfXJeI0NLu1RTyWdb4/l8e8Kl6m38XVg0o+s1ZSk2Wsry4Mt+UHAeHDxJbHY3S7Na8Ptf4QSf28uptCI0lXru7hrMHV2C8Ha2vfT7MTUahUHX73iP8L/fZ7jrm3w4aWTTiGe9GkXpsGIy+tveQhfUDY2dHxsOJhOXIQeuQjwdWDWrE828HM3bz1mcCfMHQmUFmju/ZerKC2h1SZxIKaC5lxOL7+tqvnPyGItOKxPvAjvLVqeLP5U6PRlF5Szbm8SKfecpKNNyV3QQjw+OQFEU/FzszGN+HmOwd0ff+wn+StWyTtOZ5YeyCPd2pF9bT3bEZuHtbMviGV0bhTfA9A16dhxi9yf8rOvN6NETVGMOMqZ6yWj0hSk8+s1e1pfkXFbcp4UX86Z0Ns9pf6tTmgue4RQMeof//AX7zqUS6GZP92aezLunM672TUAHNSEEpB+D/V/LKJ/iDAjqSlpBGa+sOcnmmAz0AiwUGB7ld2nBFrP3j1fl1DoqbNxYeN6PvQlR7IrPRlGymNwthNfGtcXa0uJSgmJj+biZtkFPPQwrJlOOLYsd7ufXKL+rn2PuCAFr5yDyEnnW4XX2lIbz1NBmKAp0CfWgWzOPRvPjuyGEkOvA+rQiafzPjJu3m/xSLU8OacmcIRENLV3Ds/V12PkBWNkhIkeREzqckvBRPP7tIeIyipjRqxl+rraMiPJvFC3P+iYr/iCeP/+LFKsw3st9Dld7G14e04bpPcMu84krioJMKtmVAAAgAElEQVRlI3qdTNega8th+d3oFUsmVbxEt85tmlbroSZ0lfDLv+DUGv5u/jirY0JYOK0DQ9r4NrRkt5b8C3Ke+8pytPeu4ZHlhxAC1j/e17wTpOpCCNg7T7pVQnvJ5RVdg8gLG8kD3ydw6GA+sB2AL6d2ZniUf11XM1s0lXpWf/0uE1PfJQdHphfdx6MDI3j6tsiGFq1eMD2Dbhjoy9NYsLXFW/yc7MhxnY6X1da5nOXOxoH8bv9m1t/dGNTKq+kZ8+OrYe0Tcl7poa/y7V9JnEgp5MupnZuuMQeZRPX7i3L+/9BepOJNvMsYXl5yktT8Ml4Y2QoPR1uC3e3NY6Wk62Tt128wKfVDkly7cLzHx/zXzYdBrRrhHPW1YDoGXQhIPUTiTy9zqMyfF4pup1xrRys/B0a1d2p6WZ8GCsu1pKemEOBQyf4CF857PMGnW+OxtBT8Z5SZZ3pWRa+HLS/Dnk8hpCdi/BesOW/DR+tP0DfCi9vaNuEPfmkuZRteQjiFsMNrBr8sO8jvMenohczmXP5gd7qEmnGUkxHkFFfw2bZ4Qi6c4Jx3L8If/pFm1uY3WN7wBl1TApteRMT9jlKYgo+wJc9hChM6BzO9ZxiRfsatPG+OaHV6Zn29k6cynsNNyeRfFR9Rjm2tcyibNRWFciWhrjPRDHmTZ3+O4ZcjqYR7O/Lq2LZN1h0njiynYu2z2FQW87D2CTatOI6bgzUP9Q+nV7gXkX7OTWO66Door9Dw2IKN/JVpxR2d5jJtQjuwMs/B8gY16JpKPQnL5xKZ+C17bHqxRjuSrMBhLJg9pOkketTAv5b+hU/yJnpUHuAz/RE8LIr4Iex1FvXph4+LLeHeTk3PgNm7yVkA7d15c6005k8Pa8nDA1qYVGLHrSYp9hgZ2kD2Rj7Pw/0G8Igi16M061DVq7Bi33n0QqDT6Sg6+AOdctfzmT6emLs20KdT+4YW76bSoFZTo9Mz8XR/7tU8x39tn6H9mMf44sHBtAhvjr29PU5OTri7uzNq1CguXLhiRbtrIiwsjC1bttRZ5/vvv6dXr144ODgwYMCAK8p1Oh3/+c9/CAgIwNnZmU6dOpGfn39DctVED88yXtZ+RG/LE5QE9Mbi3p957pUPGNwumI7N/fHw8DAJnezcuRMnJ6fLNkVR+PHHH29Irpo4kVLAnDVJdHp9M0v2JHJf7zDev38ojo4OJvc72bp1K507d8bFxYXmzZszf/78G5KpLl7MG8WTdm/wyKSxdAh2o32QG61bhpvk+7N27VqioqJwcnKiV69exMTcnGWJl//6G51+G8OITQN4JOdN2lim0O7zEob26n7LdfL0008TERGBs7MzrVq14ptvvrms/MiRI3Tp0gUHBwe6dOnCkSNHbkimBjXoDtaWbHthNB89/wRbnuzP1B6hl+LM165dS3FxMWlpafj6+vLYY4/ddHk8PDx44oknmDt3bo3lL7/8Mnv27GHv3r0UFhaybNky7OzqP5Nu+uiBWDy4FZcXEgidvRLCBwKmp5O+fftSXFx8aVu3bh1OTk4MHz683uXYciqDP05lMri1L8/cFnlppkhT04lWq+X2229n9uzZFBQUsGrVKv79739z9OjRepfjWHI+u88Vcl+f8Evz2F/E1PQSFxfHPffcw5dffkl+fj5jxoxh7NixVFZW1rscS2b2JjyiFU5RI9DdvgC3F2KxdnRrEJ04Ojqydu1aCgoKWLp0KXPmzGHPnj0AaDQaxo0bx9SpU8nLy2P69OmMGzcOjUZz/TcUQlx1A4YDZ4B4YG4N5bbAKkP530DY1a7ZpUsXURuhoaFi8+bNl/Z/++03ERERIYQQory8XDz11FMiODhY+Pj4iNmzZ4vS0lIhhBBZWVli1KhRwtXVVbi7u4s+ffoInU4npk6dKhRFEXZ2dsLR0VG88847td5bCCEWLFgg+vfvf9mx3Nxc4ejoKOLj4+s8tzrIRUCM0nNj00l1ZsyYIWbMmFFnHSGuTSfCoJeCMo0oLNOYvE7S09MFIEpKSi4di46OFsuXL693nVzILREv/3pCFDQCvfzf//2fGDly5KV9nU4n7OzsxJYtW+pNL6b8/lxkzJgx4v333xdCCLFp0yYREBAg9Hr9pfLg4GCxYcOG69bJVVvoiqJYAvOAEUAbYLKiKG2qVXsAyBNCtAA+At65/k/M5ZSWlrJq1Sp69OgBwNy5c4mNjeXIkSPEx8eTkpLCa6+9BsAHH3xAUFAQWVlZZGRk8Oabb6IoCsuWLSMkJOTSF/rZZ5+9ZjmOHz+OlZUVq1evxs/Pj5YtWzJv3rz6esxrwlR0UpWSkhJWr17N9OnTb/j5asLFzrrO9UxNRSe+vr5MnjyZxYsXo9Pp2Lt3L0lJSfTp0+f6HrwOgtwdeGVsW1wagV6Ai42/S38LIThx4sR1XetGaCidlJWVsX//ftq2bQvAyZMnad++/WXjYe3bt+fkyZPX/WzGDIp2A+KFEGcBFEVZCYwDqjrAxgGvGP5eDXymKIoiqv4PXiPjx4/HysqKkpISvL292bRpE0II5s+fz7Fjx/DwkGFYL7zwAlOmTOGtt97C2tqatLQ0kpKSaNGiBX379r3e219BcnIyBQUFxMbGcu7cOeLi4hg8eDAtW7Zk6NCh9XafujA1nVTlp59+wsvLi/79+9+U69eGKepk8uTJzJw5kzlz5gDwxRdfEBx8a9ckNTW9DBkyhOeee47t27fTq1cv3nnnHTQaDaWlpfV2j6vR0Dp56KGH6NChA7fdJtdqLS4uxtX18rV+XV1dKSoquu57KFezuYqiTASGCyFmGvbvBboLIR6tUueEoU6yYT/BUCe72rVmAbMMu5FIN05NtAMSgYtP5gaEIT8i7QBddTGBw8gxgQDgYtB6FpBeyzVDgIsZFmlV6gF4GcqqyucGhAPHgYtOrotvaV2jK6FCCO86yv95CEXJApJqKTZFnVSlJVAMpNZSXhWjdQJ16sUUdWIHtAYSgEKkOzIC+RspqOMx60snNT2DKegFw3UDAGsgB3AxnJtL7ZjL+xMEOCN1ojcc80HqIL5KvRaG62XU8hxQl05q88Vc3ICJwMIq+/cCn1WrcwIIqrKfAHhd7dp13DMRGFLtWBZwF1AKBBpxjSggExhs2D9X/Zp1nDsT2F7tWDgggJAqxz4FPrre52zsOqlSFoxcIDz8VujClHVieF8OVzv2cfV3pqnppYY6bsgGQCtz1wnwqsFGelY7PgxIxtCwNhxLQjaOr+s5jYlySeGflijIL01KbXUURbECXJFf4BtGkYxDfiFPAguAjxRF8TGUByqKcpvh79GKorRQpFOqAPnVvfg1zACaX+Veloqi2CFdURaKotgpimINIIRIAHYCLyqKYqsoSmtgErCuPp7zWjAVnVThXmCPQUcNggnp5DAQoSjKIINM4cBo4Fi9PrCRmJBeUBSli6GONzAfWCOEOF2vD2wEt1gnzwNTkIa/uk3cbrje4wabctHrsfW6H86Ir4sVcBZoBtgAR4G21eo8Anxp+HsS8H09fE3LkF/wIuTX7R5DmR3wpkGmQuAU8Lih7EnDuSXIL99LVa45DjgP5ANP13LfGchWeNVtSZXyQGCjQa6zwOxb0bowZZ0Y6pwGHrhVujB1nSBbfScMMiUjgwQsVL2wyyBPLvAV4NgEdCKACsN9L24vVCnvBBw0yHYI6HQjz3lVHzqAoigjkd1GS2CREOJ/iqK8hgyfWWP4Ki8zCJcLTBKGQVQVFRUVlVuDUQZdRUVFRcX0MSYOfZGiKJmGSJaayhVFUT5VFCVeUZRjiqJ0rn8xVVRUVFSuhjGDokuQmaK1MQIZlhWBDEn84sbFUlFRUVG5Vq5q0IUQO6g7TnQc8I2Q/AW4KYrSNJdDUVFRUWlA6mNyrkAuT6xJNhxTUVFRUbmF3NL50Ktmijo6OnZp1arVrbx9g3Dw4MFsYWSmm5eXlwgLC7vJEjU816ITaBp6UXVSM+r7cyV16aQ+DLoxiUcACCHmIxMKiI6OFgcOHKiH25s2iqLUlop8BWFhYag6uZKmoBdVJzWjvj9XUpdO6sPlsgaYZoh26QEUCCHS6uG6KioqKirXwFVb6IqirAAGAF6KoiQDLyMn10EI8SWwHhiJnGCmFLjvZgmroqKiolI7VzXoQojJVykXyNR/FRUVFZUGpOmuxKyioqJiZqgGXUVFRcVMUA26ioqKipmgGnQVFRUVM0E16CoqKipmgmrQVVRUVMwE1aCrqKiomAmqQVdRUVExE1SDXl8IAWX5DS2FiopKE0Y16PWBXg+r74Nltze0JCoqjRe9Tr5LKteNatBvBE0JbH0Dlt8JJ3+G5v1lS11FReXaKEiBxSNg/4KGlqRRc0vnQzcrKjWwYDBknQInP4h+AAa/DIrS0JKZFunHIWYNhA+C0J4NLY2KKZF6GDJPwYW/4fhqeaz77IaVqZGjGvTrxcoGBr8ElrYQMaShpTE9jiyHDXOhogAUS7B3Vw26inSpWFjInuzOD+HUGrB2hNajod+z4NWioSVs1KgG3Vh0Wkg+AEm7wMIa+jwBrUY1tFSmRcZJqCyHwC4Q0hPajgO/9tBuojToKk2b0lz4YTp0vAc6TILbv4TB/wX3ZmCpmqL6QNWiMaQegW8nQGmO3G8zTrYwmrp7RQjIS4TcBIjdBPu/lh+5u5eBRzMY+38NLaGKKVCpgQt/wcYXIDtWGnQAG0fwimhY2cwMowy6oijDgU8AS2ChEOLtauUzgPf4Z+m5z4QQC+tRzoZDr4N1T4CFFdz9Lfi0AY/mTdOY6/WQcgCCusrnXzEZYjfIMksb6DgZhr7esDKqmBanf4N1/4bidLB2gMkroMXghpbKbDFmxSJLYB4wFEgG9iuKskYIEVOt6iohxKM3QcaGRejB0Qd6Pgqtx9RabU9CNil5ZbjaW3MqrYg5Q8yo5ZF+AnZ+AKmHZIv8mQRw9IIeD0HLYeAVCX5RYOda6yWSckoI9XS8dTKbOrpKKM0GZ7+GluTmoNOCpTW4BoN3JIz6AML6gL1bQ0tm1hjTQu8GxAshzgIoirISGAdUN+jmgRCQtAf+eE36+DyaweiPwCWgxuplGh0xaQU8sOQAZVodAMEe9szq1xx7G8tbKXn9k38Btr8NMb9KH2dgNAx8EWycZHnzAXKrAb1ekFFUjhDw06FkPt4Sx4pZPega5nGLhDcNhBBkFlWg0wtS88vYEZdNX9uztNr5CBl2zUgds4J+LY1a1L5xoCmRLXIETJgP/u1h+pqGlqrJYIxBDwQuVNlPBrrXUO8ORVH6AbHAk0KIC9UrKIoyC5gFEBIScu3S3mz0OvhpFpxYDU6+UJgqDbpr4BVVtTo9H/weyzd7EynV6PBysuHTyZ1QgAGR3lhZNtIQf70Ocs/JaANnf+kfD+kBYz6pUQ81sTkmgzfXn+JcdsmlY+M7BtAhqGm1zsq1Op75/iCnThymi0Uc63Q9KMEejeUavK2smKcbRIesYvMw6ELAzvdh30IozoD+z6njTA1AfQ2KrgVWCCEqFEWZDSwFBlWvJISYD8wHiI6ObvgMnPTjYOsC7qGyC7zuCWnM+z0LfZ4EGwdAtrJOpRVRptVRUKZh3dE0TqcXEZNWyLiOAfRs7kmvcC9CPB0a+IGuEyHg1Fo48h0k7gYLS3gmXnaZ799Yx2mCT/6Io7W/C+0CXVn2VxIxqYXsiMsi0teZV8e2xc7aAncHG4a28UVpIi93fqmG+PQ84n56g9eLfsTNVn7Ypnb2wnfoEyQdFri0fpmPfGru9TU6hIA/34Htb0H4YJj4tXSvXAfpBeXklFTQNqB2951K7Rhj0FOA4Cr7Qfwz+AmAECKnyu5C4N0bF+0mUpYHez+HHe/KsKm+T0Hyfji8DPo9A4NevFRVq9Mz98fj/Hgo+dIxNwdrQjwceHdie+6KDq7pDo2HxF2w5RX5/K7B0P4uaNbXqFN/j8ng4y1xAFhaSGPd0teZu6ODeXlM28bvcrpG9HrBB5vP8PXOBH61eJbJFsmkBQzGrcfd4OxLu2b9QVHw6T+6oUWtXxQFTvwko78mLpFx5teIplLP6+tiWLHvPFGBrvzySO/6l7MxoddDeT44ePyzb4RejTHo+4EIRVGaIQ35JGBK1QqKovgLIdIMu2OBU8ZLfovJiIGvh4GmCFqOgA6GR3Hxh9vnQ4e7ASgs17InPpvv/j7Pzrhs/jUgnB7NPbGyUOgS6o6ddSM2VpUa0JbKASpbF+lmue0tmaVncflz5RRXsO9cLudySvj9ZAZa3T9zbVzILaWFjxO9wz2xtbZkWs9QgtwbaS/lOtDr9Px5LI61B+IIyD9EgOYcC4vGMqJjGDg+QEZABP5dah9Ib7SUF8jEsaQ9MOIdOb40eQW4hV6zMdfrBX/GZfHpH3EcPp/PvT1CmdWv+U0S3MQRQo5X7f1MZtE6+cK/Lw5VGufQuKpBF0JUKoryKLAJGba4SAhxUlGU14ADQog1wOOKoowFKoFcYMZ1PM7NR1cJax6VWZ7T/pAJMBfdAO5hcgPO55QyY/E+zmaXYGmh8O4d7bmrayNviVcUyVjxkz9D/B/gFgzT14F/e/Qzt7InIYeUgynSFRqfzYmUAgDSCsrRVEoj3inEDX9Xu0uXDHZ34NFBLYgKbHrd4/xDP2Gz5mEGUsZAw7FKLHEfdBcjhnUCOjWkeDeHrDNwcKn8DRWlgr2HdFu6BIBnuNGXKa6o5Pv9F1h9MJms4gqyiirwcbblk0kdGdfRuHEasyNmjZwXKvsMeLaQUXXuof+UWxjXgDTKhy6EWA+sr3bsv1X+fh543qg7NiRCLyM0RrwLQdFXFgvBnoQc5qw8jFYn+Hp6NO2CXPFxtqvhYo2Iv+fD5pdkFqeTH3Saynm3aGYviCGz5BganZ6i8spL1V3srOjX0hsrC4XBrWwZ3cEfH2fbJtX6rgudXvD63ko66/vSoUNnWgd7YxnQCauAjoww8sVrdOj1sHikbBgEd5PJYzW8Q7VxNquYP2OzSMop5ceDyRRVVNIpxI2+Lbzo19Kbke38sbFqpIEExpJ5Wo41JO8HB0+ZWDX4ZQjpDk4+MoS19xyZRXudvyPzzRTVaSHloFTe6fUw5mMZDzv1RznYV42ici2PrTjM9jNZBLnbs3JWV1r4ODeA4PWEENKtYuMIAR2hzXjoMoPKwK7sPpvHw98exMVez4h2Mg66a5gH0WEeKICHo03jdindDHSVcHodHFrKfI/n+PGCIz0mfkhUYx9DqQudVg6Ud5omXSkXY8kdvWo95Y9TGQgBOiE4lVbIgcQ89ifmUmHo5VlaKIxs588DfZrRMbgJRD3pddI4a0ph0TBAkRPVVRTKqRBKs2W9kB6XwjsrdXq2nEjjVFoR+xNzOZCUB0DsGyOuejvzM+g6LZz8RY645ybIY54tZAiid+RlxryiUkdeiZZ1x1JZvDuR9MJy/jOqNfd0D23cA3racjlnhksgjP5QtqiCu7E5JoPHXt1MuVZPKz9nltzXDT/XRt77uNloSmDHe4i/56NoS0i1acZ3Mae5s0sn7jRXY16cCSd+lFM55MTJwfIWg6Ht+DpPm7ctnvc2nbnsmL+rHVO6h+DnYseYDgFNp7FQlA4HFkmf+IPbZMTc0NchYpgcr6uGEIKV+y9gZ23B17vOcSKlEIAAVzumdg81uvdifga9sgLWPyVjqO/4Gpr1k92ZauSVaBj16U5SC8oB6NbMgw/u6kCP5p63WuL6JX4LbH4FMo7D8HcAw8BTbBb//v4Izb2cuKNLEHdFB+Fsd2VPRaUKKYcQS0ahaEtZp+/FDqtebCjrzOQ+zfj30MiGlu7mkLQXVk6WkWABnWDS8jpT9cu1OuysLdlwPI33Np1hfMcARrTzx0JRGBjpjaWF0mTCVamskO/fvgVwdjsgoNVo6aaycYAu0684pUyj44vt8Ry+kM/OONlad7Sx5NPJnRgZ5XfN+jMPg15RJMMQ+zwJtk4w8w/wCK9zxP3jLbGkF5bzwshW9Ar3Mo+Bvfg/YPkkcAuBO5dS3nIMP/6dxKJd50jIKiHQzZ6v7u1CsIfqC6+LglIt3+1LIiYVfHmQwxXuuLbsTWZRBSvvaG8ev5WaEAJ+f1HOjDl9Lfi1q7P6uewSRn6yk94tvNiTkE2HYDfendjB/H3hF6kohphfpAcgpAekHYOVU8A5APo/C+3uumI6YL1eEJ9VTKVOkFNSwfu/x3IsOR8/FzueuS2S1v7OhHg4XLe7t/Ea9Ipi2PEeJO6E7DjQFMuolYghdc7gllFYztM/HGVnXDZTe4Qwq5/xo/Mmzx+vgVsIBVM3UmbpwtxvD7L9TBZRgS58fHfHpjHwdCNUFHP+9AHO/PoeG8tuo8CjHXm+I3nsjuYMbHVlL88s0Oth62vQ9UGZCXz7V9JHXsd0xzq94Fx2MV/vSkSj07PlVAat/V1YcG8X8/99VWrg7DY4twOOrYKSLOj1mDToQdFw788Q1veKcbqSikp+PJTM4t2Jl2VQuztY88U9XRgeVT9z+jROg15RBAuHyKk4Q3pB1B3Q/u46F1A4eiGf938/w6m0Qso0Op4dHsn9vZvdQqFvEuWF8sdjbQ/D36LYKZTxi2Iu/WheHtOGGb3Cmk639zpJ3r8W798fJUSbjze2tBo4guBhA69+YmNn90ew6yPpouw++4rGUEZhOYVlWnyc7Vi+7zzbzmSSkldGSn4ZAJO7BTOlWyjhPo442DROc3JVdJVyLiMh4Ls7pDG3tJFZsX2e+KcnoxgGPJFRPYk5JQgB+xJzWfH3eQrLK+kY7MY7d7TD1d4GGyuFns296nW8rnH9D1RqZAy5rTO0vR2Cu0P45S/d6fRCzqQXAeDjbEe4jyPL/z7PV3+exdnOio7BbjwxpKV5dJszTsKvj8jZIKesojygO08sP8T53FImdwvB28lGNeZGsH/VW3SJeYdYEcQqx4d48J4pBAeFXv3Exs7JX2Tsc9Qd0G3WZUU6veDtDadYvDuRSr3A2lJBqxO0D3Kltb8L9/UO41hyAY8MbGGe4azlBRC3WfrC47fAv/bIrM3uD8nlJiOGgY0DFZU6dsVlk1GYw7pjqeSWaKjUC+Iziy9dykKBEVH+3N+nGV1Cb+5CL43HoKcegZX3wB0LILQXDJh7qaigTMuzq49yPLng0iBndYa09uHNCe0af0w5yMiLP9+BPf8Hts7o+jzNhuNpfL4tgZi0Ql4b15ZpPcMaWkqTpuTCcXZc0LI3y4aso2Vo3Afjcsf/8Vywb9OIwkjcBavvh6BuMObTyybREkLw9A9H+flwCpO6BtPCx4mU/DLuig6mtb9LAwp9Czi9HrH1dcg8hYKgwsqZdK9eHN53hhL7ACCKs1klbFn/N5U6QVG5lkJDDkeopwOt/KTve3zHAPpEeKMAfq52+LrcGrvTOAx6YapcTEGxACvby4pS88uYsXgf57JLGNXOnzYBLgyM9MHCQuFYcj7xmcVM6BxEuLdTAwlfz6Qege/uhJJMzgZPYIPfv1i+ppiU/MOEeTrw5dTODI+6MiyqqXMqrZBdcdmcyyok4sTH3Cd+5rB2Mt/oxjC560S6j3+l8c6QeT3s+khmRk9dLQMJDGh1eubvOMvPh1N4ckhL85rXvzb0OijLp9Tald/SfQnKceQv7QR26aM4VB6BKLaAxFxkEryMpR8Y6X3JbTKsrR9hno6EejhgYdGwvWHTN+jZ8bDsdhmIf/9G8GtHan4Z3+xN4vsDF8gt0eBsa8XS+7rRq8XlCQ9mY8QBKoopt7BH2Hmj9+nMByW3sSjOF+Ky6NHcg1fGtmVQK59Lk2Q1dSoNg3UnUws5dD6P3fE5DLA4wuvWSwhWMjnsPY4xg+bwUEg4Ho42DS3urefub6EwFY2lIzqNjhJNJasPJrN0TyJpBeUMa+PLY4PMdMHm/AsQuxFRkIIu/wLF5w5QjD1jS18mt1xPh+BXub93GFOae1LT22RvY2myIb8mbdBFSTb6pWNRdBWcGLqcNQcsSck/yO8xGQghGNbGj5a+ToztGNC4szrrQBSmUb7pVcrjttO36A2KhT0wDRtLC96a0JbbOwU2DReBEZRpdOSValh/PI0lexJJzitDUSDA1Z5FHeMYePo9hHcrGPQhnVqNbnpzdVcUyQVL+j/H8WzB17sKWXdsI5X6fyZ+6hXuyRvjoy71cs2G4iz0Dl5sPZ1J862P0Tx7G1phSbaFJ0mVXqwUQ+ke6c3Mfs3pHOLeaMedTMeg63UyyxMBmhKKrdx4dFUCnfK68buuKyd/LMbGqhQ3e2vu6xXG9F5hZhtP/emWWCIKdtFDHMPm5A9Y6ctZpRvO6A7BhPl7YWdlwch2/vjcIr+cKZBboiG/VANAUm4pB2KTGRxYia2iY3WyC5mFFcSePopLZR65uNA2yJcFLWNo2aYTlpGDID8C3DJQBv9XRgQ1JfQ6+PNdxJ5PQVvG/077szCtGU62VkzpHkKAmz0WCvRp4U2bADPwkWvL5EBmzBr0iTtRSrJQ9JU8H7CYVWdtaaaMRs8YfIIjySzR8tKoNnzSxrehpa4XGtSg6/SCxIO/E/DXK9jmn8VCJwc0BQrPu3zMzmwf2g94nskudrjYWzO0tW/jTsk3AiEEuWcPMSL1SUqELYdFS2KjXyYysgMPRZppLLQRLN59jso/PyTa4gxhSjoDLdLgIGzXdWC5eB5vZ1t+s/0frpZZ8oQsw+b6DEQOk7NLDn+rIR/h5iKEjMywcbw8Bvr4atj5IWSeZJtlbz6rGEpmeRv+MyqMu7sGm6zr4Eb4YvHX/Cv1RYosXNipiyJR15Uc4cLOxFJeGdOJga0GcCa9yCwXXWlQg16m1fHUT6d5zMqWJDGALCEn6ynGjrP5OhZOizbfhI5aUBSFV2ZN4vx+R45YtqeFnzv3m0Or6QYZEeWPR0Iq9mWlVDi3pbzZdM5UeGDpHMG+6L64OljDqdmX9LsAAALpSURBVI/loHlRmkzDDoqW6evmzJ/vyQQ7oQN9JaBIHcy9IEN8T61BL/S8ZvMUf1j14fnxrRnWxtesB4A3lLYhyfF1jlq2o3WQO30jvAhUFG73droUrmyuC5Y3qEG3s7LgsWmTgEmEAlUjf2f5OputS8UYQrqOwQRXXW0w2gS4wOxfL5vOoUP1Sq3NbCWgq5BboiFBF45Py2n4uzmQpnFAW1aEha4Cu9wCAny8EWM+5d1tqSzZcY5lD7Sjb4QZrF96FdY8MYgaVsBsEhhl0BVFGQ58glzgYqEQ4u1q5bb8f3v379pUFIZx/Ps0wQwKLTgoth0EW5AiCooOOihicesiNrvgIOIg/gHi5q5LQQcFcegUULCCf4AxUzGDFPFHRQIVFcWlxtchKaZNSm6FBD15PlMSDtzDC3m4vOfec+AecBj4BMxGxJuuF88NcXp/Gr0r64O/ONosZa9q3yguFIBT5IZEvWVxM7dY5uzUblbrv1io1jh/ZGwgwnzQdQ10STngNnAGWAbKkkoRUW0ZdgH4HBH7JBWBm8BsLyZsZg0HRod5dOUEX36s8rRa49D4CBO7dvCzHjxe/MiD5+8AuDY9yaWTiT6CaOtkuUM/CixFxGsASQ+BGaA10GeA683P88AtSYqIbAfhmdmWbS/kmdrT6Akf3/AOxsHxEa5OTwJQyKf9IIH9kSXQR4H3Ld+XgWObjWmeQfoV2AmstA6SdBFY2zTiu6T1u+GnKfOmIJVKZUXS215O5h+xpY1SBqQurkln/v+027QmfV0UjYg5YK6f1/yfRISbnB24Lu1ck3auCWRZZfoAtJ61Ndb8reMYSXlgmMbiqJmZ9UmWQC8DE5L2StoGFIHShjElYO18pXPAM/fPzcz6q2vLpdkTvww8ofHY4t2IeCnpBvAiIkrAHeC+pCUaW5IVezlpMzNrJ99Im5mlwW9qmJklwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSJ+A1+MI44zuSSUAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gPN-Iq07EdsN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}